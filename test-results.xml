<?xml version="1.0" encoding="utf-8"?><testsuites><testsuite name="pytest" errors="65" failures="109" skipped="65" tests="303" time="84.581" timestamp="2025-05-20T22:12:06.538214-03:00" hostname="OA1"><testcase classname="tests.integration.guardiaoCognitivo.test_guardiao_cognitivo" name="test_health_check_parado" time="0.010"><failure message="AssertionError: assert 'unhealthy' == 'healthy'&#10;  &#10;  - healthy&#10;  + unhealthy&#10;  ? ++">client = &lt;FlaskClient &lt;Flask 'src.guardiao.guardiao_cognitivo'&gt;&gt;

    def test_health_check_parado(client):
        response = client.get("/health")
        data = json.loads(response.data)
        assert response.status_code == 200
&gt;       assert data["status"] == "healthy" # Mesmo parado, o serviço Flask está healthy
E       AssertionError: assert 'unhealthy' == 'healthy'
E         
E         - healthy
E         + unhealthy
E         ? ++

tests\integration\guardiaoCognitivo\test_guardiao_cognitivo.py:49: AssertionError</failure></testcase><testcase classname="tests.integration.guardiaoCognitivo.test_guardiao_cognitivo" name="test_start_stop_guardian" time="1.108" /><testcase classname="tests.integration.guardiaoCognitivo.test_guardiao_cognitivo" name="test_new_diagnosis_event" time="0.003" /><testcase classname="tests.integration.guardiaoCognitivo.test_guardiao_cognitivo" name="test_new_action_plan_event" time="0.003" /><testcase classname="tests.integration.guardiaoCognitivo.test_guardiao_cognitivo" name="test_verificar_coerencia_diagnosticos_aciona_emergencia" time="0.003"><failure message="ModuleNotFoundError: No module named 'guardiao_cognitivo'">args = (), keywargs = {'client': &lt;FlaskClient &lt;Flask 'src.guardiao.guardiao_cognitivo'&gt;&gt;}

    @wraps(func)
    def patched(*args, **keywargs):
&gt;       with self.decoration_helper(patched,
                                    args,
                                    keywargs) as (newargs, newkeywargs):

C:\Python313\Lib\unittest\mock.py:1423: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
C:\Python313\Lib\contextlib.py:141: in __enter__
    return next(self.gen)
C:\Python313\Lib\unittest\mock.py:1405: in decoration_helper
    arg = exit_stack.enter_context(patching)
C:\Python313\Lib\contextlib.py:530: in enter_context
    result = _enter(cm)
C:\Python313\Lib\unittest\mock.py:1481: in __enter__
    self.target = self.getter()
C:\Python313\Lib\pkgutil.py:513: in resolve_name
    mod = importlib.import_module(modname)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'guardiao_cognitivo', package = None

    def import_module(name, package=None):
        """Import a module.
    
        The 'package' argument is required when performing a relative import. It
        specifies the package to use as the anchor point from which to resolve the
        relative import to an absolute import.
    
        """
        level = 0
        if name.startswith('.'):
            if not package:
                raise TypeError("the 'package' argument is required to perform a "
                                f"relative import for {name!r}")
            for character in name:
                if character != '.':
                    break
                level += 1
&gt;       return _bootstrap._gcd_import(name[level:], package, level)
E       ModuleNotFoundError: No module named 'guardiao_cognitivo'

C:\Python313\Lib\importlib\__init__.py:88: ModuleNotFoundError</failure></testcase><testcase classname="tests.integration.guardiaoCognitivo.test_guardiao_cognitivo" name="test_verificar_eficacia_acoes_aciona_emergencia" time="0.004"><failure message="ModuleNotFoundError: No module named 'guardiao_cognitivo'">args = (), keywargs = {'client': &lt;FlaskClient &lt;Flask 'src.guardiao.guardiao_cognitivo'&gt;&gt;}

    @wraps(func)
    def patched(*args, **keywargs):
&gt;       with self.decoration_helper(patched,
                                    args,
                                    keywargs) as (newargs, newkeywargs):

C:\Python313\Lib\unittest\mock.py:1423: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
C:\Python313\Lib\contextlib.py:141: in __enter__
    return next(self.gen)
C:\Python313\Lib\unittest\mock.py:1405: in decoration_helper
    arg = exit_stack.enter_context(patching)
C:\Python313\Lib\contextlib.py:530: in enter_context
    result = _enter(cm)
C:\Python313\Lib\unittest\mock.py:1481: in __enter__
    self.target = self.getter()
C:\Python313\Lib\pkgutil.py:513: in resolve_name
    mod = importlib.import_module(modname)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

name = 'guardiao_cognitivo', package = None

    def import_module(name, package=None):
        """Import a module.
    
        The 'package' argument is required when performing a relative import. It
        specifies the package to use as the anchor point from which to resolve the
        relative import to an absolute import.
    
        """
        level = 0
        if name.startswith('.'):
            if not package:
                raise TypeError("the 'package' argument is required to perform a "
                                f"relative import for {name!r}")
            for character in name:
                if character != '.':
                    break
                level += 1
&gt;       return _bootstrap._gcd_import(name[level:], package, level)
E       ModuleNotFoundError: No module named 'guardiao_cognitivo'

C:\Python313\Lib\importlib\__init__.py:88: ModuleNotFoundError</failure></testcase><testcase classname="tests.integration.guardiaoCognitivo.test_guardiao_cognitivo" name="test_acionar_protocolo_emergencia_com_escalonamento" time="0.005" /><testcase classname="tests.integration.test_dependencias_integration" name="test_fluxo_completo_autocura" time="0.003"><failure message="assert False is True&#10; +  where False = verificar_compatibilidade_python()&#10; +    where verificar_compatibilidade_python = &lt;src.autocura.dependencias.GerenciadorDependencias object at 0x000002471E67F230&gt;.verificar_compatibilidade_python">gerenciador = &lt;src.autocura.dependencias.GerenciadorDependencias object at 0x000002471E67F230&gt;
requirements_teste = 'requirements_teste.txt'

    def test_fluxo_completo_autocura(gerenciador, requirements_teste):
        """Testa o fluxo completo de autocura com um pacote real."""
        # Registra um problema conhecido
        gerenciador.registrar_problema(
            pacote="pytest",
            versao="7.4.0",
            erro="No matching distribution found for pytest==7.4.0",
            solucao="Instalar pytest com versão específica: pip install pytest==7.4.0"
        )
    
        # Verifica compatibilidade do Python
&gt;       assert gerenciador.verificar_compatibilidade_python() is True
E       assert False is True
E        +  where False = verificar_compatibilidade_python()
E        +    where verificar_compatibilidade_python = &lt;src.autocura.dependencias.GerenciadorDependencias object at 0x000002471E67F230&gt;.verificar_compatibilidade_python

tests\integration\test_dependencias_integration.py:37: AssertionError</failure></testcase><testcase classname="tests.integration.test_dependencias_integration" name="test_historico_persistencia" time="0.010"><failure message="AssertionError: assert 3 == 2&#10; +  where 3 = len([ProblemaDependencia(pacote='pytest', versao='7.4.0', erro='No matching distribution found for pytest==7.4.0', solucao='Instalar pytest com vers\xe3o espec\xedfica: pip install pytest==7.4.0', data_ocorrencia=datetime.datetime(2025, 5, 20, 22, 12, 12, 956910), resolvido=False), ProblemaDependencia(pacote='pytest', versao='7.4.0', erro='Erro 1', solucao='Solu\xe7\xe3o 1', data_ocorrencia=datetime.datetime(2025, 5, 20, 22, 12, 12, 962338), resolvido=False), ProblemaDependencia(pacote='prometheus-client', versao='0.17.1', erro='Erro 2', solucao='Solu\xe7\xe3o 2', data_ocorrencia=datetime.datetime(2025, 5, 20, 22, 12, 12, 963082), resolvido=False)])&#10; +    where [ProblemaDependencia(pacote='pytest', versao='7.4.0', erro='No matching distribution found for pytest==7.4.0', solucao='Instalar pytest com vers\xe3o espec\xedfica: pip install pytest==7.4.0', data_ocorrencia=datetime.datetime(2025, 5, 20, 22, 12, 12, 956910), resolvido=False), ProblemaDependencia(pacote='pytest', versao='7.4.0', erro='Erro 1', solucao='Solu\xe7\xe3o 1', data_ocorrencia=datetime.datetime(2025, 5, 20, 22, 12, 12, 962338), resolvido=False), ProblemaDependencia(pacote='prometheus-client', versao='0.17.1', erro='Erro 2', solucao='Solu\xe7\xe3o 2', data_ocorrencia=datetime.datetime(2025, 5, 20, 22, 12, 12, 963082), resolvido=False)] = &lt;src.autocura.dependencias.GerenciadorDependencias object at 0x000002471E5DA350&gt;.historico&#10; +  and   2 = len([('pytest', '7.4.0', 'Erro 1', 'Solu\xe7\xe3o 1'), ('prometheus-client', '0.17.1', 'Erro 2', 'Solu\xe7\xe3o 2')])">gerenciador = &lt;src.autocura.dependencias.GerenciadorDependencias object at 0x000002471E67F230&gt;

    def test_historico_persistencia(gerenciador):
        """Testa a persistência do histórico entre instâncias."""
        # Registra problemas
        problemas = [
            ("pytest", "7.4.0", "Erro 1", "Solução 1"),
            ("prometheus-client", "0.17.1", "Erro 2", "Solução 2")
        ]
    
        for pacote, versao, erro, solucao in problemas:
            gerenciador.registrar_problema(pacote, versao, erro, solucao)
    
        # Cria novo gerenciador
        novo_gerenciador = GerenciadorDependencias(arquivo_historico=gerenciador.arquivo_historico)
    
        # Verifica se os problemas foram carregados
&gt;       assert len(novo_gerenciador.historico) == len(problemas)
E       AssertionError: assert 3 == 2
E        +  where 3 = len([ProblemaDependencia(pacote='pytest', versao='7.4.0', erro='No matching distribution found for pytest==7.4.0', solucao='Instalar pytest com vers\xe3o espec\xedfica: pip install pytest==7.4.0', data_ocorrencia=datetime.datetime(2025, 5, 20, 22, 12, 12, 956910), resolvido=False), ProblemaDependencia(pacote='pytest', versao='7.4.0', erro='Erro 1', solucao='Solu\xe7\xe3o 1', data_ocorrencia=datetime.datetime(2025, 5, 20, 22, 12, 12, 962338), resolvido=False), ProblemaDependencia(pacote='prometheus-client', versao='0.17.1', erro='Erro 2', solucao='Solu\xe7\xe3o 2', data_ocorrencia=datetime.datetime(2025, 5, 20, 22, 12, 12, 963082), resolvido=False)])
E        +    where [ProblemaDependencia(pacote='pytest', versao='7.4.0', erro='No matching distribution found for pytest==7.4.0', solucao='Instalar pytest com vers\xe3o espec\xedfica: pip install pytest==7.4.0', data_ocorrencia=datetime.datetime(2025, 5, 20, 22, 12, 12, 956910), resolvido=False), ProblemaDependencia(pacote='pytest', versao='7.4.0', erro='Erro 1', solucao='Solu\xe7\xe3o 1', data_ocorrencia=datetime.datetime(2025, 5, 20, 22, 12, 12, 962338), resolvido=False), ProblemaDependencia(pacote='prometheus-client', versao='0.17.1', erro='Erro 2', solucao='Solu\xe7\xe3o 2', data_ocorrencia=datetime.datetime(2025, 5, 20, 22, 12, 12, 963082), resolvido=False)] = &lt;src.autocura.dependencias.GerenciadorDependencias object at 0x000002471E5DA350&gt;.historico
E        +  and   2 = len([('pytest', '7.4.0', 'Erro 1', 'Solu\xe7\xe3o 1'), ('prometheus-client', '0.17.1', 'Erro 2', 'Solu\xe7\xe3o 2')])

tests\integration\test_dependencias_integration.py:69: AssertionError</failure></testcase><testcase classname="tests.integration.test_dependencias_integration" name="test_sugestao_solucao_integracao" time="0.002" /><testcase classname="tests.integration.test_dependencias_integration" name="test_limpeza_arquivo_historico" time="0.001" /><testcase classname="tests.integration.test_sistema_completo.TestSistemaCompleto" name="test_fluxo_completo_processamento" time="0.319"><failure message="AssertionError: assert 'Iniciando processamento' in ''&#10; +  where '' = &lt;_pytest.logging.LogCaptureFixture object at 0x000002471F32E120&gt;.text">self = &lt;tests.integration.test_sistema_completo.TestSistemaCompleto object at 0x0000024762843610&gt;
config_teste = {'ambiente': 'teste', 'api_url': 'http://localhost:8000', 'db_url': 'postgresql://test:test@localhost:5432/test_db', 'redis_url': 'redis://localhost:6379/0', ...}
mock_api = &lt;MagicMock name='Session' id='2504482925808'&gt;
mock_db = &lt;MagicMock name='create_engine' id='2504489361024'&gt;
mock_redis = &lt;MagicMock name='Redis' id='2504489361360'&gt;
monitoramento = &lt;src.orquestrador.monitoramento.MonitoramentoTestes object at 0x000002471EC89940&gt;
log_captura = &lt;_pytest.logging.LogCaptureFixture object at 0x000002471F32E120&gt;

    def test_fluxo_completo_processamento(
        self,
        config_teste: Dict[str, Any],
        mock_api: Any,
        mock_db: Any,
        mock_redis: Any,
        monitoramento: Any,
        log_captura: pytest.LogCaptureFixture
    ) -&gt; None:
        """
        Testa o fluxo completo de processamento de dados.
    
        Este teste verifica:
        1. Recebimento de dados
        2. Validação
        3. Processamento
        4. Armazenamento
        5. Cache
        6. Notificações
    
        Args:
            config_teste: Configurações de teste
            mock_api: Mock da API
            mock_db: Mock do banco de dados
            mock_redis: Mock do Redis
            monitoramento: Instância do monitoramento
            log_captura: Fixture para captura de logs
        """
        # Arrange
        dados_entrada = {
            "id": "test_123",
            "dados": [1, 2, 3],
            "timestamp": datetime.now().isoformat()
        }
    
        # Configura mocks
        mock_api.return_value.post.return_value.json.return_value = {"status": "success"}
        mock_db.return_value.execute.return_value = None
        mock_redis.return_value.set.return_value = True
    
        # Act
        inicio = time.time()
        resultado = self._processar_dados(dados_entrada, config_teste)
        duracao = time.time() - inicio
    
        # Assert
        assert resultado["status"] == "success"
        assert "id" in resultado
        assert "timestamp" in resultado
    
        # Verifica logs
&gt;       assert "Iniciando processamento" in log_captura.text
E       AssertionError: assert 'Iniciando processamento' in ''
E        +  where '' = &lt;_pytest.logging.LogCaptureFixture object at 0x000002471F32E120&gt;.text

tests\integration\test_sistema_completo.py:83: AssertionError</failure></testcase><testcase classname="tests.integration.test_sistema_completo.TestSistemaCompleto" name="test_recuperacao_falha" time="0.002"><failure message="AssertionError: assert 0 == 2&#10; +  where 0 = &lt;MagicMock name='Session().post' id='2504489366064'&gt;.call_count&#10; +    where &lt;MagicMock name='Session().post' id='2504489366064'&gt; = &lt;MagicMock name='Session()' id='2504489365728'&gt;.post&#10; +      where &lt;MagicMock name='Session()' id='2504489365728'&gt; = &lt;MagicMock name='Session' id='2504489364720'&gt;.return_value">self = &lt;tests.integration.test_sistema_completo.TestSistemaCompleto object at 0x0000024762843750&gt;
config_teste = {'ambiente': 'teste', 'api_url': 'http://localhost:8000', 'db_url': 'postgresql://test:test@localhost:5432/test_db', 'redis_url': 'redis://localhost:6379/0', ...}
mock_api = &lt;MagicMock name='Session' id='2504489364720'&gt;
mock_db = &lt;MagicMock name='create_engine' id='2504489365056'&gt;
mock_redis = &lt;MagicMock name='Redis' id='2504489365392'&gt;
monitoramento = &lt;src.orquestrador.monitoramento.MonitoramentoTestes object at 0x000002471EC89940&gt;

    def test_recuperacao_falha(
        self,
        config_teste: Dict[str, Any],
        mock_api: Any,
        mock_db: Any,
        mock_redis: Any,
        monitoramento: Any
    ) -&gt; None:
        """
        Testa a recuperação após uma falha no processamento.
    
        Este teste verifica:
        1. Falha inicial
        2. Retry automático
        3. Recuperação
        4. Processamento final
    
        Args:
            config_teste: Configurações de teste
            mock_api: Mock da API
            mock_db: Mock do banco de dados
            mock_redis: Mock do Redis
            monitoramento: Instância do monitoramento
        """
        # Arrange
        dados_entrada = {
            "id": "test_456",
            "dados": [4, 5, 6],
            "timestamp": datetime.now().isoformat()
        }
    
        # Configura falha inicial e recuperação
        mock_api.return_value.post.side_effect = [
            Exception("Erro temporário"),
            {"status": "success"}
        ]
    
        # Act
        resultado = self._processar_dados_com_retry(
            dados_entrada,
            config_teste,
            max_retries=3
        )
    
        # Assert
        assert resultado["status"] == "success"
&gt;       assert mock_api.return_value.post.call_count == 2
E       AssertionError: assert 0 == 2
E        +  where 0 = &lt;MagicMock name='Session().post' id='2504489366064'&gt;.call_count
E        +    where &lt;MagicMock name='Session().post' id='2504489366064'&gt; = &lt;MagicMock name='Session()' id='2504489365728'&gt;.post
E        +      where &lt;MagicMock name='Session()' id='2504489365728'&gt; = &lt;MagicMock name='Session' id='2504489364720'&gt;.return_value

tests\integration\test_sistema_completo.py:139: AssertionError</failure></testcase><testcase classname="tests.integration.test_sistema_completo.TestSistemaCompleto" name="test_processamento_concorrente" time="16.306"><failure message="elastic_transport.ConnectionError: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(&lt;urllib3.connection.HTTPConnection object at 0x000002471F32F770&gt;: Failed to establish a new connection: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente))">self = &lt;urllib3.connection.HTTPConnection object at 0x000002471F297820&gt;

    def _new_conn(self) -&gt; socket.socket:
        """Establish a socket connection and set nodelay settings on it.
    
        :return: New socket connection.
        """
        try:
&gt;           sock = connection.create_connection(
                (self._dns_host, self.port),
                self.timeout,
                source_address=self.source_address,
                socket_options=self.socket_options,
            )

C:\Python313\Lib\site-packages\urllib3\connection.py:198: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
C:\Python313\Lib\site-packages\urllib3\util\connection.py:85: in create_connection
    raise err
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

address = ('localhost', 9200), timeout = 10.0, source_address = None
socket_options = [(6, 1, 1)]

    def create_connection(
        address: tuple[str, int],
        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,
        source_address: tuple[str, int] | None = None,
        socket_options: _TYPE_SOCKET_OPTIONS | None = None,
    ) -&gt; socket.socket:
        """Connect to *address* and return the socket object.
    
        Convenience function.  Connect to *address* (a 2-tuple ``(host,
        port)``) and return the socket object.  Passing the optional
        *timeout* parameter will set the timeout on the socket instance
        before attempting to connect.  If no *timeout* is supplied, the
        global default timeout setting returned by :func:`socket.getdefaulttimeout`
        is used.  If *source_address* is set it must be a tuple of (host, port)
        for the socket to bind as a source address before making the connection.
        An host of '' or port 0 tells the OS to use the default.
        """
    
        host, port = address
        if host.startswith("["):
            host = host.strip("[]")
        err = None
    
        # Using the value from allowed_gai_family() in the context of getaddrinfo lets
        # us select whether to work with IPv4 DNS records, IPv6 records, or both.
        # The original create_connection function always returns all records.
        family = allowed_gai_family()
    
        try:
            host.encode("idna")
        except UnicodeError:
            raise LocationParseError(f"'{host}', label empty or too long") from None
    
        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):
            af, socktype, proto, canonname, sa = res
            sock = None
            try:
                sock = socket.socket(af, socktype, proto)
    
                # If provided, set socket level options before connecting.
                _set_socket_options(sock, socket_options)
    
                if timeout is not _DEFAULT_TIMEOUT:
                    sock.settimeout(timeout)
                if source_address:
                    sock.bind(source_address)
&gt;               sock.connect(sa)
E               ConnectionRefusedError: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente

C:\Python313\Lib\site-packages\urllib3\util\connection.py:73: ConnectionRefusedError

The above exception was the direct cause of the following exception:

self = &lt;Urllib3HttpNode(http://localhost:9200)&gt;, method = 'POST'
target = '/autocura-testes-2025.05.20/_doc'
body = b'{"timestamp":"2025-05-20T22:12:13.313880","nome":"test_processamento_concorrente","sucesso":true,"duracao":1.5735626220703125e-05}'
headers = {'accept': 'application/vnd.elasticsearch+json; compatible-with=9', 'content-type': 'application/vnd.elasticsearch+json; compatible-with=9', 'x-elastic-client-meta': 'es=9.0.1,py=3.13.3,t=8.17.1,ur=2.4.0'}
request_timeout = &lt;DEFAULT&gt;

    def perform_request(
        self,
        method: str,
        target: str,
        body: Optional[bytes] = None,
        headers: Optional[HttpHeaders] = None,
        request_timeout: Union[DefaultType, Optional[float]] = DEFAULT,
    ) -&gt; NodeApiResponse:
        if self.path_prefix:
            target = f"{self.path_prefix}{target}"
    
        start = time.time()
        try:
            kw = {}
            if request_timeout is not DEFAULT:
                kw["timeout"] = request_timeout
    
            request_headers = self._headers.copy()
            if headers:
                request_headers.update(headers)
    
            body_to_send: Optional[bytes]
            if body:
                if self._http_compress:
                    body_to_send = gzip.compress(body)
                    request_headers["content-encoding"] = "gzip"
                else:
                    body_to_send = body
            else:
                body_to_send = None
    
&gt;           response = self.pool.urlopen(
                method,
                target,
                body=body_to_send,
                retries=Retry(False),
                headers=request_headers,
                **kw,  # type: ignore[arg-type]
            )

C:\Python313\Lib\site-packages\elastic_transport\_node\_http_urllib3.py:167: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
C:\Python313\Lib\site-packages\urllib3\connectionpool.py:841: in urlopen
    retries = retries.increment(
C:\Python313\Lib\site-packages\urllib3\util\retry.py:449: in increment
    raise reraise(type(error), error, _stacktrace)
C:\Python313\Lib\site-packages\urllib3\util\util.py:39: in reraise
    raise value
C:\Python313\Lib\site-packages\urllib3\connectionpool.py:787: in urlopen
    response = self._make_request(
C:\Python313\Lib\site-packages\urllib3\connectionpool.py:493: in _make_request
    conn.request(
C:\Python313\Lib\site-packages\urllib3\connection.py:445: in request
    self.endheaders()
C:\Python313\Lib\http\client.py:1333: in endheaders
    self._send_output(message_body, encode_chunked=encode_chunked)
C:\Python313\Lib\http\client.py:1093: in _send_output
    self.send(msg)
C:\Python313\Lib\http\client.py:1037: in send
    self.connect()
C:\Python313\Lib\site-packages\urllib3\connection.py:276: in connect
    self.sock = self._new_conn()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;urllib3.connection.HTTPConnection object at 0x000002471F297820&gt;

    def _new_conn(self) -&gt; socket.socket:
        """Establish a socket connection and set nodelay settings on it.
    
        :return: New socket connection.
        """
        try:
            sock = connection.create_connection(
                (self._dns_host, self.port),
                self.timeout,
                source_address=self.source_address,
                socket_options=self.socket_options,
            )
        except socket.gaierror as e:
            raise NameResolutionError(self.host, self, e) from e
        except SocketTimeout as e:
            raise ConnectTimeoutError(
                self,
                f"Connection to {self.host} timed out. (connect timeout={self.timeout})",
            ) from e
    
        except OSError as e:
&gt;           raise NewConnectionError(
                self, f"Failed to establish a new connection: {e}"
            ) from e
E           urllib3.exceptions.NewConnectionError: &lt;urllib3.connection.HTTPConnection object at 0x000002471F297820&gt;: Failed to establish a new connection: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente

C:\Python313\Lib\site-packages\urllib3\connection.py:213: NewConnectionError

The above exception was the direct cause of the following exception:

self = &lt;tests.integration.test_sistema_completo.TestSistemaCompleto object at 0x00000247629A4D60&gt;
config_teste = {'ambiente': 'teste', 'api_url': 'http://localhost:8000', 'db_url': 'postgresql://test:test@localhost:5432/test_db', 'redis_url': 'redis://localhost:6379/0', ...}
mock_api = &lt;MagicMock name='Session' id='2504489361696'&gt;
mock_db = &lt;MagicMock name='create_engine' id='2504489366400'&gt;
mock_redis = &lt;MagicMock name='Redis' id='2504489366736'&gt;
monitoramento = &lt;src.orquestrador.monitoramento.MonitoramentoTestes object at 0x000002471EC89940&gt;

    def test_processamento_concorrente(
        self,
        config_teste: Dict[str, Any],
        mock_api: Any,
        mock_db: Any,
        mock_redis: Any,
        monitoramento: Any
    ) -&gt; None:
        """
        Testa o processamento concorrente de múltiplos dados.
    
        Este teste verifica:
        1. Processamento paralelo
        2. Consistência dos dados
        3. Performance
    
        Args:
            config_teste: Configurações de teste
            mock_api: Mock da API
            mock_db: Mock do banco de dados
            mock_redis: Mock do Redis
            monitoramento: Instância do monitoramento
        """
        # Arrange
        dados_entrada = [
            {"id": f"test_{i}", "dados": [i], "timestamp": datetime.now().isoformat()}
            for i in range(10)
        ]
    
        # Act
        inicio = time.time()
        resultados = self._processar_dados_concorrente(dados_entrada, config_teste)
        duracao = time.time() - inicio
    
        # Assert
        assert len(resultados) == len(dados_entrada)
        assert all(r["status"] == "success" for r in resultados)
    
        # Verifica métricas
&gt;       monitoramento.registrar_execucao_teste(
            "test_processamento_concorrente",
            True,
            duracao
        )

tests\integration\test_sistema_completo.py:187: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\orquestrador\monitoramento.py:143: in registrar_execucao_teste
    self.es.index(
C:\Python313\Lib\site-packages\elasticsearch\_sync\client\utils.py:415: in wrapped
    return api(*args, **kwargs)
C:\Python313\Lib\site-packages\elasticsearch\_sync\client\__init__.py:2951: in index
    return self.perform_request(  # type: ignore[return-value]
C:\Python313\Lib\site-packages\elasticsearch\_sync\client\_base.py:271: in perform_request
    response = self._perform_request(
C:\Python313\Lib\site-packages\elasticsearch\_sync\client\_base.py:315: in _perform_request
    meta, resp_body = self.transport.perform_request(
C:\Python313\Lib\site-packages\elastic_transport\_transport.py:342: in perform_request
    resp = node.perform_request(
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;Urllib3HttpNode(http://localhost:9200)&gt;, method = 'POST'
target = '/autocura-testes-2025.05.20/_doc'
body = b'{"timestamp":"2025-05-20T22:12:13.313880","nome":"test_processamento_concorrente","sucesso":true,"duracao":1.5735626220703125e-05}'
headers = {'accept': 'application/vnd.elasticsearch+json; compatible-with=9', 'content-type': 'application/vnd.elasticsearch+json; compatible-with=9', 'x-elastic-client-meta': 'es=9.0.1,py=3.13.3,t=8.17.1,ur=2.4.0'}
request_timeout = &lt;DEFAULT&gt;

    def perform_request(
        self,
        method: str,
        target: str,
        body: Optional[bytes] = None,
        headers: Optional[HttpHeaders] = None,
        request_timeout: Union[DefaultType, Optional[float]] = DEFAULT,
    ) -&gt; NodeApiResponse:
        if self.path_prefix:
            target = f"{self.path_prefix}{target}"
    
        start = time.time()
        try:
            kw = {}
            if request_timeout is not DEFAULT:
                kw["timeout"] = request_timeout
    
            request_headers = self._headers.copy()
            if headers:
                request_headers.update(headers)
    
            body_to_send: Optional[bytes]
            if body:
                if self._http_compress:
                    body_to_send = gzip.compress(body)
                    request_headers["content-encoding"] = "gzip"
                else:
                    body_to_send = body
            else:
                body_to_send = None
    
            response = self.pool.urlopen(
                method,
                target,
                body=body_to_send,
                retries=Retry(False),
                headers=request_headers,
                **kw,  # type: ignore[arg-type]
            )
            response_headers = HttpHeaders(response.headers)
            data = response.data
            duration = time.time() - start
    
        except RERAISE_EXCEPTIONS:
            raise
        except Exception as e:
            err: Exception
            if isinstance(e, NewConnectionError):
                err = ConnectionError(str(e), errors=(e,))
            elif isinstance(e, (ConnectTimeoutError, ReadTimeoutError)):
                err = ConnectionTimeout(
                    "Connection timed out during request", errors=(e,)
                )
            elif isinstance(e, (ssl.SSLError, urllib3.exceptions.SSLError)):
                err = TlsError(str(e), errors=(e,))
            elif isinstance(e, BUILTIN_EXCEPTIONS):
                raise
            else:
                err = ConnectionError(str(e), errors=(e,))
            self._log_request(
                method=method,
                target=target,
                headers=request_headers,
                body=body,
                exception=err,
            )
&gt;           raise err from e
E           elastic_transport.ConnectionError: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(&lt;urllib3.connection.HTTPConnection object at 0x000002471F32F770&gt;: Failed to establish a new connection: [WinError 10061] Nenhuma conexão pôde ser feita porque a máquina de destino as recusou ativamente))

C:\Python313\Lib\site-packages\elastic_transport\_node\_http_urllib3.py:202: ConnectionError</failure></testcase><testcase classname="tests.integration.test_sistema_completo.TestSistemaCompleto" name="test_persistencia_dados" time="0.014" /><testcase classname="tests.test_auto_scaling" name="test_inicializacao" time="0.001" /><testcase classname="tests.test_auto_scaling" name="test_registrar_metricas" time="0.001" /><testcase classname="tests.test_auto_scaling" name="test_scaling_up" time="0.001"><failure message="assert None == 2">auto_scaling = &lt;src.scaling.auto_scaling.AutoScaling object at 0x000002471F33B250&gt;

    def test_scaling_up(auto_scaling):
        """Testa o scaling up quando as métricas excedem os limites."""
        # Registra métricas que devem trigger scaling up
        for i in range(10):
            metricas = MetricasScaling(
                cpu_usage=80.0,  # Acima do threshold
                memoria_usage=85.0,  # Acima do threshold
                latencia=250.0,  # Acima do threshold
                requests_por_segundo=150.0,
                timestamp=datetime.now()
            )
            auto_scaling.registrar_metricas(metricas)
    
        # Executa scaling
        novas_instancias = auto_scaling.executar_scaling()
&gt;       assert novas_instancias == 2  # Deve aumentar para 2 instâncias
E       assert None == 2

tests\test_auto_scaling.py:55: AssertionError</failure></testcase><testcase classname="tests.test_auto_scaling" name="test_scaling_down" time="0.001"><failure message="assert None == 2">auto_scaling = &lt;src.scaling.auto_scaling.AutoScaling object at 0x000002471F5AD6E0&gt;

    def test_scaling_down(auto_scaling):
        """Testa o scaling down quando as métricas estão baixas."""
        # Primeiro escala up
        auto_scaling.instancias_atuais = 3
    
        # Registra métricas que devem trigger scaling down
        for i in range(10):
            metricas = MetricasScaling(
                cpu_usage=30.0,  # Bem abaixo do threshold
                memoria_usage=35.0,  # Bem abaixo do threshold
                latencia=100.0,  # Bem abaixo do threshold
                requests_por_segundo=50.0,
                timestamp=datetime.now()
            )
            auto_scaling.registrar_metricas(metricas)
    
        # Executa scaling
        novas_instancias = auto_scaling.executar_scaling()
&gt;       assert novas_instancias == 2  # Deve diminuir para 2 instâncias
E       assert None == 2

tests\test_auto_scaling.py:75: AssertionError</failure></testcase><testcase classname="tests.test_auto_scaling" name="test_cooldown_period" time="0.001"><failure message="assert None == 2">auto_scaling = &lt;src.scaling.auto_scaling.AutoScaling object at 0x000002471F5AD940&gt;

    def test_cooldown_period(auto_scaling):
        """Testa o período de cooldown entre operações de scaling."""
        # Registra métricas para scaling up
        for i in range(10):
            metricas = MetricasScaling(
                cpu_usage=80.0,
                memoria_usage=85.0,
                latencia=250.0,
                requests_por_segundo=150.0,
                timestamp=datetime.now()
            )
            auto_scaling.registrar_metricas(metricas)
    
        # Primeiro scaling
        novas_instancias = auto_scaling.executar_scaling()
&gt;       assert novas_instancias == 2
E       assert None == 2

tests\test_auto_scaling.py:92: AssertionError</failure></testcase><testcase classname="tests.test_auto_scaling" name="test_limites_instancias" time="0.001" /><testcase classname="tests.test_auto_scaling" name="test_obter_metricas_atual" time="0.001" /><testcase classname="tests.test_autocura" name="test_memory_manager_initialization" time="0.004"><failure message="AssertionError: assert False&#10; +  where False = exists()&#10; +    where exists = WindowsPath('C:/Users/filip/AppData/Local/Temp/pytest-of-filip/pytest-2/test_memory_manager_initializa0/test_memory.json').exists&#10; +      where WindowsPath('C:/Users/filip/AppData/Local/Temp/pytest-of-filip/pytest-2/test_memory_manager_initializa0/test_memory.json') = &lt;src.autocura.memory.MemoryManager object at 0x000002471F32F0E0&gt;.memory_path">memory_manager = &lt;src.autocura.memory.MemoryManager object at 0x000002471F32F0E0&gt;

    def test_memory_manager_initialization(memory_manager):
        """Testa inicialização do MemoryManager"""
&gt;       assert memory_manager.memory_path.exists()
E       AssertionError: assert False
E        +  where False = exists()
E        +    where exists = WindowsPath('C:/Users/filip/AppData/Local/Temp/pytest-of-filip/pytest-2/test_memory_manager_initializa0/test_memory.json').exists
E        +      where WindowsPath('C:/Users/filip/AppData/Local/Temp/pytest-of-filip/pytest-2/test_memory_manager_initializa0/test_memory.json') = &lt;src.autocura.memory.MemoryManager object at 0x000002471F32F0E0&gt;.memory_path

tests\test_autocura.py:71: AssertionError</failure></testcase><testcase classname="tests.test_autocura" name="test_memory_manager_save" time="0.013" /><testcase classname="tests.test_autocura" name="test_memory_manager_update_from_feedback" time="0.003" /><testcase classname="tests.test_autocura" name="test_feedback_system_initialization" time="0.002"><failure message="AssertionError: assert False&#10; +  where False = exists()&#10; +    where exists = WindowsPath('C:/Users/filip/AppData/Local/Temp/pytest-of-filip/pytest-2/test_feedback_system_initializ0/test_feedback.json').exists&#10; +      where WindowsPath('C:/Users/filip/AppData/Local/Temp/pytest-of-filip/pytest-2/test_feedback_system_initializ0/test_feedback.json') = &lt;src.autocura.feedback.FeedbackSystem object at 0x000002471F32F230&gt;.feedback_path">feedback_system = &lt;src.autocura.feedback.FeedbackSystem object at 0x000002471F32F230&gt;

    def test_feedback_system_initialization(feedback_system):
        """Testa inicialização do FeedbackSystem"""
&gt;       assert feedback_system.feedback_path.exists()
E       AssertionError: assert False
E        +  where False = exists()
E        +    where exists = WindowsPath('C:/Users/filip/AppData/Local/Temp/pytest-of-filip/pytest-2/test_feedback_system_initializ0/test_feedback.json').exists
E        +      where WindowsPath('C:/Users/filip/AppData/Local/Temp/pytest-of-filip/pytest-2/test_feedback_system_initializ0/test_feedback.json') = &lt;src.autocura.feedback.FeedbackSystem object at 0x000002471F32F230&gt;.feedback_path

tests\test_autocura.py:102: AssertionError</failure></testcase><testcase classname="tests.test_autocura" name="test_feedback_system_register" time="0.004" /><testcase classname="tests.test_autocura" name="test_feedback_system_analyze" time="0.005" /><testcase classname="tests.test_autocura" name="test_monitor_initialization" time="0.004"><failure message="AssertionError: assert False&#10; +  where False = exists()&#10; +    where exists = WindowsPath('C:/Users/filip/AppData/Local/Temp/pytest-of-filip/pytest-2/test_monitor_initialization0/test_metrics.json').exists&#10; +      where WindowsPath('C:/Users/filip/AppData/Local/Temp/pytest-of-filip/pytest-2/test_monitor_initialization0/test_metrics.json') = &lt;src.autocura.monitoring.AutocuraMonitor object at 0x000002471F32DFD0&gt;.metrics_path">monitor = &lt;src.autocura.monitoring.AutocuraMonitor object at 0x000002471F32DFD0&gt;

    def test_monitor_initialization(monitor):
        """Testa inicialização do AutocuraMonitor"""
&gt;       assert monitor.metrics_path.exists()
E       AssertionError: assert False
E        +  where False = exists()
E        +    where exists = WindowsPath('C:/Users/filip/AppData/Local/Temp/pytest-of-filip/pytest-2/test_monitor_initialization0/test_metrics.json').exists
E        +      where WindowsPath('C:/Users/filip/AppData/Local/Temp/pytest-of-filip/pytest-2/test_monitor_initialization0/test_metrics.json') = &lt;src.autocura.monitoring.AutocuraMonitor object at 0x000002471F32DFD0&gt;.metrics_path

tests\test_autocura.py:134: AssertionError</failure></testcase><testcase classname="tests.test_autocura" name="test_monitor_record_feedback" time="0.002"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'autocura_feedback', 'autocura_feedback_total', 'autocura_feedback_created'}&quot;">tmp_path = WindowsPath('C:/Users/filip/AppData/Local/Temp/pytest-of-filip/pytest-2/test_monitor_record_feedback0')

    @pytest.fixture
    def monitor(tmp_path):
        metrics_path = tmp_path / "test_metrics.json"
&gt;       return AutocuraMonitor(metrics_path=metrics_path)

tests\test_autocura.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\autocura\monitoring.py:29: in __init__
    self._init_prometheus_metrics()
src\autocura\monitoring.py:37: in _init_prometheus_metrics
    self.feedback_counter = Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(autocura_feedback)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'autocura_feedback', 'autocura_feedback_total', 'autocura_feedback_created'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_autocura" name="test_monitor_update_system_metrics" time="0.002"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'autocura_feedback', 'autocura_feedback_total', 'autocura_feedback_created'}&quot;">tmp_path = WindowsPath('C:/Users/filip/AppData/Local/Temp/pytest-of-filip/pytest-2/test_monitor_update_system_met0')

    @pytest.fixture
    def monitor(tmp_path):
        metrics_path = tmp_path / "test_metrics.json"
&gt;       return AutocuraMonitor(metrics_path=metrics_path)

tests\test_autocura.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\autocura\monitoring.py:29: in __init__
    self._init_prometheus_metrics()
src\autocura\monitoring.py:37: in _init_prometheus_metrics
    self.feedback_counter = Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(autocura_feedback)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'autocura_feedback', 'autocura_feedback_total', 'autocura_feedback_created'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_autocura" name="test_engine_initialization" time="0.003"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'autocura_feedback', 'autocura_feedback_total', 'autocura_feedback_created'}&quot;">tmp_path = WindowsPath('C:/Users/filip/AppData/Local/Temp/pytest-of-filip/pytest-2/test_engine_initialization0')

    @pytest.fixture
    def monitor(tmp_path):
        metrics_path = tmp_path / "test_metrics.json"
&gt;       return AutocuraMonitor(metrics_path=metrics_path)

tests\test_autocura.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\autocura\monitoring.py:29: in __init__
    self._init_prometheus_metrics()
src\autocura\monitoring.py:37: in _init_prometheus_metrics
    self.feedback_counter = Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(autocura_feedback)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'autocura_feedback', 'autocura_feedback_total', 'autocura_feedback_created'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_autocura" name="test_engine_process_feedback" time="0.004"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'autocura_feedback', 'autocura_feedback_total', 'autocura_feedback_created'}&quot;">tmp_path = WindowsPath('C:/Users/filip/AppData/Local/Temp/pytest-of-filip/pytest-2/test_engine_process_feedback0')

    @pytest.fixture
    def monitor(tmp_path):
        metrics_path = tmp_path / "test_metrics.json"
&gt;       return AutocuraMonitor(metrics_path=metrics_path)

tests\test_autocura.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\autocura\monitoring.py:29: in __init__
    self._init_prometheus_metrics()
src\autocura\monitoring.py:37: in _init_prometheus_metrics
    self.feedback_counter = Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(autocura_feedback)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'autocura_feedback', 'autocura_feedback_total', 'autocura_feedback_created'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_autocura" name="test_engine_evolve" time="0.003"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'autocura_feedback', 'autocura_feedback_total', 'autocura_feedback_created'}&quot;">tmp_path = WindowsPath('C:/Users/filip/AppData/Local/Temp/pytest-of-filip/pytest-2/test_engine_evolve0')

    @pytest.fixture
    def monitor(tmp_path):
        metrics_path = tmp_path / "test_metrics.json"
&gt;       return AutocuraMonitor(metrics_path=metrics_path)

tests\test_autocura.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\autocura\monitoring.py:29: in __init__
    self._init_prometheus_metrics()
src\autocura\monitoring.py:37: in _init_prometheus_metrics
    self.feedback_counter = Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(autocura_feedback)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'autocura_feedback', 'autocura_feedback_total', 'autocura_feedback_created'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_autocura" name="test_integration_flow" time="0.005"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'autocura_feedback', 'autocura_feedback_total', 'autocura_feedback_created'}&quot;">tmp_path = WindowsPath('C:/Users/filip/AppData/Local/Temp/pytest-of-filip/pytest-2/test_integration_flow0')

    @pytest.fixture
    def monitor(tmp_path):
        metrics_path = tmp_path / "test_metrics.json"
&gt;       return AutocuraMonitor(metrics_path=metrics_path)

tests\test_autocura.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\autocura\monitoring.py:29: in __init__
    self._init_prometheus_metrics()
src\autocura\monitoring.py:37: in _init_prometheus_metrics
    self.feedback_counter = Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(autocura_feedback)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'autocura_feedback', 'autocura_feedback_total', 'autocura_feedback_created'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_autocura" name="test_error_handling" time="0.004"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'autocura_feedback', 'autocura_feedback_total', 'autocura_feedback_created'}&quot;">tmp_path = WindowsPath('C:/Users/filip/AppData/Local/Temp/pytest-of-filip/pytest-2/test_error_handling0')

    @pytest.fixture
    def monitor(tmp_path):
        metrics_path = tmp_path / "test_metrics.json"
&gt;       return AutocuraMonitor(metrics_path=metrics_path)

tests\test_autocura.py:57: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\autocura\monitoring.py:29: in __init__
    self._init_prometheus_metrics()
src\autocura\monitoring.py:37: in _init_prometheus_metrics
    self.feedback_counter = Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(autocura_feedback)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'autocura_feedback', 'autocura_feedback_total', 'autocura_feedback_created'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_cache" name="test_set_get" time="8.135"><failure message="AssertionError: assert None == 'test_value'&#10; +  where None = get('test_key')&#10; +    where get = &lt;src.cache.redis_cache.CacheDistribuido object at 0x000002471ED0ACF0&gt;.get">cache = &lt;src.cache.redis_cache.CacheDistribuido object at 0x000002471ED0ACF0&gt;

    def test_set_get(cache):
        """Testa operações básicas de set e get."""
        # Teste com string
        cache.set("test_key", "test_value")
&gt;       assert cache.get("test_key") == "test_value"
E       AssertionError: assert None == 'test_value'
E        +  where None = get('test_key')
E        +    where get = &lt;src.cache.redis_cache.CacheDistribuido object at 0x000002471ED0ACF0&gt;.get

tests\test_cache.py:14: AssertionError</failure></testcase><testcase classname="tests.test_cache" name="test_ttl" time="8.131"><failure message="AssertionError: assert None == 'ttl_value'&#10; +  where None = get('ttl_key')&#10; +    where get = &lt;src.cache.redis_cache.CacheDistribuido object at 0x000002471F49D310&gt;.get">cache = &lt;src.cache.redis_cache.CacheDistribuido object at 0x000002471F49D310&gt;

    def test_ttl(cache):
        """Testa o funcionamento do TTL (Time To Live)."""
        cache.set("ttl_key", "ttl_value", ttl=1)
&gt;       assert cache.get("ttl_key") == "ttl_value"
E       AssertionError: assert None == 'ttl_value'
E        +  where None = get('ttl_key')
E        +    where get = &lt;src.cache.redis_cache.CacheDistribuido object at 0x000002471F49D310&gt;.get

tests\test_cache.py:29: AssertionError</failure></testcase><testcase classname="tests.test_cache" name="test_delete" time="8.105"><failure message="AssertionError: assert False&#10; +  where False = exists('delete_key')&#10; +    where exists = &lt;src.cache.redis_cache.CacheDistribuido object at 0x000002471F49DF90&gt;.exists">cache = &lt;src.cache.redis_cache.CacheDistribuido object at 0x000002471F49DF90&gt;

    def test_delete(cache):
        """Testa a operação de delete."""
        cache.set("delete_key", "delete_value")
&gt;       assert cache.exists("delete_key")
E       AssertionError: assert False
E        +  where False = exists('delete_key')
E        +    where exists = &lt;src.cache.redis_cache.CacheDistribuido object at 0x000002471F49DF90&gt;.exists

tests\test_cache.py:36: AssertionError</failure></testcase><testcase classname="tests.test_cache" name="test_exists" time="12.176"><failure message="AssertionError: assert False&#10; +  where False = exists('existent_key')&#10; +    where exists = &lt;src.cache.redis_cache.CacheDistribuido object at 0x000002471F5AF950&gt;.exists">cache = &lt;src.cache.redis_cache.CacheDistribuido object at 0x000002471F5AF950&gt;

    def test_exists(cache):
        """Testa a verificação de existência de chaves."""
        assert not cache.exists("non_existent_key")
        cache.set("existent_key", "value")
&gt;       assert cache.exists("existent_key")
E       AssertionError: assert False
E        +  where False = exists('existent_key')
E        +    where exists = &lt;src.cache.redis_cache.CacheDistribuido object at 0x000002471F5AF950&gt;.exists

tests\test_cache.py:44: AssertionError</failure></testcase><testcase classname="tests.test_cache" name="test_clear" time="12.211"><failure message="AssertionError: assert False&#10; +  where False = exists('key1')&#10; +    where exists = &lt;src.cache.redis_cache.CacheDistribuido object at 0x000002471F5AF490&gt;.exists">cache = &lt;src.cache.redis_cache.CacheDistribuido object at 0x000002471F5AF490&gt;

    def test_clear(cache):
        """Testa a limpeza do cache."""
        cache.set("key1", "value1")
        cache.set("key2", "value2")
&gt;       assert cache.exists("key1")
E       AssertionError: assert False
E        +  where False = exists('key1')
E        +    where exists = &lt;src.cache.redis_cache.CacheDistribuido object at 0x000002471F5AF490&gt;.exists

tests\test_cache.py:50: AssertionError</failure></testcase><testcase classname="tests.test_cache" name="test_error_handling" time="0.005"><failure message="Failed: DID NOT RAISE &lt;class 'Exception'&gt;">cache = &lt;src.cache.redis_cache.CacheDistribuido object at 0x000002472FB0D250&gt;

    def test_error_handling(cache):
        """Testa o tratamento de erros."""
        # Teste com valor inválido
&gt;       with pytest.raises(Exception):
E       Failed: DID NOT RAISE &lt;class 'Exception'&gt;

tests\test_cache.py:59: Failed</failure></testcase><testcase classname="tests.test_camada_integracao" name="test_inicializacao" time="0.003"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_camada_integracao" name="test_inicializar_finalizar" time="0.002"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_camada_integracao" name="test_enviar_metricas" time="0.002"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_camada_integracao" name="test_enviar_metricas_falha" time="0.003"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_camada_integracao" name="test_enviar_diagnostico" time="0.002"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_camada_integracao" name="test_enviar_acao" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_camada_integracao" name="test_obter_metricas" time="0.002"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_camada_integracao" name="test_obter_logs" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_camada_integracao" name="test_verificar_saude_endpoint" time="0.002"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_camada_integracao" name="test_verificar_saude_endpoint_falha" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_camada_integracao" name="test_verificar_saude_todos_endpoints" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_camada_integracao" name="test_retry_mechanism" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_camada_integracao" name="test_timeout" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_criptografia" name="test_inicializacao" time="0.053" /><testcase classname="tests.test_criptografia" name="test_criptografia_simetrica_string" time="0.020" /><testcase classname="tests.test_criptografia" name="test_criptografia_simetrica_dict" time="0.027" /><testcase classname="tests.test_criptografia" name="test_criptografia_assimetrica" time="0.015" /><testcase classname="tests.test_criptografia" name="test_exportar_importar_chave_publica" time="0.077" /><testcase classname="tests.test_criptografia" name="test_rotacao_chaves" time="0.055" /><testcase classname="tests.test_criptografia" name="test_erro_criptografia_invalida" time="0.040" /><testcase classname="tests.test_deteccao_anomalias" name="test_inicializacao" time="0.001" /><testcase classname="tests.test_deteccao_anomalias" name="test_registrar_metricas" time="0.001" /><testcase classname="tests.test_deteccao_anomalias" name="test_janela_metricas" time="0.001" /><testcase classname="tests.test_deteccao_anomalias" name="test_treinar_modelo" time="0.099" /><testcase classname="tests.test_deteccao_anomalias" name="test_detectar_anomalias" time="0.103" /><testcase classname="tests.test_deteccao_anomalias" name="test_obter_estatisticas" time="0.002"><failure message="assert 0 &gt; 0">detector = &lt;src.seguranca.deteccao_anomalias.DetectorAnomalias object at 0x000002472FB0D010&gt;

    def test_obter_estatisticas(detector):
        """Testa a obtenção de estatísticas."""
        # Registra algumas anomalias
        for i in range(3):
            metricas = MetricasSeguranca(
                cpu_usage=90.0,
                memoria_usage=85.0,
                latencia=400.0,
                requests_por_segundo=800.0,
                erro_rate=0.3,
                auth_failures=5,
                timestamp=datetime.now()
            )
            detector.registrar_metricas(metricas)
    
        # Treina e detecta
        detector.treinar_modelo()
        detector.detectar_anomalias()
    
        # Obtém estatísticas
        stats = detector.obter_estatisticas()
&gt;       assert stats["total_anomalias"] &gt; 0
E       assert 0 &gt; 0

tests\test_deteccao_anomalias.py:132: AssertionError</failure></testcase><testcase classname="tests.test_deteccao_anomalias" name="test_limpar_historico" time="0.002"><failure message="assert 0 == 1&#10; +  where 0 = len([])&#10; +    where [] = &lt;src.seguranca.deteccao_anomalias.DetectorAnomalias object at 0x000002471F3FEAD0&gt;.anomalias_detectadas">detector = &lt;src.seguranca.deteccao_anomalias.DetectorAnomalias object at 0x000002471F3FEAD0&gt;

    def test_limpar_historico(detector):
        """Testa a limpeza do histórico de anomalias."""
        # Registra anomalias antigas e recentes
        agora = datetime.now()
    
        # Anomalia antiga
        metricas_antiga = MetricasSeguranca(
            cpu_usage=90.0,
            memoria_usage=85.0,
            latencia=400.0,
            requests_por_segundo=800.0,
            erro_rate=0.3,
            auth_failures=5,
            timestamp=agora - timedelta(days=10)
        )
        detector.registrar_metricas(metricas_antiga)
    
        # Anomalia recente
        metricas_recente = MetricasSeguranca(
            cpu_usage=90.0,
            memoria_usage=85.0,
            latencia=400.0,
            requests_por_segundo=800.0,
            erro_rate=0.3,
            auth_failures=5,
            timestamp=agora
        )
        detector.registrar_metricas(metricas_recente)
    
        # Treina e detecta
        detector.treinar_modelo()
        detector.detectar_anomalias()
    
        # Limpa histórico
        detector.limpar_historico(dias=7)
    
        # Verifica se manteve apenas a anomalia recente
&gt;       assert len(detector.anomalias_detectadas) == 1
E       assert 0 == 1
E        +  where 0 = len([])
E        +    where [] = &lt;src.seguranca.deteccao_anomalias.DetectorAnomalias object at 0x000002471F3FEAD0&gt;.anomalias_detectadas

tests\test_deteccao_anomalias.py:173: AssertionError</failure></testcase><testcase classname="tests.test_diagnostico_avancado.TestDiagnosticoAvancado" name="test_calcular_confianca_predicao" time="0.004" /><testcase classname="tests.test_diagnostico_avancado.TestDiagnosticoAvancado" name="test_calcular_correlacao" time="0.004" /><testcase classname="tests.test_diagnostico_avancado.TestDiagnosticoAvancado" name="test_calcular_lag" time="0.013"><failure message="AssertionError: 0 != 1">self = &lt;tests.test_diagnostico_avancado.TestDiagnosticoAvancado testMethod=test_calcular_lag&gt;

    def test_calcular_lag(self):
        """Testa cálculo de lag"""
        serie1 = [1, 2, 3, 4, 5]
        serie2 = [0, 1, 2, 3, 4]
    
        lag = self.diagnostico._calcular_lag(serie1, serie2)
&gt;       self.assertEqual(lag, 1)
E       AssertionError: 0 != 1

tests\test_diagnostico_avancado.py:157: AssertionError</failure></testcase><testcase classname="tests.test_diagnostico_avancado.TestDiagnosticoAvancado" name="test_calcular_tendencia" time="0.004" /><testcase classname="tests.test_diagnostico_avancado.TestDiagnosticoAvancado" name="test_carregar_config" time="0.003" /><testcase classname="tests.test_diagnostico_avancado.TestDiagnosticoAvancado" name="test_coletar_dados_historicos" time="0.006" /><testcase classname="tests.test_diagnostico_avancado.TestDiagnosticoAvancado" name="test_criar_config_padrao" time="0.005" /><testcase classname="tests.test_diagnostico_avancado.TestDiagnosticoAvancado" name="test_extrair_features" time="0.004" /><testcase classname="tests.test_diagnostico_avancado.TestDiagnosticoAvancado" name="test_inicializacao" time="0.004" /><testcase classname="tests.test_diagnostico_avancado.TestDiagnosticoAvancado" name="test_iniciar_parar" time="1.006" /><testcase classname="tests.test_diagnostico_avancado.TestDiagnosticoAvancado" name="test_obter_resultados" time="0.006" /><testcase classname="tests.test_diagnostico_avancado.TestDiagnosticoAvancado" name="test_predizer_valores" time="0.006"><failure message="AssertionError: 305.0 != 6.0 within 7 places (299.0 difference)">self = &lt;tests.test_diagnostico_avancado.TestDiagnosticoAvancado testMethod=test_predizer_valores&gt;

    def test_predizer_valores(self):
        """Testa predição de valores"""
        valores = [1, 2, 3, 4, 5]
        tendencia = 1.0
        horizonte = 300
    
        predicoes = self.diagnostico._predizer_valores(valores, tendencia, horizonte)
        self.assertEqual(len(predicoes), 1)  # horizonte/intervalo_predicao
&gt;       self.assertAlmostEqual(predicoes[0], 6.0)
E       AssertionError: 305.0 != 6.0 within 7 places (299.0 difference)

tests\test_diagnostico_avancado.py:174: AssertionError</failure></testcase><testcase classname="tests.test_diagnostico_avancado.TestDiagnosticoAvancado" name="test_registrar_resultados" time="0.007" /><testcase classname="tests.test_exemplo.TestProcessadorDados" name="test_processar_dados_sucesso" time="0.001" /><testcase classname="tests.test_exemplo.TestProcessadorDados" name="test_processar_dados_invalidos" time="0.001" /><testcase classname="tests.test_exemplo.TestIntegracaoAPI" name="test_obter_dados" time="0.003"><failure message="NameError: name 'requests' is not defined">self = &lt;tests.test_exemplo.TestIntegracaoAPI object at 0x000002471E25A350&gt;
config_teste = {'api_url': 'http://localhost:8000', 'retry_count': 3, 'timeout': 30}
mock_api = &lt;MagicMock name='Session' id='2504490692832'&gt;

    def test_obter_dados(self, config_teste: Dict[str, Any], mock_api: Mock) -&gt; None:
        """
        Testa a obtenção de dados da API.
    
        Args:
            config_teste: Fixture com configurações
            mock_api: Fixture com mock da API
        """
        # Arrange
        mock_response = Mock()
        mock_response.json.return_value = {"status": "success", "data": []}
        mock_api.return_value.get.return_value = mock_response
    
        # Act
&gt;       cliente = APIClient(config_teste)

tests\test_exemplo.py:104: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;tests.test_exemplo.APIClient object at 0x000002471F473620&gt;
config = {'api_url': 'http://localhost:8000', 'retry_count': 3, 'timeout': 30}

    def __init__(self, config: Dict[str, Any]):
        """
        Inicializa o cliente.
    
        Args:
            config: Configurações do cliente
        """
        self.config = config
&gt;       self.session = requests.Session()
E       NameError: name 'requests' is not defined

tests\test_exemplo.py:167: NameError</failure></testcase><testcase classname="tests.test_exemplo.TestIntegracaoAPI" name="test_timeout_api" time="0.002"><failure message="NameError: name 'requests' is not defined">self = &lt;tests.test_exemplo.TestIntegracaoAPI object at 0x000002471E25A490&gt;
config_teste = {'api_url': 'http://localhost:8000', 'retry_count': 3, 'timeout': 30}
mock_api = &lt;MagicMock name='Session' id='2504490690816'&gt;

    @pytest.mark.timeout(5)  # Timeout de 5 segundos
    def test_timeout_api(self, config_teste: Dict[str, Any], mock_api: Mock) -&gt; None:
        """
        Testa o timeout da API.
    
        Args:
            config_teste: Fixture com configurações
            mock_api: Fixture com mock da API
        """
        # Arrange
        mock_api.return_value.get.side_effect = TimeoutError()
    
        # Act &amp; Assert
&gt;       cliente = APIClient(config_teste)

tests\test_exemplo.py:126: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;tests.test_exemplo.APIClient object at 0x000002471E259810&gt;
config = {'api_url': 'http://localhost:8000', 'retry_count': 3, 'timeout': 30}

    def __init__(self, config: Dict[str, Any]):
        """
        Inicializa o cliente.
    
        Args:
            config: Configurações do cliente
        """
        self.config = config
&gt;       self.session = requests.Session()
E       NameError: name 'requests' is not defined

tests\test_exemplo.py:167: NameError</failure></testcase><testcase classname="tests.test_fluxo_autonomia" name="test_transicao_autonomia_nivel_1_para_2" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_fluxo_autonomia" name="test_manter_autonomia_nivel_1_por_baixo_desempenho" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_fluxo_autonomia" name="test_reducao_autonomia_por_violacao_etica" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_fluxo_autonomia" name="test_reducao_autonomia_por_incidente_critico" time="0.000"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_fluxo_autonomia" name="test_estabilidade_autonomia_nivel_2" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_fluxo_autonomia" name="test_geracao_acoes_por_nivel_autonomia" time="0.000"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_fluxo_autonomia" name="test_validacao_etica_por_nivel_autonomia" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_fluxo_autonomia" name="test_salvaguardas_por_nivel_autonomia" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_gerador_acoes" name="test_gerar_acao_manutencao" time="0.002"><failure message="AttributeError: 'dict' object has no attribute 'anomalia_detectada'">def test_gerar_acao_manutencao():
        """Testa a geração de ação de manutenção."""
        gerador = GeradorAcoes()
    
        # Simular contexto
        contexto = {
            "tipo": "manutencao",
            "prioridade": "alta",
            "descricao": "Corrigir bug crítico",
            "componente": "api",
            "impacto": "alto"
        }
    
        # Gerar ação
&gt;       acao = gerador.gerar_acao(contexto)

tests\test_gerador_acoes.py:56: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;src.acoes.gerador_acoes.GeradorAcoes object at 0x000002471F32E510&gt;
diagnostico = {'componente': 'api', 'descricao': 'Corrigir bug crítico', 'impacto': 'alto', 'prioridade': 'alta', ...}

    def gerar_acao(self, diagnostico: Diagnostico) -&gt; Optional[Acao]:
        """Gera uma ação emergente baseada no diagnóstico."""
&gt;       if not diagnostico.anomalia_detectada:
E       AttributeError: 'dict' object has no attribute 'anomalia_detectada'

src\acoes\gerador_acoes.py:107: AttributeError</failure></testcase><testcase classname="tests.test_gerador_acoes" name="test_gerar_acao_hotfix" time="0.002"><failure message="AttributeError: 'dict' object has no attribute 'anomalia_detectada'">def test_gerar_acao_hotfix():
        """Testa a geração de ação de hotfix."""
        gerador = GeradorAcoes()
    
        # Simular contexto
        contexto = {
            "tipo": "hotfix",
            "prioridade": "critica",
            "descricao": "Corrigir vulnerabilidade de segurança",
            "componente": "autenticacao",
            "impacto": "critico"
        }
    
        # Gerar ação
&gt;       acao = gerador.gerar_acao(contexto)

tests\test_gerador_acoes.py:79: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;src.acoes.gerador_acoes.GeradorAcoes object at 0x000002471F338E10&gt;
diagnostico = {'componente': 'autenticacao', 'descricao': 'Corrigir vulnerabilidade de segurança', 'impacto': 'critico', 'prioridade': 'critica', ...}

    def gerar_acao(self, diagnostico: Diagnostico) -&gt; Optional[Acao]:
        """Gera uma ação emergente baseada no diagnóstico."""
&gt;       if not diagnostico.anomalia_detectada:
E       AttributeError: 'dict' object has no attribute 'anomalia_detectada'

src\acoes\gerador_acoes.py:107: AttributeError</failure></testcase><testcase classname="tests.test_gerador_acoes" name="test_gerar_acao_refatoracao" time="0.002"><failure message="AttributeError: 'dict' object has no attribute 'anomalia_detectada'">def test_gerar_acao_refatoracao():
        """Testa a geração de ação de refatoração."""
        gerador = GeradorAcoes()
    
        # Simular contexto
        contexto = {
            "tipo": "refatoracao",
            "prioridade": "media",
            "descricao": "Melhorar estrutura do código",
            "componente": "core",
            "impacto": "medio"
        }
    
        # Gerar ação
&gt;       acao = gerador.gerar_acao(contexto)

tests\test_gerador_acoes.py:102: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;src.acoes.gerador_acoes.GeradorAcoes object at 0x000002471F339E50&gt;
diagnostico = {'componente': 'core', 'descricao': 'Melhorar estrutura do código', 'impacto': 'medio', 'prioridade': 'media', ...}

    def gerar_acao(self, diagnostico: Diagnostico) -&gt; Optional[Acao]:
        """Gera uma ação emergente baseada no diagnóstico."""
&gt;       if not diagnostico.anomalia_detectada:
E       AttributeError: 'dict' object has no attribute 'anomalia_detectada'

src\acoes\gerador_acoes.py:107: AttributeError</failure></testcase><testcase classname="tests.test_gerador_acoes" name="test_gerar_acao_redesign" time="0.002"><failure message="AttributeError: 'dict' object has no attribute 'anomalia_detectada'">def test_gerar_acao_redesign():
        """Testa a geração de ação de redesign."""
        gerador = GeradorAcoes()
    
        # Simular contexto
        contexto = {
            "tipo": "redesign",
            "prioridade": "baixa",
            "descricao": "Redesenhar interface do usuário",
            "componente": "frontend",
            "impacto": "baixo"
        }
    
        # Gerar ação
&gt;       acao = gerador.gerar_acao(contexto)

tests\test_gerador_acoes.py:125: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;src.acoes.gerador_acoes.GeradorAcoes object at 0x000002471E5DFBB0&gt;
diagnostico = {'componente': 'frontend', 'descricao': 'Redesenhar interface do usuário', 'impacto': 'baixo', 'prioridade': 'baixa', ...}

    def gerar_acao(self, diagnostico: Diagnostico) -&gt; Optional[Acao]:
        """Gera uma ação emergente baseada no diagnóstico."""
&gt;       if not diagnostico.anomalia_detectada:
E       AttributeError: 'dict' object has no attribute 'anomalia_detectada'

src\acoes\gerador_acoes.py:107: AttributeError</failure></testcase><testcase classname="tests.test_gerador_acoes" name="test_verificar_dependencias" time="0.002"><failure message="AttributeError: 'GeradorAcoes' object has no attribute 'verificar_dependencias'">def test_verificar_dependencias():
        """Testa a verificação de dependências."""
        gerador = GeradorAcoes()
    
        # Simular ação com dependências
        acao = {
            "id": "test_1",
            "tipo": "manutencao",
            "dependencias": [
                {"id": "dep_1", "status": "concluida"},
                {"id": "dep_2", "status": "concluida"}
            ]
        }
    
        # Verificar dependências
&gt;       resultado = gerador.verificar_dependencias(acao)
E       AttributeError: 'GeradorAcoes' object has no attribute 'verificar_dependencias'

tests\test_gerador_acoes.py:149: AttributeError</failure></testcase><testcase classname="tests.test_gerador_acoes" name="test_verificar_dependencias_pendentes" time="0.002"><failure message="AttributeError: 'GeradorAcoes' object has no attribute 'verificar_dependencias'">def test_verificar_dependencias_pendentes():
        """Testa a verificação de dependências pendentes."""
        gerador = GeradorAcoes()
    
        # Simular ação com dependências pendentes
        acao = {
            "id": "test_1",
            "tipo": "manutencao",
            "dependencias": [
                {"id": "dep_1", "status": "concluida"},
                {"id": "dep_2", "status": "pendente"}
            ]
        }
    
        # Verificar dependências
&gt;       resultado = gerador.verificar_dependencias(acao)
E       AttributeError: 'GeradorAcoes' object has no attribute 'verificar_dependencias'

tests\test_gerador_acoes.py:169: AttributeError</failure></testcase><testcase classname="tests.test_gerador_acoes" name="test_executar_acao_manutencao" time="0.003"><failure message="AttributeError: 'GeradorAcoes' object has no attribute 'executar_acao'">def test_executar_acao_manutencao():
        """Testa a execução de ação de manutenção."""
        gerador = GeradorAcoes()
    
        # Simular ação
        acao = {
            "id": "test_1",
            "tipo": "manutencao",
            "status": "pendente",
            "componente": "api"
        }
    
        # Executar ação
&gt;       resultado = gerador.executar_acao(acao)
E       AttributeError: 'GeradorAcoes' object has no attribute 'executar_acao'

tests\test_gerador_acoes.py:187: AttributeError</failure></testcase><testcase classname="tests.test_gerador_acoes" name="test_executar_acao_hotfix" time="0.002"><failure message="AttributeError: 'GeradorAcoes' object has no attribute 'executar_acao'">def test_executar_acao_hotfix():
        """Testa a execução de ação de hotfix."""
        gerador = GeradorAcoes()
    
        # Simular ação
        acao = {
            "id": "test_1",
            "tipo": "hotfix",
            "status": "pendente",
            "componente": "autenticacao"
        }
    
        # Executar ação
&gt;       resultado = gerador.executar_acao(acao)
E       AttributeError: 'GeradorAcoes' object has no attribute 'executar_acao'

tests\test_gerador_acoes.py:207: AttributeError</failure></testcase><testcase classname="tests.test_gerador_acoes" name="test_executar_acao_refatoracao" time="0.003"><failure message="AttributeError: 'GeradorAcoes' object has no attribute 'executar_acao'">def test_executar_acao_refatoracao():
        """Testa a execução de ação de refatoração."""
        gerador = GeradorAcoes()
    
        # Simular ação
        acao = {
            "id": "test_1",
            "tipo": "refatoracao",
            "status": "pendente",
            "componente": "core"
        }
    
        # Executar ação
&gt;       resultado = gerador.executar_acao(acao)
E       AttributeError: 'GeradorAcoes' object has no attribute 'executar_acao'

tests\test_gerador_acoes.py:227: AttributeError</failure></testcase><testcase classname="tests.test_gerador_acoes" name="test_executar_acao_redesign" time="0.002"><failure message="AttributeError: 'GeradorAcoes' object has no attribute 'executar_acao'">def test_executar_acao_redesign():
        """Testa a execução de ação de redesign."""
        gerador = GeradorAcoes()
    
        # Simular ação
        acao = {
            "id": "test_1",
            "tipo": "redesign",
            "status": "pendente",
            "componente": "frontend"
        }
    
        # Executar ação
&gt;       resultado = gerador.executar_acao(acao)
E       AttributeError: 'GeradorAcoes' object has no attribute 'executar_acao'

tests\test_gerador_acoes.py:247: AttributeError</failure></testcase><testcase classname="tests.test_gerador_acoes" name="test_obter_estatisticas" time="0.002"><failure message="AttributeError: 'GeradorAcoes' object has no attribute 'obter_estatisticas'. Did you mean: 'obter_estatisticas_acoes'?">def test_obter_estatisticas():
        """Testa a obtenção de estatísticas."""
        gerador = GeradorAcoes()
    
        # Simular ações
        acoes = [
            {"id": "test_1", "status": "concluida"},
            {"id": "test_2", "status": "pendente"},
            {"id": "test_3", "status": "concluida"}
        ]
    
        # Obter estatísticas
&gt;       estatisticas = gerador.obter_estatisticas(acoes)
E       AttributeError: 'GeradorAcoes' object has no attribute 'obter_estatisticas'. Did you mean: 'obter_estatisticas_acoes'?

tests\test_gerador_acoes.py:266: AttributeError</failure></testcase><testcase classname="tests.test_gerador_acoes" name="test_obter_acoes_pendentes" time="0.004" /><testcase classname="tests.test_gerador_acoes" name="test_obter_acoes_concluidas" time="0.002"><failure message="AttributeError: 'GeradorAcoes' object has no attribute 'obter_acoes_concluidas'">def test_obter_acoes_concluidas():
        """Testa a obtenção de ações concluídas."""
        gerador = GeradorAcoes()
    
        # Simular ações
        acoes = [
            {"id": "test_1", "status": "concluida"},
            {"id": "test_2", "status": "pendente"},
            {"id": "test_3", "status": "concluida"}
        ]
    
        # Obter ações concluídas
&gt;       concluidas = gerador.obter_acoes_concluidas(acoes)
E       AttributeError: 'GeradorAcoes' object has no attribute 'obter_acoes_concluidas'

tests\test_gerador_acoes.py:303: AttributeError</failure></testcase><testcase classname="tests.test_gerador_acoes" name="test_obter_acoes_por_tipo" time="0.002"><failure message="AttributeError: 'GeradorAcoes' object has no attribute 'obter_acoes_por_tipo'">def test_obter_acoes_por_tipo():
        """Testa a obtenção de ações por tipo."""
        gerador = GeradorAcoes()
    
        # Simular ações
        acoes = [
            {"id": "test_1", "tipo": "manutencao"},
            {"id": "test_2", "tipo": "hotfix"},
            {"id": "test_3", "tipo": "manutencao"}
        ]
    
        # Obter ações por tipo
&gt;       manutencoes = gerador.obter_acoes_por_tipo(acoes, "manutencao")
E       AttributeError: 'GeradorAcoes' object has no attribute 'obter_acoes_por_tipo'

tests\test_gerador_acoes.py:322: AttributeError</failure></testcase><testcase classname="tests.test_gerador_acoes" name="test_inicializacao" time="0.002" /><testcase classname="tests.test_gerador_acoes" name="test_gerar_acao_cpu" time="0.003" /><testcase classname="tests.test_gerador_acoes" name="test_gerar_acao_memoria" time="0.002" /><testcase classname="tests.test_gerador_acoes" name="test_gerar_acao_sem_anomalia" time="0.002" /><testcase classname="tests.test_gerador_acoes" name="test_gerar_acao_padrao_desconhecido" time="0.002" /><testcase classname="tests.test_gerador_acoes" name="test_atualizar_status_acao" time="0.002" /><testcase classname="tests.test_gerador_acoes" name="test_atualizar_status_acao_inexistente" time="0.001" /><testcase classname="tests.test_gerador_acoes" name="test_obter_historico_acoes" time="0.002" /><testcase classname="tests.test_gerador_acoes" name="test_obter_estatisticas_acoes" time="0.003" /><testcase classname="tests.test_gerador_acoes" name="test_limpar_historico" time="0.002" /><testcase classname="tests.test_gerenciador_config" name="test_inicializacao" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_gerenciador_config" name="test_criar_configuracao" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'configuracoes_criadas_created', 'configuracoes_criadas_total', 'configuracoes_criadas'}&quot;">config = {'base_dir': 'test_config'}

    @pytest.fixture
    def gerenciador(config):
        """Instância do gerenciador de configuração."""
&gt;       return GerenciadorConfig(config)

tests\test_gerenciador_config.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\config\gerenciador_config.py:49: in __init__
    "configuracoes_criadas": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(configuracoes_criadas)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'configuracoes_criadas_created', 'configuracoes_criadas_total', 'configuracoes_criadas'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_config" name="test_criar_configuracao_tipo_invalido" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'configuracoes_criadas_created', 'configuracoes_criadas_total', 'configuracoes_criadas'}&quot;">config = {'base_dir': 'test_config'}

    @pytest.fixture
    def gerenciador(config):
        """Instância do gerenciador de configuração."""
&gt;       return GerenciadorConfig(config)

tests\test_gerenciador_config.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\config\gerenciador_config.py:49: in __init__
    "configuracoes_criadas": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(configuracoes_criadas)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'configuracoes_criadas_created', 'configuracoes_criadas_total', 'configuracoes_criadas'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_config" name="test_atualizar_configuracao" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'configuracoes_criadas_created', 'configuracoes_criadas_total', 'configuracoes_criadas'}&quot;">config = {'base_dir': 'test_config'}

    @pytest.fixture
    def gerenciador(config):
        """Instância do gerenciador de configuração."""
&gt;       return GerenciadorConfig(config)

tests\test_gerenciador_config.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\config\gerenciador_config.py:49: in __init__
    "configuracoes_criadas": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(configuracoes_criadas)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'configuracoes_criadas_created', 'configuracoes_criadas_total', 'configuracoes_criadas'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_config" name="test_atualizar_configuracao_inexistente" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'configuracoes_criadas_created', 'configuracoes_criadas_total', 'configuracoes_criadas'}&quot;">config = {'base_dir': 'test_config'}

    @pytest.fixture
    def gerenciador(config):
        """Instância do gerenciador de configuração."""
&gt;       return GerenciadorConfig(config)

tests\test_gerenciador_config.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\config\gerenciador_config.py:49: in __init__
    "configuracoes_criadas": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(configuracoes_criadas)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'configuracoes_criadas_created', 'configuracoes_criadas_total', 'configuracoes_criadas'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_config" name="test_obter_configuracao" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'configuracoes_criadas_created', 'configuracoes_criadas_total', 'configuracoes_criadas'}&quot;">config = {'base_dir': 'test_config'}

    @pytest.fixture
    def gerenciador(config):
        """Instância do gerenciador de configuração."""
&gt;       return GerenciadorConfig(config)

tests\test_gerenciador_config.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\config\gerenciador_config.py:49: in __init__
    "configuracoes_criadas": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(configuracoes_criadas)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'configuracoes_criadas_created', 'configuracoes_criadas_total', 'configuracoes_criadas'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_config" name="test_buscar_configuracoes" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'configuracoes_criadas_created', 'configuracoes_criadas_total', 'configuracoes_criadas'}&quot;">config = {'base_dir': 'test_config'}

    @pytest.fixture
    def gerenciador(config):
        """Instância do gerenciador de configuração."""
&gt;       return GerenciadorConfig(config)

tests\test_gerenciador_config.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\config\gerenciador_config.py:49: in __init__
    "configuracoes_criadas": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(configuracoes_criadas)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'configuracoes_criadas_created', 'configuracoes_criadas_total', 'configuracoes_criadas'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_config" name="test_obter_historico" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'configuracoes_criadas_created', 'configuracoes_criadas_total', 'configuracoes_criadas'}&quot;">config = {'base_dir': 'test_config'}

    @pytest.fixture
    def gerenciador(config):
        """Instância do gerenciador de configuração."""
&gt;       return GerenciadorConfig(config)

tests\test_gerenciador_config.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\config\gerenciador_config.py:49: in __init__
    "configuracoes_criadas": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(configuracoes_criadas)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'configuracoes_criadas_created', 'configuracoes_criadas_total', 'configuracoes_criadas'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_config" name="test_obter_estatisticas" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'configuracoes_criadas_created', 'configuracoes_criadas_total', 'configuracoes_criadas'}&quot;">config = {'base_dir': 'test_config'}

    @pytest.fixture
    def gerenciador(config):
        """Instância do gerenciador de configuração."""
&gt;       return GerenciadorConfig(config)

tests\test_gerenciador_config.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\config\gerenciador_config.py:49: in __init__
    "configuracoes_criadas": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(configuracoes_criadas)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'configuracoes_criadas_created', 'configuracoes_criadas_total', 'configuracoes_criadas'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_config" name="test_carregar_configuracoes" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'configuracoes_criadas_created', 'configuracoes_criadas_total', 'configuracoes_criadas'}&quot;">config = {'base_dir': 'test_config'}

    @pytest.fixture
    def gerenciador(config):
        """Instância do gerenciador de configuração."""
&gt;       return GerenciadorConfig(config)

tests\test_gerenciador_config.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\config\gerenciador_config.py:49: in __init__
    "configuracoes_criadas": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(configuracoes_criadas)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'configuracoes_criadas_created', 'configuracoes_criadas_total', 'configuracoes_criadas'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_config" name="test_limpeza" time="0.004"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'configuracoes_criadas_created', 'configuracoes_criadas_total', 'configuracoes_criadas'}&quot;">config = {'base_dir': 'test_config'}

    @pytest.fixture
    def gerenciador(config):
        """Instância do gerenciador de configuração."""
&gt;       return GerenciadorConfig(config)

tests\test_gerenciador_config.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\config\gerenciador_config.py:49: in __init__
    "configuracoes_criadas": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(configuracoes_criadas)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'configuracoes_criadas_created', 'configuracoes_criadas_total', 'configuracoes_criadas'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_eventos" name="test_inicializacao" time="0.004"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_gerenciador_eventos" name="test_registrar_evento" time="0.002"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_criados_total', 'eventos_criados', 'eventos_criados_created'}&quot;">config = {'max_eventos': 1000, 'ttl_padrao': 86400}

    @pytest.fixture
    def gerenciador(config):
        """Fornece uma instância do gerenciador de eventos para testes."""
&gt;       return GerenciadorEventos(config)

tests\test_gerenciador_eventos.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\eventos\gerenciador_eventos.py:41: in __init__
    "eventos_criados": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(eventos_criados)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_criados_total', 'eventos_criados', 'eventos_criados_created'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_eventos" name="test_registrar_evento_tipo_invalido" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_criados_total', 'eventos_criados', 'eventos_criados_created'}&quot;">config = {'max_eventos': 1000, 'ttl_padrao': 86400}

    @pytest.fixture
    def gerenciador(config):
        """Fornece uma instância do gerenciador de eventos para testes."""
&gt;       return GerenciadorEventos(config)

tests\test_gerenciador_eventos.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\eventos\gerenciador_eventos.py:41: in __init__
    "eventos_criados": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(eventos_criados)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_criados_total', 'eventos_criados', 'eventos_criados_created'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_eventos" name="test_processar_evento" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_criados_total', 'eventos_criados', 'eventos_criados_created'}&quot;">config = {'max_eventos': 1000, 'ttl_padrao': 86400}

    @pytest.fixture
    def gerenciador(config):
        """Fornece uma instância do gerenciador de eventos para testes."""
&gt;       return GerenciadorEventos(config)

tests\test_gerenciador_eventos.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\eventos\gerenciador_eventos.py:41: in __init__
    "eventos_criados": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(eventos_criados)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_criados_total', 'eventos_criados', 'eventos_criados_created'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_eventos" name="test_processar_evento_sem_handler" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_criados_total', 'eventos_criados', 'eventos_criados_created'}&quot;">config = {'max_eventos': 1000, 'ttl_padrao': 86400}

    @pytest.fixture
    def gerenciador(config):
        """Fornece uma instância do gerenciador de eventos para testes."""
&gt;       return GerenciadorEventos(config)

tests\test_gerenciador_eventos.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\eventos\gerenciador_eventos.py:41: in __init__
    "eventos_criados": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(eventos_criados)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_criados_total', 'eventos_criados', 'eventos_criados_created'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_eventos" name="test_processar_evento_erro_handler" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_criados_total', 'eventos_criados', 'eventos_criados_created'}&quot;">config = {'max_eventos': 1000, 'ttl_padrao': 86400}

    @pytest.fixture
    def gerenciador(config):
        """Fornece uma instância do gerenciador de eventos para testes."""
&gt;       return GerenciadorEventos(config)

tests\test_gerenciador_eventos.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\eventos\gerenciador_eventos.py:41: in __init__
    "eventos_criados": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(eventos_criados)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_criados_total', 'eventos_criados', 'eventos_criados_created'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_eventos" name="test_obter_evento" time="0.002"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_criados_total', 'eventos_criados', 'eventos_criados_created'}&quot;">config = {'max_eventos': 1000, 'ttl_padrao': 86400}

    @pytest.fixture
    def gerenciador(config):
        """Fornece uma instância do gerenciador de eventos para testes."""
&gt;       return GerenciadorEventos(config)

tests\test_gerenciador_eventos.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\eventos\gerenciador_eventos.py:41: in __init__
    "eventos_criados": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(eventos_criados)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_criados_total', 'eventos_criados', 'eventos_criados_created'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_eventos" name="test_buscar_eventos" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_criados_total', 'eventos_criados', 'eventos_criados_created'}&quot;">config = {'max_eventos': 1000, 'ttl_padrao': 86400}

    @pytest.fixture
    def gerenciador(config):
        """Fornece uma instância do gerenciador de eventos para testes."""
&gt;       return GerenciadorEventos(config)

tests\test_gerenciador_eventos.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\eventos\gerenciador_eventos.py:41: in __init__
    "eventos_criados": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(eventos_criados)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_criados_total', 'eventos_criados', 'eventos_criados_created'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_eventos" name="test_limpar_eventos_antigos" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_criados_total', 'eventos_criados', 'eventos_criados_created'}&quot;">config = {'max_eventos': 1000, 'ttl_padrao': 86400}

    @pytest.fixture
    def gerenciador(config):
        """Fornece uma instância do gerenciador de eventos para testes."""
&gt;       return GerenciadorEventos(config)

tests\test_gerenciador_eventos.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\eventos\gerenciador_eventos.py:41: in __init__
    "eventos_criados": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(eventos_criados)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_criados_total', 'eventos_criados', 'eventos_criados_created'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_eventos" name="test_obter_estatisticas" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_criados_total', 'eventos_criados', 'eventos_criados_created'}&quot;">config = {'max_eventos': 1000, 'ttl_padrao': 86400}

    @pytest.fixture
    def gerenciador(config):
        """Fornece uma instância do gerenciador de eventos para testes."""
&gt;       return GerenciadorEventos(config)

tests\test_gerenciador_eventos.py:20: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\eventos\gerenciador_eventos.py:41: in __init__
    "eventos_criados": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(eventos_criados)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_criados_total', 'eventos_criados', 'eventos_criados_created'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_logs" name="test_inicializacao" time="0.003"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_gerenciador_logs" name="test_registrar_log" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'logs_criados', 'logs_criados_total', 'logs_criados_created'}&quot;">config = {'base_dir': 'test_logs'}

    @pytest.fixture
    def gerenciador(config):
        """Instância do gerenciador de logs."""
&gt;       return GerenciadorLogs(config)

tests\test_gerenciador_logs.py:19: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\logs\gerenciador_logs.py:63: in __init__
    "logs_criados": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(logs_criados)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'logs_criados', 'logs_criados_total', 'logs_criados_created'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_logs" name="test_registrar_log_nivel_invalido" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'logs_criados', 'logs_criados_total', 'logs_criados_created'}&quot;">config = {'base_dir': 'test_logs'}

    @pytest.fixture
    def gerenciador(config):
        """Instância do gerenciador de logs."""
&gt;       return GerenciadorLogs(config)

tests\test_gerenciador_logs.py:19: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\logs\gerenciador_logs.py:63: in __init__
    "logs_criados": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(logs_criados)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'logs_criados', 'logs_criados_total', 'logs_criados_created'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_logs" name="test_obter_log" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'logs_criados', 'logs_criados_total', 'logs_criados_created'}&quot;">config = {'base_dir': 'test_logs'}

    @pytest.fixture
    def gerenciador(config):
        """Instância do gerenciador de logs."""
&gt;       return GerenciadorLogs(config)

tests\test_gerenciador_logs.py:19: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\logs\gerenciador_logs.py:63: in __init__
    "logs_criados": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(logs_criados)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'logs_criados', 'logs_criados_total', 'logs_criados_created'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_logs" name="test_buscar_logs" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'logs_criados', 'logs_criados_total', 'logs_criados_created'}&quot;">config = {'base_dir': 'test_logs'}

    @pytest.fixture
    def gerenciador(config):
        """Instância do gerenciador de logs."""
&gt;       return GerenciadorLogs(config)

tests\test_gerenciador_logs.py:19: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\logs\gerenciador_logs.py:63: in __init__
    "logs_criados": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(logs_criados)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'logs_criados', 'logs_criados_total', 'logs_criados_created'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_logs" name="test_limpar_logs_antigos" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'logs_criados', 'logs_criados_total', 'logs_criados_created'}&quot;">config = {'base_dir': 'test_logs'}

    @pytest.fixture
    def gerenciador(config):
        """Instância do gerenciador de logs."""
&gt;       return GerenciadorLogs(config)

tests\test_gerenciador_logs.py:19: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\logs\gerenciador_logs.py:63: in __init__
    "logs_criados": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(logs_criados)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'logs_criados', 'logs_criados_total', 'logs_criados_created'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_logs" name="test_obter_estatisticas" time="0.002"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'logs_criados', 'logs_criados_total', 'logs_criados_created'}&quot;">config = {'base_dir': 'test_logs'}

    @pytest.fixture
    def gerenciador(config):
        """Instância do gerenciador de logs."""
&gt;       return GerenciadorLogs(config)

tests\test_gerenciador_logs.py:19: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\logs\gerenciador_logs.py:63: in __init__
    "logs_criados": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(logs_criados)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'logs_criados', 'logs_criados_total', 'logs_criados_created'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_logs" name="test_limpeza" time="0.002"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'logs_criados', 'logs_criados_total', 'logs_criados_created'}&quot;">config = {'base_dir': 'test_logs'}

    @pytest.fixture
    def gerenciador(config):
        """Instância do gerenciador de logs."""
&gt;       return GerenciadorLogs(config)

tests\test_gerenciador_logs.py:19: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\logs\gerenciador_logs.py:63: in __init__
    "logs_criados": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(logs_criados)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'logs_criados', 'logs_criados_total', 'logs_criados_created'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_inicializacao" time="0.003"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_criar_entidade" time="0.004"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_criar_entidade_tipo_invalido" time="0.003"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_criar_entidade_tamanho_excedido" time="0.003"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_atualizar_entidade" time="0.003"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_atualizar_entidade_inexistente" time="0.004"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_obter_entidade" time="0.003"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_obter_entidade_inexistente" time="0.003"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_buscar_entidades" time="0.004"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_adicionar_relacionamento" time="0.003"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_adicionar_relacionamento_inexistente" time="0.002"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_obter_relacionamentos" time="0.003"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_obter_relacionamentos_inexistente" time="0.003"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_limpar_cache" time="0.004"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_obter_estatisticas" time="0.004"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_salvar_carregar_memoria" time="0.001"><failure message="TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'">def test_salvar_carregar_memoria():
        """Testa o salvamento e carregamento da memória."""
&gt;       gerenciador = GerenciadorMemoria()
E       TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'

tests\test_gerenciador_memoria.py:348: TypeError</failure></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_atualizar_estado_sistema" time="0.001"><failure message="TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'">def test_atualizar_estado_sistema():
        """Testa a atualização do estado do sistema."""
&gt;       gerenciador = GerenciadorMemoria()
E       TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'

tests\test_gerenciador_memoria.py:376: TypeError</failure></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_atualizar_metricas" time="0.001"><failure message="TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'">def test_atualizar_metricas():
        """Testa a atualização de métricas."""
&gt;       gerenciador = GerenciadorMemoria()
E       TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'

tests\test_gerenciador_memoria.py:398: TypeError</failure></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_registrar_decisao" time="0.001"><failure message="TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'">def test_registrar_decisao():
        """Testa o registro de uma decisão."""
&gt;       gerenciador = GerenciadorMemoria()
E       TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'

tests\test_gerenciador_memoria.py:424: TypeError</failure></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_registrar_acao" time="0.001"><failure message="TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'">def test_registrar_acao():
        """Testa o registro de uma ação."""
&gt;       gerenciador = GerenciadorMemoria()
E       TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'

tests\test_gerenciador_memoria.py:450: TypeError</failure></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_registrar_incidente" time="0.001"><failure message="TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'">def test_registrar_incidente():
        """Testa o registro de um incidente."""
&gt;       gerenciador = GerenciadorMemoria()
E       TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'

tests\test_gerenciador_memoria.py:475: TypeError</failure></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_registrar_aprendizado" time="0.001"><failure message="TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'">def test_registrar_aprendizado():
        """Testa o registro de um aprendizado."""
&gt;       gerenciador = GerenciadorMemoria()
E       TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'

tests\test_gerenciador_memoria.py:500: TypeError</failure></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_obter_historico" time="0.001"><failure message="TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'">def test_obter_historico():
        """Testa a obtenção do histórico."""
&gt;       gerenciador = GerenciadorMemoria()
E       TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'

tests\test_gerenciador_memoria.py:525: TypeError</failure></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_obter_historico_por_tipo" time="0.001"><failure message="TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'">def test_obter_historico_por_tipo():
        """Testa a obtenção do histórico por tipo."""
&gt;       gerenciador = GerenciadorMemoria()
E       TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'

tests\test_gerenciador_memoria.py:560: TypeError</failure></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_obter_historico_por_periodo" time="0.001"><failure message="TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'">def test_obter_historico_por_periodo():
        """Testa a obtenção do histórico por período."""
&gt;       gerenciador = GerenciadorMemoria()
E       TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'

tests\test_gerenciador_memoria.py:599: TypeError</failure></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_limpar_memoria_antiga" time="0.001"><failure message="TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'">def test_limpar_memoria_antiga():
        """Testa a limpeza de memória antiga."""
&gt;       gerenciador = GerenciadorMemoria()
E       TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'

tests\test_gerenciador_memoria.py:629: TypeError</failure></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_backup_memoria" time="0.001"><failure message="TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'">def test_backup_memoria():
        """Testa o backup da memória."""
&gt;       gerenciador = GerenciadorMemoria()
E       TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'

tests\test_gerenciador_memoria.py:663: TypeError</failure></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_restaurar_backup" time="0.001"><failure message="TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'">def test_restaurar_backup():
        """Testa a restauração de backup."""
&gt;       gerenciador = GerenciadorMemoria()
E       TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'

tests\test_gerenciador_memoria.py:695: TypeError</failure></testcase><testcase classname="tests.test_gerenciador_memoria" name="test_limpar_memoria" time="0.001"><failure message="TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'">def test_limpar_memoria():
        """Testa a limpeza da memória."""
&gt;       gerenciador = GerenciadorMemoria()
E       TypeError: GerenciadorMemoria.__init__() missing 1 required positional argument: 'config'

tests\test_gerenciador_memoria.py:733: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_inicializacao" time="0.009"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}&quot;">config = {'prometheus_port': 9090}

    @pytest.fixture
    def guardiao(config):
        """Fixture com instância do guardião cognitivo."""
&gt;       return GuardiaoCognitivo(config)

tests\test_guardiao_cognitivo.py:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\guardiao\guardiao_cognitivo.py:118: in __init__
    "eventos_cognitivos": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(eventos_cognitivos)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_registrar_evento" time="0.008"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}&quot;">config = {'prometheus_port': 9090}

    @pytest.fixture
    def guardiao(config):
        """Fixture com instância do guardião cognitivo."""
&gt;       return GuardiaoCognitivo(config)

tests\test_guardiao_cognitivo.py:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\guardiao\guardiao_cognitivo.py:118: in __init__
    "eventos_cognitivos": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(eventos_cognitivos)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_avaliar_saude_cognitiva" time="0.013"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}&quot;">config = {'prometheus_port': 9090}

    @pytest.fixture
    def guardiao(config):
        """Fixture com instância do guardião cognitivo."""
&gt;       return GuardiaoCognitivo(config)

tests\test_guardiao_cognitivo.py:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\guardiao\guardiao_cognitivo.py:118: in __init__
    "eventos_cognitivos": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(eventos_cognitivos)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_verificar_limites" time="0.012"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}&quot;">config = {'prometheus_port': 9090}

    @pytest.fixture
    def guardiao(config):
        """Fixture com instância do guardião cognitivo."""
&gt;       return GuardiaoCognitivo(config)

tests\test_guardiao_cognitivo.py:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\guardiao\guardiao_cognitivo.py:118: in __init__
    "eventos_cognitivos": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(eventos_cognitivos)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_executar_acao_protetiva" time="0.009"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}&quot;">config = {'prometheus_port': 9090}

    @pytest.fixture
    def guardiao(config):
        """Fixture com instância do guardião cognitivo."""
&gt;       return GuardiaoCognitivo(config)

tests\test_guardiao_cognitivo.py:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\guardiao\guardiao_cognitivo.py:118: in __init__
    "eventos_cognitivos": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(eventos_cognitivos)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_atualizar_metricas" time="0.007"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}&quot;">config = {'prometheus_port': 9090}

    @pytest.fixture
    def guardiao(config):
        """Fixture com instância do guardião cognitivo."""
&gt;       return GuardiaoCognitivo(config)

tests\test_guardiao_cognitivo.py:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\guardiao\guardiao_cognitivo.py:118: in __init__
    "eventos_cognitivos": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(eventos_cognitivos)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_obter_historico_eventos" time="0.008"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}&quot;">config = {'prometheus_port': 9090}

    @pytest.fixture
    def guardiao(config):
        """Fixture com instância do guardião cognitivo."""
&gt;       return GuardiaoCognitivo(config)

tests\test_guardiao_cognitivo.py:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\guardiao\guardiao_cognitivo.py:118: in __init__
    "eventos_cognitivos": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(eventos_cognitivos)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_limpar_historico" time="0.007"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}&quot;">config = {'prometheus_port': 9090}

    @pytest.fixture
    def guardiao(config):
        """Fixture com instância do guardião cognitivo."""
&gt;       return GuardiaoCognitivo(config)

tests\test_guardiao_cognitivo.py:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\guardiao\guardiao_cognitivo.py:118: in __init__
    "eventos_cognitivos": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(eventos_cognitivos)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_gerar_relatorio" time="0.008"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}&quot;">config = {'prometheus_port': 9090}

    @pytest.fixture
    def guardiao(config):
        """Fixture com instância do guardião cognitivo."""
&gt;       return GuardiaoCognitivo(config)

tests\test_guardiao_cognitivo.py:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\guardiao\guardiao_cognitivo.py:118: in __init__
    "eventos_cognitivos": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(eventos_cognitivos)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_acoes_protetivas" time="0.008"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}&quot;">config = {'prometheus_port': 9090}

    @pytest.fixture
    def guardiao(config):
        """Fixture com instância do guardião cognitivo."""
&gt;       return GuardiaoCognitivo(config)

tests\test_guardiao_cognitivo.py:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\guardiao\guardiao_cognitivo.py:118: in __init__
    "eventos_cognitivos": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(eventos_cognitivos)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_metricas_prometheus" time="0.011"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}&quot;">config = {'prometheus_port': 9090}

    @pytest.fixture
    def guardiao(config):
        """Fixture com instância do guardião cognitivo."""
&gt;       return GuardiaoCognitivo(config)

tests\test_guardiao_cognitivo.py:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\guardiao\guardiao_cognitivo.py:118: in __init__
    "eventos_cognitivos": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(eventos_cognitivos)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_limites_alertas" time="0.007"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}&quot;">config = {'prometheus_port': 9090}

    @pytest.fixture
    def guardiao(config):
        """Fixture com instância do guardião cognitivo."""
&gt;       return GuardiaoCognitivo(config)

tests\test_guardiao_cognitivo.py:23: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\guardiao\guardiao_cognitivo.py:118: in __init__
    "eventos_cognitivos": Counter(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Counter(eventos_cognitivos)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'eventos_cognitivos_created', 'eventos_cognitivos', 'eventos_cognitivos_total'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_monitorar_recursos" time="0.001"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_monitorar_recursos():
        """Testa o monitoramento de recursos."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:240: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_monitorar_recursos_criticos" time="0.001"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_monitorar_recursos_criticos():
        """Testa o monitoramento de recursos críticos."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:259: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_monitorar_desempenho" time="0.001"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_monitorar_desempenho():
        """Testa o monitoramento de desempenho."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:280: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_monitorar_desempenho_critico" time="0.001"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_monitorar_desempenho_critico():
        """Testa o monitoramento de desempenho crítico."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:299: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_monitorar_seguranca" time="0.001"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_monitorar_seguranca():
        """Testa o monitoramento de segurança."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:320: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_monitorar_seguranca_critico" time="0.001"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_monitorar_seguranca_critico():
        """Testa o monitoramento de segurança crítico."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:339: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_monitorar_etica" time="0.001"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_monitorar_etica():
        """Testa o monitoramento de ética."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:360: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_monitorar_etica_critico" time="0.001"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_monitorar_etica_critico():
        """Testa o monitoramento de ética crítico."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:379: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_aplicar_salvaguardas_recursos" time="0.001"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_aplicar_salvaguardas_recursos():
        """Testa a aplicação de salvaguardas para recursos."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:400: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_aplicar_salvaguardas_desempenho" time="0.001"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_aplicar_salvaguardas_desempenho():
        """Testa a aplicação de salvaguardas para desempenho."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:422: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_aplicar_salvaguardas_seguranca" time="0.001"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_aplicar_salvaguardas_seguranca():
        """Testa a aplicação de salvaguardas para segurança."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:444: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_aplicar_salvaguardas_etica" time="0.001"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_aplicar_salvaguardas_etica():
        """Testa a aplicação de salvaguardas para ética."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:466: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_verificar_autonomia" time="0.001"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_verificar_autonomia():
        """Testa a verificação de autonomia."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:488: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_verificar_autonomia_reduzida" time="0.001"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_verificar_autonomia_reduzida():
        """Testa a verificação de autonomia reduzida."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:512: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_verificar_aprendizado" time="0.001"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_verificar_aprendizado():
        """Testa a verificação de aprendizado."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:536: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_verificar_aprendizado_insuficiente" time="0.001"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_verificar_aprendizado_insuficiente():
        """Testa a verificação de aprendizado insuficiente."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:556: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_verificar_estabilidade" time="0.002"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_verificar_estabilidade():
        """Testa a verificação de estabilidade."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:576: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_verificar_estabilidade_baixa" time="0.003"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_verificar_estabilidade_baixa():
        """Testa a verificação de estabilidade baixa."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:596: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_verificar_conformidade" time="0.001"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_verificar_conformidade():
        """Testa a verificação de conformidade."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:616: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_verificar_conformidade_parcial" time="0.001"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_verificar_conformidade_parcial():
        """Testa a verificação de conformidade parcial."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:636: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_verificar_evolucao" time="0.001"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_verificar_evolucao():
        """Testa a verificação de evolução."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:656: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_verificar_evolucao_estagnada" time="0.001"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_verificar_evolucao_estagnada():
        """Testa a verificação de evolução estagnada."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:676: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_verificar_resiliencia" time="0.001"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_verificar_resiliencia():
        """Testa a verificação de resiliência."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:696: TypeError</failure></testcase><testcase classname="tests.test_guardiao_cognitivo" name="test_verificar_resiliencia_baixa" time="0.001"><failure message="TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'">def test_verificar_resiliencia_baixa():
        """Testa a verificação de resiliência baixa."""
&gt;       guardiao = GuardiaoCognitivo()
E       TypeError: GuardiaoCognitivo.__init__() missing 1 required positional argument: 'gerenciador_memoria'

tests\test_guardiao_cognitivo.py:716: TypeError</failure></testcase><testcase classname="tests.test_kubernetes_orchestrator" name="test_inicializacao" time="0.002"><error message="failed on setup with &quot;AttributeError: 'dict' object has no attribute 'load_kube_config'&quot;">config = {'namespace': 'test'}

    @pytest.fixture
    def orchestrator(config):
        """Fixture que fornece uma instância do orquestrador Kubernetes para os testes."""
        with patch("kubernetes.config.load_kube_config"):
&gt;           return KubernetesOrchestrator(config)

tests\test_kubernetes_orchestrator.py:19: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;src.orquestracao.kubernetes_orchestrator.KubernetesOrchestrator object at 0x000002471F472F90&gt;
config = {'namespace': 'test'}

    def __init__(self, config: Dict[str, Any]):
        """Inicializa o orquestrador Kubernetes.
    
        Args:
            config: Configuração do orquestrador
        """
        self.config = config
        self.logger = logging.getLogger(__name__)
    
        # Carrega configuração do Kubernetes
        try:
&gt;           config.load_kube_config()
E           AttributeError: 'dict' object has no attribute 'load_kube_config'

src\orquestracao\kubernetes_orchestrator.py:22: AttributeError</error></testcase><testcase classname="tests.test_kubernetes_orchestrator" name="test_criar_deployment" time="0.002"><error message="failed on setup with &quot;AttributeError: 'dict' object has no attribute 'load_kube_config'&quot;">config = {'namespace': 'test'}

    @pytest.fixture
    def orchestrator(config):
        """Fixture que fornece uma instância do orquestrador Kubernetes para os testes."""
        with patch("kubernetes.config.load_kube_config"):
&gt;           return KubernetesOrchestrator(config)

tests\test_kubernetes_orchestrator.py:19: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;src.orquestracao.kubernetes_orchestrator.KubernetesOrchestrator object at 0x000002471F49F890&gt;
config = {'namespace': 'test'}

    def __init__(self, config: Dict[str, Any]):
        """Inicializa o orquestrador Kubernetes.
    
        Args:
            config: Configuração do orquestrador
        """
        self.config = config
        self.logger = logging.getLogger(__name__)
    
        # Carrega configuração do Kubernetes
        try:
&gt;           config.load_kube_config()
E           AttributeError: 'dict' object has no attribute 'load_kube_config'

src\orquestracao\kubernetes_orchestrator.py:22: AttributeError</error></testcase><testcase classname="tests.test_kubernetes_orchestrator" name="test_criar_deployment_falha" time="0.002"><error message="failed on setup with &quot;AttributeError: 'dict' object has no attribute 'load_kube_config'&quot;">config = {'namespace': 'test'}

    @pytest.fixture
    def orchestrator(config):
        """Fixture que fornece uma instância do orquestrador Kubernetes para os testes."""
        with patch("kubernetes.config.load_kube_config"):
&gt;           return KubernetesOrchestrator(config)

tests\test_kubernetes_orchestrator.py:19: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;src.orquestracao.kubernetes_orchestrator.KubernetesOrchestrator object at 0x000002471F49FC50&gt;
config = {'namespace': 'test'}

    def __init__(self, config: Dict[str, Any]):
        """Inicializa o orquestrador Kubernetes.
    
        Args:
            config: Configuração do orquestrador
        """
        self.config = config
        self.logger = logging.getLogger(__name__)
    
        # Carrega configuração do Kubernetes
        try:
&gt;           config.load_kube_config()
E           AttributeError: 'dict' object has no attribute 'load_kube_config'

src\orquestracao\kubernetes_orchestrator.py:22: AttributeError</error></testcase><testcase classname="tests.test_kubernetes_orchestrator" name="test_atualizar_deployment" time="0.002"><error message="failed on setup with &quot;AttributeError: 'dict' object has no attribute 'load_kube_config'&quot;">config = {'namespace': 'test'}

    @pytest.fixture
    def orchestrator(config):
        """Fixture que fornece uma instância do orquestrador Kubernetes para os testes."""
        with patch("kubernetes.config.load_kube_config"):
&gt;           return KubernetesOrchestrator(config)

tests\test_kubernetes_orchestrator.py:19: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;src.orquestracao.kubernetes_orchestrator.KubernetesOrchestrator object at 0x000002471F674D60&gt;
config = {'namespace': 'test'}

    def __init__(self, config: Dict[str, Any]):
        """Inicializa o orquestrador Kubernetes.
    
        Args:
            config: Configuração do orquestrador
        """
        self.config = config
        self.logger = logging.getLogger(__name__)
    
        # Carrega configuração do Kubernetes
        try:
&gt;           config.load_kube_config()
E           AttributeError: 'dict' object has no attribute 'load_kube_config'

src\orquestracao\kubernetes_orchestrator.py:22: AttributeError</error></testcase><testcase classname="tests.test_kubernetes_orchestrator" name="test_deletar_deployment" time="0.001"><error message="failed on setup with &quot;AttributeError: 'dict' object has no attribute 'load_kube_config'&quot;">config = {'namespace': 'test'}

    @pytest.fixture
    def orchestrator(config):
        """Fixture que fornece uma instância do orquestrador Kubernetes para os testes."""
        with patch("kubernetes.config.load_kube_config"):
&gt;           return KubernetesOrchestrator(config)

tests\test_kubernetes_orchestrator.py:19: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;src.orquestracao.kubernetes_orchestrator.KubernetesOrchestrator object at 0x000002471F6749D0&gt;
config = {'namespace': 'test'}

    def __init__(self, config: Dict[str, Any]):
        """Inicializa o orquestrador Kubernetes.
    
        Args:
            config: Configuração do orquestrador
        """
        self.config = config
        self.logger = logging.getLogger(__name__)
    
        # Carrega configuração do Kubernetes
        try:
&gt;           config.load_kube_config()
E           AttributeError: 'dict' object has no attribute 'load_kube_config'

src\orquestracao\kubernetes_orchestrator.py:22: AttributeError</error></testcase><testcase classname="tests.test_kubernetes_orchestrator" name="test_obter_status_deployment" time="0.001"><error message="failed on setup with &quot;AttributeError: 'dict' object has no attribute 'load_kube_config'&quot;">config = {'namespace': 'test'}

    @pytest.fixture
    def orchestrator(config):
        """Fixture que fornece uma instância do orquestrador Kubernetes para os testes."""
        with patch("kubernetes.config.load_kube_config"):
&gt;           return KubernetesOrchestrator(config)

tests\test_kubernetes_orchestrator.py:19: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;src.orquestracao.kubernetes_orchestrator.KubernetesOrchestrator object at 0x000002471F48A7B0&gt;
config = {'namespace': 'test'}

    def __init__(self, config: Dict[str, Any]):
        """Inicializa o orquestrador Kubernetes.
    
        Args:
            config: Configuração do orquestrador
        """
        self.config = config
        self.logger = logging.getLogger(__name__)
    
        # Carrega configuração do Kubernetes
        try:
&gt;           config.load_kube_config()
E           AttributeError: 'dict' object has no attribute 'load_kube_config'

src\orquestracao\kubernetes_orchestrator.py:22: AttributeError</error></testcase><testcase classname="tests.test_kubernetes_orchestrator" name="test_configurar_autoscaling" time="0.002"><error message="failed on setup with &quot;AttributeError: 'dict' object has no attribute 'load_kube_config'&quot;">config = {'namespace': 'test'}

    @pytest.fixture
    def orchestrator(config):
        """Fixture que fornece uma instância do orquestrador Kubernetes para os testes."""
        with patch("kubernetes.config.load_kube_config"):
&gt;           return KubernetesOrchestrator(config)

tests\test_kubernetes_orchestrator.py:19: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;src.orquestracao.kubernetes_orchestrator.KubernetesOrchestrator object at 0x000002471F66E360&gt;
config = {'namespace': 'test'}

    def __init__(self, config: Dict[str, Any]):
        """Inicializa o orquestrador Kubernetes.
    
        Args:
            config: Configuração do orquestrador
        """
        self.config = config
        self.logger = logging.getLogger(__name__)
    
        # Carrega configuração do Kubernetes
        try:
&gt;           config.load_kube_config()
E           AttributeError: 'dict' object has no attribute 'load_kube_config'

src\orquestracao\kubernetes_orchestrator.py:22: AttributeError</error></testcase><testcase classname="tests.test_kubernetes_orchestrator" name="test_obter_metricas_deployment" time="0.002"><error message="failed on setup with &quot;AttributeError: 'dict' object has no attribute 'load_kube_config'&quot;">config = {'namespace': 'test'}

    @pytest.fixture
    def orchestrator(config):
        """Fixture que fornece uma instância do orquestrador Kubernetes para os testes."""
        with patch("kubernetes.config.load_kube_config"):
&gt;           return KubernetesOrchestrator(config)

tests\test_kubernetes_orchestrator.py:19: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;src.orquestracao.kubernetes_orchestrator.KubernetesOrchestrator object at 0x0000024720ECE9C0&gt;
config = {'namespace': 'test'}

    def __init__(self, config: Dict[str, Any]):
        """Inicializa o orquestrador Kubernetes.
    
        Args:
            config: Configuração do orquestrador
        """
        self.config = config
        self.logger = logging.getLogger(__name__)
    
        # Carrega configuração do Kubernetes
        try:
&gt;           config.load_kube_config()
E           AttributeError: 'dict' object has no attribute 'load_kube_config'

src\orquestracao\kubernetes_orchestrator.py:22: AttributeError</error></testcase><testcase classname="tests.test_kubernetes_orchestrator" name="test_verificar_saude_deployment" time="0.002"><error message="failed on setup with &quot;AttributeError: 'dict' object has no attribute 'load_kube_config'&quot;">config = {'namespace': 'test'}

    @pytest.fixture
    def orchestrator(config):
        """Fixture que fornece uma instância do orquestrador Kubernetes para os testes."""
        with patch("kubernetes.config.load_kube_config"):
&gt;           return KubernetesOrchestrator(config)

tests\test_kubernetes_orchestrator.py:19: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;src.orquestracao.kubernetes_orchestrator.KubernetesOrchestrator object at 0x000002471F3DFD50&gt;
config = {'namespace': 'test'}

    def __init__(self, config: Dict[str, Any]):
        """Inicializa o orquestrador Kubernetes.
    
        Args:
            config: Configuração do orquestrador
        """
        self.config = config
        self.logger = logging.getLogger(__name__)
    
        # Carrega configuração do Kubernetes
        try:
&gt;           config.load_kube_config()
E           AttributeError: 'dict' object has no attribute 'load_kube_config'

src\orquestracao\kubernetes_orchestrator.py:22: AttributeError</error></testcase><testcase classname="tests.test_kubernetes_orchestrator" name="test_verificar_saude_deployment_warning" time="0.002"><error message="failed on setup with &quot;AttributeError: 'dict' object has no attribute 'load_kube_config'&quot;">config = {'namespace': 'test'}

    @pytest.fixture
    def orchestrator(config):
        """Fixture que fornece uma instância do orquestrador Kubernetes para os testes."""
        with patch("kubernetes.config.load_kube_config"):
&gt;           return KubernetesOrchestrator(config)

tests\test_kubernetes_orchestrator.py:19: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;src.orquestracao.kubernetes_orchestrator.KubernetesOrchestrator object at 0x0000024720EC5150&gt;
config = {'namespace': 'test'}

    def __init__(self, config: Dict[str, Any]):
        """Inicializa o orquestrador Kubernetes.
    
        Args:
            config: Configuração do orquestrador
        """
        self.config = config
        self.logger = logging.getLogger(__name__)
    
        # Carrega configuração do Kubernetes
        try:
&gt;           config.load_kube_config()
E           AttributeError: 'dict' object has no attribute 'load_kube_config'

src\orquestracao\kubernetes_orchestrator.py:22: AttributeError</error></testcase><testcase classname="tests.test_observador_4d" name="test_inicializacao" time="0.004"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_observador_4d" name="test_atualizar_dimensao" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'cpu_usage'}&quot;">config = {'prometheus_port': 9090}

    @pytest.fixture
    def observador(config):
        """Fixture que fornece uma instância do observador 4D para os testes."""
&gt;       return Observador4D(config)

tests\test_observador_4d.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\observabilidade\observador_4d.py:31: in __init__
    "cpu_usage": Gauge("cpu_usage", "Uso de CPU", ["host"]),
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:376: in __init__
    super().__init__(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Gauge(cpu_usage)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'cpu_usage'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_observador_4d" name="test_atualizar_dimensao_limite" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'cpu_usage'}&quot;">config = {'prometheus_port': 9090}

    @pytest.fixture
    def observador(config):
        """Fixture que fornece uma instância do observador 4D para os testes."""
&gt;       return Observador4D(config)

tests\test_observador_4d.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\observabilidade\observador_4d.py:31: in __init__
    "cpu_usage": Gauge("cpu_usage", "Uso de CPU", ["host"]),
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:376: in __init__
    super().__init__(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Gauge(cpu_usage)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'cpu_usage'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_observador_4d" name="test_obter_dimensao" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'cpu_usage'}&quot;">config = {'prometheus_port': 9090}

    @pytest.fixture
    def observador(config):
        """Fixture que fornece uma instância do observador 4D para os testes."""
&gt;       return Observador4D(config)

tests\test_observador_4d.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\observabilidade\observador_4d.py:31: in __init__
    "cpu_usage": Gauge("cpu_usage", "Uso de CPU", ["host"]),
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:376: in __init__
    super().__init__(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Gauge(cpu_usage)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'cpu_usage'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_observador_4d" name="test_obter_dimensao_periodo" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'cpu_usage'}&quot;">config = {'prometheus_port': 9090}

    @pytest.fixture
    def observador(config):
        """Fixture que fornece uma instância do observador 4D para os testes."""
&gt;       return Observador4D(config)

tests\test_observador_4d.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\observabilidade\observador_4d.py:31: in __init__
    "cpu_usage": Gauge("cpu_usage", "Uso de CPU", ["host"]),
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:376: in __init__
    super().__init__(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Gauge(cpu_usage)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'cpu_usage'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_observador_4d" name="test_calcular_estatisticas" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'cpu_usage'}&quot;">config = {'prometheus_port': 9090}

    @pytest.fixture
    def observador(config):
        """Fixture que fornece uma instância do observador 4D para os testes."""
&gt;       return Observador4D(config)

tests\test_observador_4d.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\observabilidade\observador_4d.py:31: in __init__
    "cpu_usage": Gauge("cpu_usage", "Uso de CPU", ["host"]),
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:376: in __init__
    super().__init__(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Gauge(cpu_usage)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'cpu_usage'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_observador_4d" name="test_detectar_anomalias" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'cpu_usage'}&quot;">config = {'prometheus_port': 9090}

    @pytest.fixture
    def observador(config):
        """Fixture que fornece uma instância do observador 4D para os testes."""
&gt;       return Observador4D(config)

tests\test_observador_4d.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\observabilidade\observador_4d.py:31: in __init__
    "cpu_usage": Gauge("cpu_usage", "Uso de CPU", ["host"]),
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:376: in __init__
    super().__init__(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Gauge(cpu_usage)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'cpu_usage'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_observador_4d" name="test_atualizar_metricas" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'cpu_usage'}&quot;">config = {'prometheus_port': 9090}

    @pytest.fixture
    def observador(config):
        """Fixture que fornece uma instância do observador 4D para os testes."""
&gt;       return Observador4D(config)

tests\test_observador_4d.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\observabilidade\observador_4d.py:31: in __init__
    "cpu_usage": Gauge("cpu_usage", "Uso de CPU", ["host"]),
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:376: in __init__
    super().__init__(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Gauge(cpu_usage)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'cpu_usage'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_observador_4d" name="test_obter_metricas" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'cpu_usage'}&quot;">config = {'prometheus_port': 9090}

    @pytest.fixture
    def observador(config):
        """Fixture que fornece uma instância do observador 4D para os testes."""
&gt;       return Observador4D(config)

tests\test_observador_4d.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\observabilidade\observador_4d.py:31: in __init__
    "cpu_usage": Gauge("cpu_usage", "Uso de CPU", ["host"]),
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:376: in __init__
    super().__init__(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Gauge(cpu_usage)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'cpu_usage'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_observador_4d" name="test_gerar_relatorio" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'cpu_usage'}&quot;">config = {'prometheus_port': 9090}

    @pytest.fixture
    def observador(config):
        """Fixture que fornece uma instância do observador 4D para os testes."""
&gt;       return Observador4D(config)

tests\test_observador_4d.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\observabilidade\observador_4d.py:31: in __init__
    "cpu_usage": Gauge("cpu_usage", "Uso de CPU", ["host"]),
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:376: in __init__
    super().__init__(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Gauge(cpu_usage)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'cpu_usage'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_observador_4d" name="test_limpar_dados_antigos" time="0.001"><error message="failed on setup with &quot;ValueError: Duplicated timeseries in CollectorRegistry: {'cpu_usage'}&quot;">config = {'prometheus_port': 9090}

    @pytest.fixture
    def observador(config):
        """Fixture que fornece uma instância do observador 4D para os testes."""
&gt;       return Observador4D(config)

tests\test_observador_4d.py:17: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\observabilidade\observador_4d.py:31: in __init__
    "cpu_usage": Gauge("cpu_usage", "Uso de CPU", ["host"]),
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:376: in __init__
    super().__init__(
C:\Python313\Lib\site-packages\prometheus_client\metrics.py:132: in __init__
    registry.register(self)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = &lt;prometheus_client.registry.CollectorRegistry object at 0x00000247614C1550&gt;
collector = prometheus_client.metrics.Gauge(cpu_usage)

    def register(self, collector: Collector) -&gt; None:
        """Add a collector to the registry."""
        with self._lock:
            names = self._get_names(collector)
            duplicates = set(self._names_to_collectors).intersection(names)
            if duplicates:
&gt;               raise ValueError(
                    'Duplicated timeseries in CollectorRegistry: {}'.format(
                        duplicates))
E               ValueError: Duplicated timeseries in CollectorRegistry: {'cpu_usage'}

C:\Python313\Lib\site-packages\prometheus_client\registry.py:43: ValueError</error></testcase><testcase classname="tests.test_orquestrador" name="test_inicializar_sistema" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador" name="test_executar_ciclo_normal" time="0.000"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador" name="test_executar_ciclo_com_incidente" time="0.000"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador" name="test_executar_ciclo_com_decisao" time="0.000"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador" name="test_executar_ciclo_com_acao" time="0.000"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador" name="test_executar_ciclo_com_aprendizado" time="0.000"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador" name="test_executar_ciclo_com_autonomia" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador" name="test_executar_ciclo_com_autonomia_reduzida" time="0.000"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador" name="test_executar_ciclo_com_validacao_etica" time="0.000"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador" name="test_executar_ciclo_com_validacao_etica_rejeitada" time="0.000"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador" name="test_executar_ciclo_com_salvaguardas" time="0.000"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador" name="test_executar_ciclo_com_acoes_geradas" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador" name="test_executar_ciclo_com_acoes_executadas" time="0.000"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador" name="test_executar_ciclo_com_aprendizado_aplicado" time="0.000"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador" name="test_executar_ciclo_com_estado_atualizado" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador" name="test_executar_ciclo_com_metricas_atualizadas" time="0.000"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador_conhecimento" name="test_inicializacao" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador_conhecimento" name="test_criar_documento" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador_conhecimento" name="test_atualizar_documento" time="0.002"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador_conhecimento" name="test_obter_documento" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador_conhecimento" name="test_buscar_documentos" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador_conhecimento" name="test_relacionamentos" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador_conhecimento" name="test_gerar_indice" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador_conhecimento" name="test_persistencia" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_orquestrador_conhecimento" name="test_limpeza" time="0.001"><skipped type="pytest.skip" message="async def function and no async plugin installed (see warnings)">C:\Python313\Lib\site-packages\_pytest\python.py:149: async def function and no async plugin installed (see warnings)</skipped></testcase><testcase classname="tests.test_rede_neural" name="test_inicializacao" time="1.239" /><testcase classname="tests.test_rede_neural" name="test_forward_pass" time="0.003"><failure message="ValueError: expected 2D or 3D input (got 1D input)">rede = RedeNeuralAltaOrdem(
  (network): Sequential(
    (0): Linear(in_features=4, out_features=8, bias=True)
    (1): ReLU(... bias=True)
    (11): ReLU()
    (12): Linear(in_features=32, out_features=1, bias=True)
  )
  (criterion): MSELoss()
)
metricas = [Metrica(nome='cpu_usage', valor=0.75, tipo='gauge', labels={'host': 'test'}, timestamp=datetime.datetime(2025, 5, 20,...ate', valor=0.02, tipo='gauge', labels={'host': 'test'}, timestamp=datetime.datetime(2025, 5, 20, 22, 13, 24, 972155))]

    def test_forward_pass(rede, metricas):
        """Testa o forward pass da rede neural."""
        x = rede.preparar_dados(metricas)
&gt;       anomalia, padroes = rede(x)

tests\test_rede_neural.py:64: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
C:\Python313\Lib\site-packages\torch\nn\modules\module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
C:\Python313\Lib\site-packages\torch\nn\modules\module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
src\diagnostico\rede_neural.py:101: in forward
    features = self.network[:-2](x)  # Features latentes
C:\Python313\Lib\site-packages\torch\nn\modules\module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
C:\Python313\Lib\site-packages\torch\nn\modules\module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
C:\Python313\Lib\site-packages\torch\nn\modules\container.py:240: in forward
    input = module(input)
C:\Python313\Lib\site-packages\torch\nn\modules\module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
C:\Python313\Lib\site-packages\torch\nn\modules\module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
C:\Python313\Lib\site-packages\torch\nn\modules\batchnorm.py:160: in forward
    self._check_input_dim(input)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
input = tensor([0.1040, 0.1844, 0.0000, 0.5255, 0.0247, 0.0000, 0.0000, 0.0000],
       grad_fn=&lt;ReluBackward0&gt;)

    def _check_input_dim(self, input):
        if input.dim() != 2 and input.dim() != 3:
&gt;           raise ValueError(f"expected 2D or 3D input (got {input.dim()}D input)")
E           ValueError: expected 2D or 3D input (got 1D input)

C:\Python313\Lib\site-packages\torch\nn\modules\batchnorm.py:341: ValueError</failure></testcase><testcase classname="tests.test_rede_neural" name="test_preparar_dados" time="0.002" /><testcase classname="tests.test_rede_neural" name="test_detectar_anomalia" time="0.002"><failure message="ValueError: expected 2D or 3D input (got 1D input)">rede = RedeNeuralAltaOrdem(
  (network): Sequential(
    (0): Linear(in_features=4, out_features=8, bias=True)
    (1): ReLU(... bias=True)
    (11): ReLU()
    (12): Linear(in_features=32, out_features=1, bias=True)
  )
  (criterion): MSELoss()
)
metricas = [Metrica(nome='cpu_usage', valor=0.75, tipo='gauge', labels={'host': 'test'}, timestamp=datetime.datetime(2025, 5, 20,...ate', valor=0.02, tipo='gauge', labels={'host': 'test'}, timestamp=datetime.datetime(2025, 5, 20, 22, 13, 25, 141758))]

    def test_detectar_anomalia(rede, metricas):
        """Testa a detecção de anomalias."""
&gt;       diagnostico = rede.detectar_anomalia(metricas)

tests\test_rede_neural.py:81: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
src\diagnostico\rede_neural.py:136: in detectar_anomalia
    score_anomalia, padroes = self(x)
C:\Python313\Lib\site-packages\torch\nn\modules\module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
C:\Python313\Lib\site-packages\torch\nn\modules\module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
src\diagnostico\rede_neural.py:101: in forward
    features = self.network[:-2](x)  # Features latentes
C:\Python313\Lib\site-packages\torch\nn\modules\module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
C:\Python313\Lib\site-packages\torch\nn\modules\module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
C:\Python313\Lib\site-packages\torch\nn\modules\container.py:240: in forward
    input = module(input)
C:\Python313\Lib\site-packages\torch\nn\modules\module.py:1751: in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
C:\Python313\Lib\site-packages\torch\nn\modules\module.py:1762: in _call_impl
    return forward_call(*args, **kwargs)
C:\Python313\Lib\site-packages\torch\nn\modules\batchnorm.py:160: in forward
    self._check_input_dim(input)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = BatchNorm1d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
input = tensor([0.1082, 0.7633, 0.0000, 0.0000, 0.2822, 0.0522, 0.0000, 0.2934])

    def _check_input_dim(self, input):
        if input.dim() != 2 and input.dim() != 3:
&gt;           raise ValueError(f"expected 2D or 3D input (got {input.dim()}D input)")
E           ValueError: expected 2D or 3D input (got 1D input)

C:\Python313\Lib\site-packages\torch\nn\modules\batchnorm.py:341: ValueError</failure></testcase><testcase classname="tests.test_rede_neural" name="test_identificar_padrao" time="0.006"><failure message="IndexError: list index out of range">rede = RedeNeuralAltaOrdem(
  (network): Sequential(
    (0): Linear(in_features=4, out_features=8, bias=True)
    (1): ReLU(... bias=True)
    (11): ReLU()
    (12): Linear(in_features=32, out_features=1, bias=True)
  )
  (criterion): MSELoss()
)

    def test_identificar_padrao(rede):
        """Testa a identificação de padrões."""
        # Cria tensor de padrões de exemplo
        padroes = torch.randn(32)  # Tamanho da camada de padrões
    
&gt;       padrao = rede._identificar_padrao(padroes)

tests\test_rede_neural.py:97: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = RedeNeuralAltaOrdem(
  (network): Sequential(
    (0): Linear(in_features=4, out_features=8, bias=True)
    (1): ReLU(... bias=True)
    (11): ReLU()
    (12): Linear(in_features=32, out_features=1, bias=True)
  )
  (criterion): MSELoss()
)
padroes = array([ 1.1518631 , -1.3022392 ,  0.66180015, -1.1035289 , -0.8717425 ,
        2.24124   , -0.8600071 ,  0.7086488 , ...       0.54404247, -0.13042639,  0.57121444,  0.8735658 ,  0.38440278,
        0.19666182,  0.59059715], dtype=float32)

    def _identificar_padrao(
        self,
        padroes: torch.Tensor
    ) -&gt; str:
        """Identifica o padrão mais provável baseado na saída da rede."""
        padroes = padroes.numpy()
        padrao_idx = np.argmax(padroes)
    
        # Mapeia índice para nome do padrão
        padroes_nomes = list(self.padroes_conhecidos.keys())
&gt;       return padroes_nomes[padrao_idx]
E       IndexError: list index out of range

src\diagnostico\rede_neural.py:178: IndexError</failure></testcase><testcase classname="tests.test_rede_neural" name="test_identificar_metricas_relevantes" time="0.002" /><testcase classname="tests.test_rede_neural" name="test_gerar_recomendacoes" time="0.002" /><testcase classname="tests.test_rede_neural" name="test_treinar" time="0.017" /><testcase classname="tests.test_rede_neural" name="test_salvar_carregar_modelo" time="0.023" /><testcase classname="tests.test_rede_neural" name="test_deteccao_anomalia_cpu" time="0.002"><failure message="TypeError: Metrica.__init__() got an unexpected keyword argument 'type'">rede = RedeNeuralAltaOrdem(
  (network): Sequential(
    (0): Linear(in_features=4, out_features=8, bias=True)
    (1): ReLU(... bias=True)
    (11): ReLU()
    (12): Linear(in_features=32, out_features=1, bias=True)
  )
  (criterion): MSELoss()
)

    def test_deteccao_anomalia_cpu(rede):
        """Testa a detecção de anomalia de CPU."""
        metricas = [
            Metrica(
                nome="cpu_usage",
                valor=0.9,  # Valor alto
                tipo="gauge",
                labels={"host": "test"},
                timestamp=datetime.now()
            ),
            Metrica(
                nome="memory_usage",
                valor=0.5,
                tipo="gauge",
                labels={"host": "test"},
                timestamp=datetime.now()
            ),
&gt;           Metrica(
                nome="request_latency",
                valor=0.3,
                type="gauge",
                labels={"host": "test"},
                timestamp=datetime.now()
            ),
            Metrica(
                nome="error_rate",
                valor=0.01,
                type="gauge",
                labels={"host": "test"},
                timestamp=datetime.now()
            )
        ]
E       TypeError: Metrica.__init__() got an unexpected keyword argument 'type'

tests\test_rede_neural.py:178: TypeError</failure></testcase><testcase classname="tests.test_rede_neural" name="test_deteccao_anomalia_memoria" time="0.002"><failure message="TypeError: Metrica.__init__() got an unexpected keyword argument 'type'">rede = RedeNeuralAltaOrdem(
  (network): Sequential(
    (0): Linear(in_features=4, out_features=8, bias=True)
    (1): ReLU(... bias=True)
    (11): ReLU()
    (12): Linear(in_features=32, out_features=1, bias=True)
  )
  (criterion): MSELoss()
)

    def test_deteccao_anomalia_memoria(rede):
        """Testa a detecção de anomalia de memória."""
        metricas = [
&gt;           Metrica(
                nome="cpu_usage",
                valor=0.5,
                type="gauge",
                labels={"host": "test"},
                timestamp=datetime.now()
            ),
            Metrica(
                nome="memory_usage",
                valor=0.9,  # Valor alto
                type="gauge",
                labels={"host": "test"},
                timestamp=datetime.now()
            ),
            Metrica(
                nome="request_latency",
                valor=0.3,
                type="gauge",
                labels={"host": "test"},
                timestamp=datetime.now()
            ),
            Metrica(
                nome="error_rate",
                valor=0.01,
                type="gauge",
                labels={"host": "test"},
                timestamp=datetime.now()
            )
        ]
E       TypeError: Metrica.__init__() got an unexpected keyword argument 'type'

tests\test_rede_neural.py:204: TypeError</failure></testcase><testcase classname="tests.test_validador_etico" name="test_validacao_decisao_manutencao" time="0.004"><failure message="assert False == True">def test_validacao_decisao_manutencao():
        """Testa a validação ética de uma decisão de manutenção."""
        validador = ValidadorEtico(GerenciadorMemoria({
            "redis_host": "localhost",
            "redis_port": 6379,
            "redis_db": 0
        }))
    
        # Simular decisão de manutenção
        decisao = {
            "id": "test_1",
            "tipo": "manutencao",
            "contexto": {
                "documentacao": True,
                "rastreavel": True,
                "explicavel": True,
                "impacto": "baixo",
                "reversivel": True
            }
        }
    
        # Validar decisão
        resultado = validador.validar_decisao(decisao)
    
        # Verificar resultado
&gt;       assert resultado["aprovada"] == True
E       assert False == True

tests\test_validador_etico.py:46: AssertionError</failure></testcase><testcase classname="tests.test_validador_etico" name="test_validacao_decisao_hotfix" time="0.018"><failure message="assert False == True">def test_validacao_decisao_hotfix():
        """Testa a validação ética de uma decisão de hotfix."""
        validador = ValidadorEtico(GerenciadorMemoria({
            "redis_host": "localhost",
            "redis_port": 6379,
            "redis_db": 0
        }))
    
        # Simular decisão de hotfix
        decisao = {
            "id": "test_2",
            "tipo": "hotfix",
            "contexto": {
                "documentacao": True,
                "rastreavel": True,
                "explicavel": True,
                "impacto": "medio",
                "reversivel": True,
                "urgencia": "alta",
                "testes": True
            }
        }
    
        # Validar decisão
        resultado = validador.validar_decisao(decisao)
    
        # Verificar resultado
&gt;       assert resultado["aprovada"] == True
E       assert False == True

tests\test_validador_etico.py:77: AssertionError</failure></testcase><testcase classname="tests.test_validador_etico" name="test_validacao_decisao_refatoracao" time="0.014"><failure message="assert False == True">def test_validacao_decisao_refatoracao():
        """Testa a validação ética de uma decisão de refatoração."""
        validador = ValidadorEtico(GerenciadorMemoria({
            "redis_host": "localhost",
            "redis_port": 6379,
            "redis_db": 0
        }))
    
        # Simular decisão de refatoração
        decisao = {
            "id": "test_3",
            "tipo": "refatoracao",
            "contexto": {
                "documentacao": True,
                "rastreavel": True,
                "explicavel": True,
                "impacto": "medio",
                "reversivel": True,
                "testes": True,
                "revisao": True
            }
        }
    
        # Validar decisão
        resultado = validador.validar_decisao(decisao)
    
        # Verificar resultado
&gt;       assert resultado["aprovada"] == True
E       assert False == True

tests\test_validador_etico.py:108: AssertionError</failure></testcase><testcase classname="tests.test_validador_etico" name="test_validacao_decisao_redesign" time="0.020"><failure message="assert False == True">def test_validacao_decisao_redesign():
        """Testa a validação ética de uma decisão de redesign."""
        validador = ValidadorEtico(GerenciadorMemoria({
            "redis_host": "localhost",
            "redis_port": 6379,
            "redis_db": 0
        }))
    
        # Simular decisão de redesign
        decisao = {
            "id": "test_4",
            "tipo": "redesign",
            "contexto": {
                "documentacao": True,
                "rastreavel": True,
                "explicavel": True,
                "impacto": "alto",
                "reversivel": True,
                "testes": True,
                "revisao": True,
                "aprovacao": True
            }
        }
    
        # Validar decisão
        resultado = validador.validar_decisao(decisao)
    
        # Verificar resultado
&gt;       assert resultado["aprovada"] == True
E       assert False == True

tests\test_validador_etico.py:140: AssertionError</failure></testcase><testcase classname="tests.test_validador_etico" name="test_rejeicao_decisao_sem_documentacao" time="0.013"><failure message="KeyError: 'motivos_rejeicao'">def test_rejeicao_decisao_sem_documentacao():
        """Testa a rejeição de uma decisão sem documentação."""
        validador = ValidadorEtico(GerenciadorMemoria({
            "redis_host": "localhost",
            "redis_port": 6379,
            "redis_db": 0
        }))
    
        # Simular decisão sem documentação
        decisao = {
            "id": "test_5",
            "tipo": "manutencao",
            "contexto": {
                "documentacao": False,
                "rastreavel": True,
                "explicavel": True
            }
        }
    
        # Validar decisão
        resultado = validador.validar_decisao(decisao)
    
        # Verificar resultado
        assert resultado["aprovada"] == False
&gt;       assert "documentacao" in resultado["motivos_rejeicao"]
E       KeyError: 'motivos_rejeicao'

tests\test_validador_etico.py:168: KeyError</failure></testcase><testcase classname="tests.test_validador_etico" name="test_rejeicao_decisao_sem_rastreabilidade" time="0.018"><failure message="KeyError: 'motivos_rejeicao'">def test_rejeicao_decisao_sem_rastreabilidade():
        """Testa a rejeição de uma decisão sem rastreabilidade."""
        validador = ValidadorEtico(GerenciadorMemoria({
            "redis_host": "localhost",
            "redis_port": 6379,
            "redis_db": 0
        }))
    
        # Simular decisão sem rastreabilidade
        decisao = {
            "id": "test_6",
            "tipo": "hotfix",
            "contexto": {
                "documentacao": True,
                "rastreavel": False,
                "explicavel": True
            }
        }
    
        # Validar decisão
        resultado = validador.validar_decisao(decisao)
    
        # Verificar resultado
        assert resultado["aprovada"] == False
&gt;       assert "rastreabilidade" in resultado["motivos_rejeicao"]
E       KeyError: 'motivos_rejeicao'

tests\test_validador_etico.py:194: KeyError</failure></testcase><testcase classname="tests.test_validador_etico" name="test_rejeicao_decisao_sem_explicabilidade" time="0.017"><failure message="KeyError: 'motivos_rejeicao'">def test_rejeicao_decisao_sem_explicabilidade():
        """Testa a rejeição de uma decisão sem explicabilidade."""
        validador = ValidadorEtico(GerenciadorMemoria({
            "redis_host": "localhost",
            "redis_port": 6379,
            "redis_db": 0
        }))
    
        # Simular decisão sem explicabilidade
        decisao = {
            "id": "test_7",
            "tipo": "refatoracao",
            "contexto": {
                "documentacao": True,
                "rastreavel": True,
                "explicavel": False
            }
        }
    
        # Validar decisão
        resultado = validador.validar_decisao(decisao)
    
        # Verificar resultado
        assert resultado["aprovada"] == False
&gt;       assert "explicabilidade" in resultado["motivos_rejeicao"]
E       KeyError: 'motivos_rejeicao'

tests\test_validador_etico.py:220: KeyError</failure></testcase><testcase classname="tests.test_validador_etico" name="test_validacao_impacto_alto" time="0.018"><failure message="assert False == True">def test_validacao_impacto_alto():
        """Testa a validação de uma decisão com impacto alto."""
        validador = ValidadorEtico(GerenciadorMemoria({
            "redis_host": "localhost",
            "redis_port": 6379,
            "redis_db": 0
        }))
    
        # Simular decisão com impacto alto
        decisao = {
            "id": "test_8",
            "tipo": "redesign",
            "contexto": {
                "documentacao": True,
                "rastreavel": True,
                "explicavel": True,
                "impacto": "alto",
                "reversivel": True,
                "testes": True,
                "revisao": True,
                "aprovacao": True
            }
        }
    
        # Validar decisão
        resultado = validador.validar_decisao(decisao)
    
        # Verificar resultado
&gt;       assert resultado["aprovada"] == True
E       assert False == True

tests\test_validador_etico.py:250: AssertionError</failure></testcase><testcase classname="tests.test_validador_etico" name="test_validacao_impacto_baixo" time="0.021"><failure message="assert False == True">def test_validacao_impacto_baixo():
        """Testa a validação de uma decisão com impacto baixo."""
        validador = ValidadorEtico(GerenciadorMemoria({
            "redis_host": "localhost",
            "redis_port": 6379,
            "redis_db": 0
        }))
    
        # Simular decisão com impacto baixo
        decisao = {
            "id": "test_9",
            "tipo": "manutencao",
            "contexto": {
                "documentacao": True,
                "rastreavel": True,
                "explicavel": True,
                "impacto": "baixo",
                "reversivel": True
            }
        }
    
        # Validar decisão
        resultado = validador.validar_decisao(decisao)
    
        # Verificar resultado
&gt;       assert resultado["aprovada"] == True
E       assert False == True

tests\test_validador_etico.py:279: AssertionError</failure></testcase><testcase classname="tests.test_validador_etico" name="test_validacao_urgencia" time="0.026"><failure message="assert False == True">def test_validacao_urgencia():
        """Testa a validação de uma decisão com urgencia."""
        validador = ValidadorEtico(GerenciadorMemoria({
            "redis_host": "localhost",
            "redis_port": 6379,
            "redis_db": 0
        }))
    
        # Simular decisão com urgencia
        decisao = {
            "id": "test_10",
            "tipo": "hotfix",
            "contexto": {
                "documentacao": True,
                "rastreavel": True,
                "explicavel": True,
                "impacto": "medio",
                "reversivel": True,
                "urgencia": "alta",
                "testes": True
            }
        }
    
        # Validar decisão
        resultado = validador.validar_decisao(decisao)
    
        # Verificar resultado
&gt;       assert resultado["aprovada"] == True
E       assert False == True

tests\test_validador_etico.py:310: AssertionError</failure></testcase><testcase classname="tests.test_validador_etico" name="test_validacao_reversibilidade" time="0.024"><failure message="assert False == True">def test_validacao_reversibilidade():
        """Testa a validação de uma decisão com reversibilidade."""
        validador = ValidadorEtico(GerenciadorMemoria({
            "redis_host": "localhost",
            "redis_port": 6379,
            "redis_db": 0
        }))
    
        # Simular decisão com reversibilidade
        decisao = {
            "id": "test_11",
            "tipo": "refatoracao",
            "contexto": {
                "documentacao": True,
                "rastreavel": True,
                "explicavel": True,
                "impacto": "medio",
                "reversivel": True,
                "testes": True,
                "revisao": True
            }
        }
    
        # Validar decisão
        resultado = validador.validar_decisao(decisao)
    
        # Verificar resultado
&gt;       assert resultado["aprovada"] == True
E       assert False == True

tests\test_validador_etico.py:341: AssertionError</failure></testcase><testcase classname="tests.test_validador_etico" name="test_validacao_testes" time="0.021"><failure message="assert False == True">def test_validacao_testes():
        """Testa a validação de uma decisão com testes."""
        validador = ValidadorEtico(GerenciadorMemoria({
            "redis_host": "localhost",
            "redis_port": 6379,
            "redis_db": 0
        }))
    
        # Simular decisão com testes
        decisao = {
            "id": "test_12",
            "tipo": "hotfix",
            "contexto": {
                "documentacao": True,
                "rastreavel": True,
                "explicavel": True,
                "impacto": "medio",
                "reversivel": True,
                "urgencia": "alta",
                "testes": True
            }
        }
    
        # Validar decisão
        resultado = validador.validar_decisao(decisao)
    
        # Verificar resultado
&gt;       assert resultado["aprovada"] == True
E       assert False == True

tests\test_validador_etico.py:372: AssertionError</failure></testcase><testcase classname="tests.test_validador_etico" name="test_validacao_revisao" time="0.023"><failure message="assert False == True">def test_validacao_revisao():
        """Testa a validação de uma decisão com revisão."""
        validador = ValidadorEtico(GerenciadorMemoria({
            "redis_host": "localhost",
            "redis_port": 6379,
            "redis_db": 0
        }))
    
        # Simular decisão com revisão
        decisao = {
            "id": "test_13",
            "tipo": "refatoracao",
            "contexto": {
                "documentacao": True,
                "rastreavel": True,
                "explicavel": True,
                "impacto": "medio",
                "reversivel": True,
                "testes": True,
                "revisao": True
            }
        }
    
        # Validar decisão
        resultado = validador.validar_decisao(decisao)
    
        # Verificar resultado
&gt;       assert resultado["aprovada"] == True
E       assert False == True

tests\test_validador_etico.py:403: AssertionError</failure></testcase><testcase classname="tests.test_validador_etico" name="test_validacao_aprovacao" time="0.022"><failure message="assert False == True">def test_validacao_aprovacao():
        """Testa a validação de uma decisão com aprovação."""
        validador = ValidadorEtico(GerenciadorMemoria({
            "redis_host": "localhost",
            "redis_port": 6379,
            "redis_db": 0
        }))
    
        # Simular decisão com aprovação
        decisao = {
            "id": "test_14",
            "tipo": "redesign",
            "contexto": {
                "documentacao": True,
                "rastreavel": True,
                "explicavel": True,
                "impacto": "alto",
                "reversivel": True,
                "testes": True,
                "revisao": True,
                "aprovacao": True
            }
        }
    
        # Validar decisão
        resultado = validador.validar_decisao(decisao)
    
        # Verificar resultado
&gt;       assert resultado["aprovada"] == True
E       assert False == True

tests\test_validador_etico.py:435: AssertionError</failure></testcase><testcase classname="tests.test_validador_etico" name="test_validacao_preservacao_vida" time="0.022"><failure message="assert False == True">def test_validacao_preservacao_vida():
        """Testa a validação ética do pilar de preservação da vida."""
        validador = ValidadorEtico(GerenciadorMemoria({
            "redis_host": "localhost",
            "redis_port": 6379,
            "redis_db": 0
        }))
    
        # Simular decisão que afeta preservação da vida
        decisao = {
            "id": "test_11",
            "tipo": "redesign",
            "contexto": {
                "documentacao": True,
                "rastreavel": True,
                "explicavel": True,
                "impacto": "critico",
                "reversivel": True,
                "testes": True,
                "revisao": True,
                "aprovacao": True,
                "afeta_vida": True,
                "mitigacao_riscos": True,
                "plano_emergencia": True
            }
        }
    
        # Validar decisão
        resultado = validador.validar_decisao(decisao)
    
        # Verificar resultado
&gt;       assert resultado["aprovada"] == True
E       assert False == True

tests\test_validador_etico.py:470: AssertionError</failure></testcase><testcase classname="tests.test_validador_etico" name="test_validacao_equidade_global" time="0.025"><failure message="assert False == True">def test_validacao_equidade_global():
        """Testa a validação ética do pilar de equidade global."""
        validador = ValidadorEtico(GerenciadorMemoria({
            "redis_host": "localhost",
            "redis_port": 6379,
            "redis_db": 0
        }))
    
        # Simular decisão que afeta equidade global
        decisao = {
            "id": "test_12",
            "tipo": "redesign",
            "contexto": {
                "documentacao": True,
                "rastreavel": True,
                "explicavel": True,
                "impacto": "alto",
                "reversivel": True,
                "testes": True,
                "revisao": True,
                "aprovacao": True,
                "afeta_equidade": True,
                "analise_impacto": {
                    "grupos_afetados": ["todos"],
                    "distribuicao_beneficios": "equitativa",
                    "mitigacao_desigualdades": True
                }
            }
        }
    
        # Validar decisão
        resultado = validador.validar_decisao(decisao)
    
        # Verificar resultado
&gt;       assert resultado["aprovada"] == True
E       assert False == True

tests\test_validador_etico.py:510: AssertionError</failure></testcase><testcase classname="tests.test_validador_etico" name="test_validacao_transparencia_radical" time="0.024"><failure message="assert False == True">def test_validacao_transparencia_radical():
        """Testa a validação ética do pilar de transparência radical."""
        validador = ValidadorEtico(GerenciadorMemoria({
            "redis_host": "localhost",
            "redis_port": 6379,
            "redis_db": 0
        }))
    
        # Simular decisão que requer transparência radical
        decisao = {
            "id": "test_13",
            "tipo": "redesign",
            "contexto": {
                "documentacao": True,
                "rastreavel": True,
                "explicavel": True,
                "impacto": "alto",
                "reversivel": True,
                "testes": True,
                "revisao": True,
                "aprovacao": True,
                "transparencia": {
                    "publico": True,
                    "detalhamento_completo": True,
                    "auditoria_publica": True,
                    "registro_imutavel": True
                }
            }
        }
    
        # Validar decisão
        resultado = validador.validar_decisao(decisao)
    
        # Verificar resultado
&gt;       assert resultado["aprovada"] == True
E       assert False == True

tests\test_validador_etico.py:549: AssertionError</failure></testcase><testcase classname="tests.test_validador_etico" name="test_validacao_sustentabilidade" time="0.023"><failure message="assert False == True">def test_validacao_sustentabilidade():
        """Testa a validação ética do pilar de sustentabilidade."""
        validador = ValidadorEtico(GerenciadorMemoria({
            "redis_host": "localhost",
            "redis_port": 6379,
            "redis_db": 0
        }))
    
        # Simular decisão que afeta sustentabilidade
        decisao = {
            "id": "test_14",
            "tipo": "redesign",
            "contexto": {
                "documentacao": True,
                "rastreavel": True,
                "explicavel": True,
                "impacto": "alto",
                "reversivel": True,
                "testes": True,
                "revisao": True,
                "aprovacao": True,
                "sustentabilidade": {
                    "impacto_ambiental": "minimo",
                    "recursos_renovaveis": True,
                    "ciclo_vida": "longo",
                    "descarte_seguro": True
                }
            }
        }
    
        # Validar decisão
        resultado = validador.validar_decisao(decisao)
    
        # Verificar resultado
&gt;       assert resultado["aprovada"] == True
E       assert False == True

tests\test_validador_etico.py:588: AssertionError</failure></testcase><testcase classname="tests.test_validador_etico" name="test_validacao_controle_humano" time="0.028"><failure message="assert False == True">def test_validacao_controle_humano():
        """Testa a validação ética do pilar de controle humano residual."""
        validador = ValidadorEtico(GerenciadorMemoria({
            "redis_host": "localhost",
            "redis_port": 6379,
            "redis_db": 0
        }))
    
        # Simular decisão que requer controle humano
        decisao = {
            "id": "test_15",
            "tipo": "redesign",
            "contexto": {
                "documentacao": True,
                "rastreavel": True,
                "explicavel": True,
                "impacto": "critico",
                "reversivel": True,
                "testes": True,
                "revisao": True,
                "aprovacao": True,
                "controle_humano": {
                    "supervisao_continua": True,
                    "veto_humano": True,
                    "intervencao_manual": True,
                    "auditoria_humana": True
                }
            }
        }
    
        # Validar decisão
        resultado = validador.validar_decisao(decisao)
    
        # Verificar resultado
&gt;       assert resultado["aprovada"] == True
E       assert False == True

tests\test_validador_etico.py:627: AssertionError</failure></testcase><testcase classname="tests.test_validador_etico" name="test_validacao_lgpd_gdpr" time="0.051"><failure message="assert False == True">def test_validacao_lgpd_gdpr():
        """Testa a validação de conformidade com LGPD/GDPR."""
        validador = ValidadorEtico(GerenciadorMemoria({
            "redis_host": "localhost",
            "redis_port": 6379,
            "redis_db": 0
        }))
    
        # Simular decisão que lida com dados pessoais
        decisao = {
            "id": "test_16",
            "tipo": "redesign",
            "contexto": {
                "documentacao": True,
                "rastreavel": True,
                "explicavel": True,
                "impacto": "alto",
                "reversivel": True,
                "testes": True,
                "revisao": True,
                "aprovacao": True,
                "dados_pessoais": {
                    "consentimento": True,
                    "finalidade_especifica": True,
                    "minimizacao": True,
                    "seguranca": True,
                    "direitos_titulares": True,
                    "transferencia_internacional": False
                }
            }
        }
    
        # Validar decisão
        resultado = validador.validar_decisao(decisao)
    
        # Verificar resultado
&gt;       assert resultado["aprovada"] == True
E       assert False == True

tests\test_validador_etico.py:668: AssertionError</failure></testcase><testcase classname="tests.test_validador_etico" name="test_validacao_viés_equidade" time="0.029"><failure message="assert False == True">def test_validacao_viés_equidade():
        """Testa a validação de viés e equidade nas decisões."""
        validador = ValidadorEtico(GerenciadorMemoria({
            "redis_host": "localhost",
            "redis_port": 6379,
            "redis_db": 0
        }))
    
        # Simular decisão que requer análise de viés
        decisao = {
            "id": "test_17",
            "tipo": "redesign",
            "contexto": {
                "documentacao": True,
                "rastreavel": True,
                "explicavel": True,
                "impacto": "alto",
                "reversivel": True,
                "testes": True,
                "revisao": True,
                "aprovacao": True,
                "analise_vies": {
                    "grupos_afetados": ["todos"],
                    "metricas_equidade": True,
                    "testes_vies": True,
                    "mitigacao_vies": True,
                    "monitoramento_continuo": True
                }
            }
        }
    
        # Validar decisão
        resultado = validador.validar_decisao(decisao)
    
        # Verificar resultado
&gt;       assert resultado["aprovada"] == True
E       assert False == True

tests\test_validador_etico.py:708: AssertionError</failure></testcase><testcase classname="tests.test_validador_etico" name="test_validacao_decisao_financeira" time="0.036"><failure message="assert False == True">def test_validacao_decisao_financeira():
        """Testa a validação ética de decisões financeiras."""
        validador = ValidadorEtico(GerenciadorMemoria({
            "redis_host": "localhost",
            "redis_port": 6379,
            "redis_db": 0
        }))
    
        # Simular decisão financeira
        decisao = {
            "id": "test_18",
            "tipo": "redesign",
            "contexto": {
                "documentacao": True,
                "rastreavel": True,
                "explicavel": True,
                "impacto": "alto",
                "reversivel": True,
                "testes": True,
                "revisao": True,
                "aprovacao": True,
                "aspectos_financeiros": {
                    "tokenizacao_impacto": True,
                    "simulacao_cenarios": True,
                    "equidade_distributiva": True,
                    "sustentabilidade_financeira": True,
                    "transparencia_radical": True
                }
            }
        }
    
        # Validar decisão
        resultado = validador.validar_decisao(decisao)
    
        # Verificar resultado
&gt;       assert resultado["aprovada"] == True
E       assert False == True

tests\test_validador_etico.py:748: AssertionError</failure></testcase><testcase classname="tests.test_validador_etico" name="test_validacao_cenario_extremo" time="0.030"><failure message="assert False == True">def test_validacao_cenario_extremo():
        """Testa a validação ética em cenário extremo."""
        validador = ValidadorEtico(GerenciadorMemoria({
            "redis_host": "localhost",
            "redis_port": 6379,
            "redis_db": 0
        }))
    
        # Simular decisão em cenário extremo
        decisao = {
            "id": "test_19",
            "tipo": "redesign",
            "contexto": {
                "documentacao": True,
                "rastreavel": True,
                "explicavel": True,
                "impacto": "critico",
                "reversivel": True,
                "testes": True,
                "revisao": True,
                "aprovacao": True,
                "cenario_extremo": {
                    "simulacao_completa": True,
                    "analise_consequencias": True,
                    "planos_contingencia": True,
                    "monitoramento_intensivo": True,
                    "reversao_automatica": True
                }
            }
        }
    
        # Validar decisão
        resultado = validador.validar_decisao(decisao)
    
        # Verificar resultado
&gt;       assert resultado["aprovada"] == True
E       assert False == True

tests\test_validador_etico.py:788: AssertionError</failure></testcase><testcase classname="tests.unit.test_dependencias" name="test_registrar_problema" time="0.002" /><testcase classname="tests.unit.test_dependencias" name="test_carregar_historico" time="0.026"><failure message="AssertionError: assert 2 == 1&#10; +  where 2 = len([ProblemaDependencia(pacote='test-package', versao='1.0.0', erro='Erro de teste', solucao='Solu\xe7\xe3o de teste', data_ocorrencia=datetime.datetime(2025, 5, 20, 22, 13, 26, 140367), resolvido=False), ProblemaDependencia(pacote='test-package', versao='1.0.0', erro='Erro de teste', solucao='Solu\xe7\xe3o de teste', data_ocorrencia=datetime.datetime(2025, 5, 20, 22, 13, 26, 152012), resolvido=False)])&#10; +    where [ProblemaDependencia(pacote='test-package', versao='1.0.0', erro='Erro de teste', solucao='Solu\xe7\xe3o de teste', data_ocorrencia=datetime.datetime(2025, 5, 20, 22, 13, 26, 140367), resolvido=False), ProblemaDependencia(pacote='test-package', versao='1.0.0', erro='Erro de teste', solucao='Solu\xe7\xe3o de teste', data_ocorrencia=datetime.datetime(2025, 5, 20, 22, 13, 26, 152012), resolvido=False)] = &lt;src.autocura.dependencias.GerenciadorDependencias object at 0x0000024725B73820&gt;.historico">gerenciador = &lt;src.autocura.dependencias.GerenciadorDependencias object at 0x0000024725C54510&gt;
problema_exemplo = ProblemaDependencia(pacote='test-package', versao='1.0.0', erro='Erro de teste', solucao='Solução de teste', data_ocorrencia=datetime.datetime(2025, 5, 20, 22, 13, 26, 151540), resolvido=False)

    def test_carregar_historico(gerenciador, problema_exemplo):
        """Testa o carregamento do histórico de problemas."""
        # Registra um problema
        gerenciador.registrar_problema(
            pacote=problema_exemplo.pacote,
            versao=problema_exemplo.versao,
            erro=problema_exemplo.erro,
            solucao=problema_exemplo.solucao
        )
    
        # Cria novo gerenciador para carregar o histórico
        novo_gerenciador = GerenciadorDependencias(arquivo_historico=gerenciador.arquivo_historico)
    
&gt;       assert len(novo_gerenciador.historico) == 1
E       AssertionError: assert 2 == 1
E        +  where 2 = len([ProblemaDependencia(pacote='test-package', versao='1.0.0', erro='Erro de teste', solucao='Solu\xe7\xe3o de teste', data_ocorrencia=datetime.datetime(2025, 5, 20, 22, 13, 26, 140367), resolvido=False), ProblemaDependencia(pacote='test-package', versao='1.0.0', erro='Erro de teste', solucao='Solu\xe7\xe3o de teste', data_ocorrencia=datetime.datetime(2025, 5, 20, 22, 13, 26, 152012), resolvido=False)])
E        +    where [ProblemaDependencia(pacote='test-package', versao='1.0.0', erro='Erro de teste', solucao='Solu\xe7\xe3o de teste', data_ocorrencia=datetime.datetime(2025, 5, 20, 22, 13, 26, 140367), resolvido=False), ProblemaDependencia(pacote='test-package', versao='1.0.0', erro='Erro de teste', solucao='Solu\xe7\xe3o de teste', data_ocorrencia=datetime.datetime(2025, 5, 20, 22, 13, 26, 152012), resolvido=False)] = &lt;src.autocura.dependencias.GerenciadorDependencias object at 0x0000024725B73820&gt;.historico

tests\unit\test_dependencias.py:54: AssertionError</failure></testcase><testcase classname="tests.unit.test_dependencias" name="test_verificar_compatibilidade_python" time="0.002"><failure message="assert False is True&#10; +  where False = verificar_compatibilidade_python()&#10; +    where verificar_compatibilidade_python = &lt;src.autocura.dependencias.GerenciadorDependencias object at 0x0000024725D0C290&gt;.verificar_compatibilidade_python">mock_version = &lt;MagicMock name='python_version_tuple' id='2504599178608'&gt;
gerenciador = &lt;src.autocura.dependencias.GerenciadorDependencias object at 0x0000024725D0C290&gt;

    @patch('platform.python_version_tuple')
    def test_verificar_compatibilidade_python(mock_version, gerenciador):
        """Testa a verificação de compatibilidade do Python."""
        # Testa versão compatível (3.10)
        mock_version.return_value = ('3', '10', '0')
&gt;       assert gerenciador.verificar_compatibilidade_python() is True
E       assert False is True
E        +  where False = verificar_compatibilidade_python()
E        +    where verificar_compatibilidade_python = &lt;src.autocura.dependencias.GerenciadorDependencias object at 0x0000024725D0C290&gt;.verificar_compatibilidade_python

tests\unit\test_dependencias.py:62: AssertionError</failure></testcase><testcase classname="tests.unit.test_dependencias" name="test_verificar_dependencias_sistema" time="0.003" /><testcase classname="tests.unit.test_dependencias" name="test_sugerir_solucao" time="0.002" /><testcase classname="tests.unit.test_dependencias" name="test_executar_autocura" time="0.009"><failure message="assert False is True&#10; +  where False = executar_autocura()&#10; +    where executar_autocura = &lt;src.autocura.dependencias.GerenciadorDependencias object at 0x0000024725D3CB50&gt;.executar_autocura">mock_run = &lt;MagicMock name='run' id='2504599179616'&gt;
gerenciador = &lt;src.autocura.dependencias.GerenciadorDependencias object at 0x0000024725D3CB50&gt;

    @patch('subprocess.run')
    def test_executar_autocura(mock_run, gerenciador):
        """Testa o processo de autocura."""
        # Simula instalação bem-sucedida
        mock_run.return_value = MagicMock(returncode=0)
&gt;       assert gerenciador.executar_autocura() is True
E       assert False is True
E        +  where False = executar_autocura()
E        +    where executar_autocura = &lt;src.autocura.dependencias.GerenciadorDependencias object at 0x0000024725D3CB50&gt;.executar_autocura

tests\unit\test_dependencias.py:104: AssertionError</failure></testcase><testcase classname="tests.unit.test_dependencias" name="test_limpeza_arquivo_historico" time="0.002" /><testcase classname="tests.unit.test_processador.TestProcessador" name="test_validacao_dados_entrada" time="0.001" /><testcase classname="tests.unit.test_processador.TestProcessador" name="test_transformacao_dados" time="0.001" /><testcase classname="tests.unit.test_processador.TestProcessador" name="test_tratamento_erros" time="0.001"><failure message="AssertionError: assert 0 &gt; 0&#10; +  where 0 = &lt;MagicMock name='sleep' id='2504599178608'&gt;.call_count">self = &lt;test_processador.TestProcessador object at 0x000002471E5DCB00&gt;

    def test_tratamento_erros(self) -&gt; None:
        """
        Testa o tratamento de erros.
    
        Verifica:
        1. Erros são capturados
        2. Mensagens de erro são apropriadas
        3. Sistema se recupera
        """
        # Arrange
        dados_entrada = {
            "id": "test_123",
            "dados": [1, 2, 3],
            "timestamp": datetime.now().isoformat()
        }
    
        # Act &amp; Assert
        with patch("time.sleep") as mock_sleep:
            resultado = self._processar_com_tratamento_erro(dados_entrada)
            assert resultado["status"] == "success"
            assert mock_sleep.call_count == 0
    
        # Testa com erro
        with patch("time.sleep") as mock_sleep:
            with patch.object(self, "_processar_dados", side_effect=Exception("Erro teste")):
                resultado = self._processar_com_tratamento_erro(dados_entrada)
                assert resultado["status"] == "error"
&gt;               assert mock_sleep.call_count &gt; 0
E               AssertionError: assert 0 &gt; 0
E                +  where 0 = &lt;MagicMock name='sleep' id='2504599178608'&gt;.call_count

tests\unit\test_processador.py:108: AssertionError</failure></testcase><testcase classname="tests.unit.test_processador.TestProcessador" name="test_casos_limite" time="1.905" /></testsuite></testsuites>