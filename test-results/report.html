<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8"/>
    <title id="head-title">report.html</title>
      <link href="assets\style.css" rel="stylesheet" type="text/css"/>
  </head>
  <body>
    <h1 id="title">report.html</h1>
    <p>Report generated on 21-May-2025 at 16:07:40 by <a href="https://pypi.python.org/pypi/pytest-html">pytest-html</a>
        v4.1.1</p>
    <div id="environment-header">
      <h2>Environment</h2>
    </div>
    <table id="environment"></table>
    <!-- TEMPLATES -->
      <template id="template_environment_row">
      <tr>
        <td></td>
        <td></td>
      </tr>
    </template>
    <template id="template_results-table__body--empty">
      <tbody class="results-table-row">
        <tr id="not-found-message">
          <td colspan="4">No results found. Check the filters.</th>
        </tr>
    </template>
    <template id="template_results-table__tbody">
      <tbody class="results-table-row">
        <tr class="collapsible">
        </tr>
        <tr class="extras-row">
          <td class="extra" colspan="4">
            <div class="extraHTML"></div>
            <div class="media">
              <div class="media-container">
                  <div class="media-container__nav--left"><</div>
                  <div class="media-container__viewport">
                    <img src="" />
                    <video controls>
                      <source src="" type="video/mp4">
                    </video>
                  </div>
                  <div class="media-container__nav--right">></div>
                </div>
                <div class="media__name"></div>
                <div class="media__counter"></div>
            </div>
            <div class="logwrapper">
              <div class="logexpander"></div>
              <div class="log"></div>
            </div>
          </td>
        </tr>
      </tbody>
    </template>
    <!-- END TEMPLATES -->
    <div class="summary">
      <div class="summary__data">
        <h2>Summary</h2>
        <div class="additional-summary prefix">
        </div>
        <p class="run-count">7 tests took 00:00:18.</p>
        <p class="filter">(Un)check the boxes to filter the results.</p>
        <div class="summary__reload">
          <div class="summary__reload__button hidden" onclick="location.reload()">
            <div>There are still tests running. <br />Reload this page to get the latest results!</div>
          </div>
        </div>
        <div class="summary__spacer"></div>
        <div class="controls">
          <div class="filters">
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="failed" />
            <span class="failed">3 Failed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="passed" />
            <span class="passed">4 Passed,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="skipped" disabled/>
            <span class="skipped">0 Skipped,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xfailed" disabled/>
            <span class="xfailed">0 Expected failures,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="xpassed" disabled/>
            <span class="xpassed">0 Unexpected passes,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="error" disabled/>
            <span class="error">0 Errors,</span>
            <input checked="true" class="filter" name="filter_checkbox" type="checkbox" data-test-result="rerun" disabled/>
            <span class="rerun">0 Reruns</span>
          </div>
          <div class="collapse">
            <button id="show_all_details">Show all details</button>&nbsp;/&nbsp;<button id="hide_all_details">Hide all details</button>
          </div>
        </div>
      </div>
      <div class="additional-summary summary">
      </div>
      <div class="additional-summary postfix">
      </div>
    </div>
    <table id="results-table">
      <thead id="results-table-head">
        <tr>
          <th class="sortable" data-column-type="result">Result</th>
          <th class="sortable" data-column-type="testId">Test</th>
          <th class="sortable" data-column-type="duration">Duration</th>
          <th>Links</th>
        </tr>
      </thead>
    </table>
  </body>
  <footer>
    <div id="data-container" data-jsonblob="{&#34;environment&#34;: {&#34;Python&#34;: &#34;3.13.3&#34;, &#34;Platform&#34;: &#34;Windows-11-10.0.26100-SP0&#34;, &#34;Packages&#34;: {&#34;pytest&#34;: &#34;7.4.0&#34;, &#34;pluggy&#34;: &#34;1.6.0&#34;}, &#34;Plugins&#34;: {&#34;asyncio&#34;: &#34;0.21.1&#34;, &#34;anyio&#34;: &#34;4.9.0&#34;, &#34;langsmith&#34;: &#34;0.3.42&#34;, &#34;cov&#34;: &#34;6.1.1&#34;, &#34;html&#34;: &#34;4.1.1&#34;, &#34;metadata&#34;: &#34;3.1.1&#34;}}, &#34;tests&#34;: {&#34;tests/integration/test_dependencias_integration.py::test_fluxo_completo_autocura&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/integration/test_dependencias_integration.py::test_fluxo_completo_autocura&#34;, &#34;duration&#34;: &#34;00:00:02&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/integration/test_dependencias_integration.py::test_fluxo_completo_autocura&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:02&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stderr call -----------------------------\n2025-05-21 16:07:16,765 - src.autocura.dependencias - INFO - Problema registrado para pytest 7.4.0\n\n------------------------------ Captured log call -------------------------------\nINFO     src.autocura.dependencias:dependencias.py:86 Problema registrado para pytest 7.4.0\n\n&#34;}], &#34;tests/integration/test_dependencias_integration.py::test_historico_persistencia&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/integration/test_dependencias_integration.py::test_historico_persistencia&#34;, &#34;duration&#34;: &#34;3 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/integration/test_dependencias_integration.py::test_historico_persistencia&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;3 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stderr call -----------------------------\n2025-05-21 16:07:18,343 - src.autocura.dependencias - INFO - Problema registrado para pytest 7.4.0\n2025-05-21 16:07:18,343 - src.autocura.dependencias - INFO - Problema registrado para prometheus-client 0.17.1\n\n------------------------------ Captured log call -------------------------------\nINFO     src.autocura.dependencias:dependencias.py:86 Problema registrado para pytest 7.4.0\nINFO     src.autocura.dependencias:dependencias.py:86 Problema registrado para prometheus-client 0.17.1\n\n&#34;}], &#34;tests/integration/test_dependencias_integration.py::test_sugestao_solucao_integracao&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/integration/test_dependencias_integration.py::test_sugestao_solucao_integracao&#34;, &#34;duration&#34;: &#34;2 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/integration/test_dependencias_integration.py::test_sugestao_solucao_integracao&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;2 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;----------------------------- Captured stderr call -----------------------------\n2025-05-21 16:07:18,346 - src.autocura.dependencias - INFO - Problema registrado para pytest 7.4.0\n\n------------------------------ Captured log call -------------------------------\nINFO     src.autocura.dependencias:dependencias.py:86 Problema registrado para pytest 7.4.0\n\n&#34;}], &#34;tests/integration/test_dependencias_integration.py::test_limpeza_arquivo_historico&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Passed&#34;, &#34;testId&#34;: &#34;tests/integration/test_dependencias_integration.py::test_limpeza_arquivo_historico&#34;, &#34;duration&#34;: &#34;1 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Passed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/integration/test_dependencias_integration.py::test_limpeza_arquivo_historico&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;1 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;No log output captured.&#34;}], &#34;tests/integration/test_sistema_completo.py::TestSistemaCompleto::test_fluxo_completo_processamento&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/integration/test_sistema_completo.py::TestSistemaCompleto::test_fluxo_completo_processamento&#34;, &#34;duration&#34;: &#34;14 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/integration/test_sistema_completo.py::TestSistemaCompleto::test_fluxo_completo_processamento&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;14 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.integration.test_sistema_completo.TestSistemaCompleto object at 0x000001E7F1450E10&amp;gt;\nmock_elasticsearch = &amp;lt;MagicMock name=&amp;#x27;Elasticsearch&amp;#x27; id=&amp;#x27;2095696945776&amp;#x27;&amp;gt;\n\n    def test_fluxo_completo_processamento(self, mock_elasticsearch):\n        &amp;quot;&amp;quot;&amp;quot;Testa o fluxo completo de processamento de dados.&amp;quot;&amp;quot;&amp;quot;\n        # Configura\u00e7\u00e3o inicial\n        sistema = SistemaAutocura()\n        registry = CollectorRegistry()\n        monitor = MonitoramentoTestes(registry=registry)\n    \n        # Dados de teste\n        dados = {\n            &amp;#x27;id&amp;#x27;: &amp;#x27;test_001&amp;#x27;,\n            &amp;#x27;dados&amp;#x27;: [1, 2, 3],\n            &amp;#x27;timestamp&amp;#x27;: &amp;#x27;2025-05-21T15:58:28&amp;#x27;\n        }\n    \n        # Execu\u00e7\u00e3o do processamento\n        resultado = sistema.processar_dados(dados)\n    \n        # Verifica\u00e7\u00f5es\n        assert resultado[&amp;#x27;status&amp;#x27;] == &amp;#x27;success&amp;#x27;\n        assert &amp;#x27;processado_em&amp;#x27; in resultado\n&amp;gt;       assert mock_elasticsearch.called\nE       AssertionError: assert False\nE        +  where False = &amp;lt;MagicMock name=&amp;#x27;Elasticsearch&amp;#x27; id=&amp;#x27;2095696945776&amp;#x27;&amp;gt;.called\n\ntests\\integration\\test_sistema_completo.py:64: AssertionError\n&#34;}], &#34;tests/integration/test_sistema_completo.py::TestSistemaCompleto::test_recuperacao_falha&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/integration/test_sistema_completo.py::TestSistemaCompleto::test_recuperacao_falha&#34;, &#34;duration&#34;: &#34;12 ms&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/integration/test_sistema_completo.py::TestSistemaCompleto::test_recuperacao_falha&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;12 ms&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;tests.integration.test_sistema_completo.TestSistemaCompleto object at 0x000001E7F1450F50&amp;gt;\nmock_elasticsearch = &amp;lt;MagicMock name=&amp;#x27;Elasticsearch&amp;#x27; id=&amp;#x27;2095697776656&amp;#x27;&amp;gt;\n\n    def test_recuperacao_falha(self, mock_elasticsearch):\n        &amp;quot;&amp;quot;&amp;quot;Testa o processo de recupera\u00e7\u00e3o ap\u00f3s uma falha.&amp;quot;&amp;quot;&amp;quot;\n        # Configura\u00e7\u00e3o inicial\n        sistema = SistemaAutocura()\n        registry = CollectorRegistry()\n        monitor = MonitoramentoTestes(registry=registry)\n    \n        # Dados de teste\n        dados = {\n            &amp;#x27;id&amp;#x27;: &amp;#x27;test_002&amp;#x27;,\n            &amp;#x27;dados&amp;#x27;: [4, 5, 6],\n            &amp;#x27;timestamp&amp;#x27;: &amp;#x27;2025-05-21T15:58:29&amp;#x27;\n        }\n    \n        # Simula falha e recupera\u00e7\u00e3o\n        mock_elasticsearch.return_value.index.side_effect = [\n            Exception(&amp;quot;Erro tempor\u00e1rio&amp;quot;),\n            {&amp;#x27;_id&amp;#x27;: &amp;#x27;test_id&amp;#x27;, &amp;#x27;result&amp;#x27;: &amp;#x27;created&amp;#x27;}\n        ]\n    \n        # Execu\u00e7\u00e3o com retry\n        resultado = sistema.processar_dados(dados, max_retries=3)\n    \n        # Verifica\u00e7\u00f5es\n        assert resultado[&amp;#x27;status&amp;#x27;] == &amp;#x27;success&amp;#x27;\n&amp;gt;       assert mock_elasticsearch.call_count == 2\nE       AssertionError: assert 0 == 2\nE        +  where 0 = &amp;lt;MagicMock name=&amp;#x27;Elasticsearch&amp;#x27; id=&amp;#x27;2095697776656&amp;#x27;&amp;gt;.call_count\n\ntests\\integration\\test_sistema_completo.py:96: AssertionError\n&#34;}], &#34;tests/integration/test_sistema_completo.py::TestSistemaCompleto::test_processamento_concorrente&#34;: [{&#34;extras&#34;: [], &#34;result&#34;: &#34;Failed&#34;, &#34;testId&#34;: &#34;tests/integration/test_sistema_completo.py::TestSistemaCompleto::test_processamento_concorrente&#34;, &#34;duration&#34;: &#34;00:00:17&#34;, &#34;resultsTableRow&#34;: [&#34;&lt;td class=\&#34;col-result\&#34;&gt;Failed&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-testId\&#34;&gt;tests/integration/test_sistema_completo.py::TestSistemaCompleto::test_processamento_concorrente&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-duration\&#34;&gt;00:00:17&lt;/td&gt;&#34;, &#34;&lt;td class=\&#34;col-links\&#34;&gt;&lt;/td&gt;&#34;], &#34;log&#34;: &#34;self = &amp;lt;urllib3.connection.HTTPConnection object at 0x000001E7F1B91F30&amp;gt;\n\n    def _new_conn(self) -&amp;gt; socket.socket:\n        &amp;quot;&amp;quot;&amp;quot;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        &amp;quot;&amp;quot;&amp;quot;\n        try:\n&amp;gt;           sock = connection.create_connection(\n                (self._dns_host, self.port),\n                self.timeout,\n                source_address=self.source_address,\n                socket_options=self.socket_options,\n            )\n\nC:\\Python313\\Lib\\site-packages\\urllib3\\connection.py:198: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\naddress = (&amp;#x27;localhost&amp;#x27;, 9200), timeout = 10.0, source_address = None\nsocket_options = [(6, 1, 1)]\n\n    def create_connection(\n        address: tuple[str, int],\n        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n        source_address: tuple[str, int] | None = None,\n        socket_options: _TYPE_SOCKET_OPTIONS | None = None,\n    ) -&amp;gt; socket.socket:\n        &amp;quot;&amp;quot;&amp;quot;Connect to *address* and return the socket object.\n    \n        Convenience function.  Connect to *address* (a 2-tuple ``(host,\n        port)``) and return the socket object.  Passing the optional\n        *timeout* parameter will set the timeout on the socket instance\n        before attempting to connect.  If no *timeout* is supplied, the\n        global default timeout setting returned by :func:`socket.getdefaulttimeout`\n        is used.  If *source_address* is set it must be a tuple of (host, port)\n        for the socket to bind as a source address before making the connection.\n        An host of &amp;#x27;&amp;#x27; or port 0 tells the OS to use the default.\n        &amp;quot;&amp;quot;&amp;quot;\n    \n        host, port = address\n        if host.startswith(&amp;quot;[&amp;quot;):\n            host = host.strip(&amp;quot;[]&amp;quot;)\n        err = None\n    \n        # Using the value from allowed_gai_family() in the context of getaddrinfo lets\n        # us select whether to work with IPv4 DNS records, IPv6 records, or both.\n        # The original create_connection function always returns all records.\n        family = allowed_gai_family()\n    \n        try:\n            host.encode(&amp;quot;idna&amp;quot;)\n        except UnicodeError:\n            raise LocationParseError(f&amp;quot;&amp;#x27;{host}&amp;#x27;, label empty or too long&amp;quot;) from None\n    \n        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n            af, socktype, proto, canonname, sa = res\n            sock = None\n            try:\n                sock = socket.socket(af, socktype, proto)\n    \n                # If provided, set socket level options before connecting.\n                _set_socket_options(sock, socket_options)\n    \n                if timeout is not _DEFAULT_TIMEOUT:\n                    sock.settimeout(timeout)\n                if source_address:\n                    sock.bind(source_address)\n                sock.connect(sa)\n                # Break explicitly a reference cycle\n                err = None\n                return sock\n    \n            except OSError as _:\n                err = _\n                if sock is not None:\n                    sock.close()\n    \n        if err is not None:\n            try:\n&amp;gt;               raise err\n\nC:\\Python313\\Lib\\site-packages\\urllib3\\util\\connection.py:85: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\naddress = (&amp;#x27;localhost&amp;#x27;, 9200), timeout = 10.0, source_address = None\nsocket_options = [(6, 1, 1)]\n\n    def create_connection(\n        address: tuple[str, int],\n        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n        source_address: tuple[str, int] | None = None,\n        socket_options: _TYPE_SOCKET_OPTIONS | None = None,\n    ) -&amp;gt; socket.socket:\n        &amp;quot;&amp;quot;&amp;quot;Connect to *address* and return the socket object.\n    \n        Convenience function.  Connect to *address* (a 2-tuple ``(host,\n        port)``) and return the socket object.  Passing the optional\n        *timeout* parameter will set the timeout on the socket instance\n        before attempting to connect.  If no *timeout* is supplied, the\n        global default timeout setting returned by :func:`socket.getdefaulttimeout`\n        is used.  If *source_address* is set it must be a tuple of (host, port)\n        for the socket to bind as a source address before making the connection.\n        An host of &amp;#x27;&amp;#x27; or port 0 tells the OS to use the default.\n        &amp;quot;&amp;quot;&amp;quot;\n    \n        host, port = address\n        if host.startswith(&amp;quot;[&amp;quot;):\n            host = host.strip(&amp;quot;[]&amp;quot;)\n        err = None\n    \n        # Using the value from allowed_gai_family() in the context of getaddrinfo lets\n        # us select whether to work with IPv4 DNS records, IPv6 records, or both.\n        # The original create_connection function always returns all records.\n        family = allowed_gai_family()\n    \n        try:\n            host.encode(&amp;quot;idna&amp;quot;)\n        except UnicodeError:\n            raise LocationParseError(f&amp;quot;&amp;#x27;{host}&amp;#x27;, label empty or too long&amp;quot;) from None\n    \n        for res in socket.getaddrinfo(host, port, family, socket.SOCK_STREAM):\n            af, socktype, proto, canonname, sa = res\n            sock = None\n            try:\n                sock = socket.socket(af, socktype, proto)\n    \n                # If provided, set socket level options before connecting.\n                _set_socket_options(sock, socket_options)\n    \n                if timeout is not _DEFAULT_TIMEOUT:\n                    sock.settimeout(timeout)\n                if source_address:\n                    sock.bind(source_address)\n&amp;gt;               sock.connect(sa)\nE               ConnectionRefusedError: [WinError 10061] Nenhuma conex\u00e3o p\u00f4de ser feita porque a m\u00e1quina de destino as recusou ativamente\n\nC:\\Python313\\Lib\\site-packages\\urllib3\\util\\connection.py:73: ConnectionRefusedError\n\nThe above exception was the direct cause of the following exception:\n\nself = &amp;lt;Urllib3HttpNode(http://localhost:9200)&amp;gt;, method = &amp;#x27;POST&amp;#x27;\ntarget = &amp;#x27;/autocura-testes-2025.05.21/_doc&amp;#x27;\nbody = b&amp;#x27;{&amp;quot;timestamp&amp;quot;:&amp;quot;2025-05-21T16:07:18.546552&amp;quot;,&amp;quot;nome&amp;quot;:&amp;quot;test_processamento_concorrente&amp;quot;,&amp;quot;sucesso&amp;quot;:true,&amp;quot;duracao&amp;quot;:1.8835067749023438e-05}&amp;#x27;\nheaders = {&amp;#x27;accept&amp;#x27;: &amp;#x27;application/vnd.elasticsearch+json; compatible-with=9&amp;#x27;, &amp;#x27;content-type&amp;#x27;: &amp;#x27;application/vnd.elasticsearch+json; compatible-with=9&amp;#x27;, &amp;#x27;x-elastic-client-meta&amp;#x27;: &amp;#x27;es=9.0.1,py=3.13.3,t=8.17.1,ur=2.4.0&amp;#x27;}\nrequest_timeout = &amp;lt;DEFAULT&amp;gt;\n\n    def perform_request(\n        self,\n        method: str,\n        target: str,\n        body: Optional[bytes] = None,\n        headers: Optional[HttpHeaders] = None,\n        request_timeout: Union[DefaultType, Optional[float]] = DEFAULT,\n    ) -&amp;gt; NodeApiResponse:\n        if self.path_prefix:\n            target = f&amp;quot;{self.path_prefix}{target}&amp;quot;\n    \n        start = time.time()\n        try:\n            kw = {}\n            if request_timeout is not DEFAULT:\n                kw[&amp;quot;timeout&amp;quot;] = request_timeout\n    \n            request_headers = self._headers.copy()\n            if headers:\n                request_headers.update(headers)\n    \n            body_to_send: Optional[bytes]\n            if body:\n                if self._http_compress:\n                    body_to_send = gzip.compress(body)\n                    request_headers[&amp;quot;content-encoding&amp;quot;] = &amp;quot;gzip&amp;quot;\n                else:\n                    body_to_send = body\n            else:\n                body_to_send = None\n    \n&amp;gt;           response = self.pool.urlopen(\n                method,\n                target,\n                body=body_to_send,\n                retries=Retry(False),\n                headers=request_headers,\n                **kw,  # type: ignore[arg-type]\n            )\n\nC:\\Python313\\Lib\\site-packages\\elastic_transport\\_node\\_http_urllib3.py:167: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;urllib3.connectionpool.HTTPConnectionPool object at 0x000001E7F154DA90&amp;gt;, method = &amp;#x27;POST&amp;#x27;\nurl = &amp;#x27;/autocura-testes-2025.05.21/_doc&amp;#x27;\nbody = b&amp;#x27;{&amp;quot;timestamp&amp;quot;:&amp;quot;2025-05-21T16:07:18.546552&amp;quot;,&amp;quot;nome&amp;quot;:&amp;quot;test_processamento_concorrente&amp;quot;,&amp;quot;sucesso&amp;quot;:true,&amp;quot;duracao&amp;quot;:1.8835067749023438e-05}&amp;#x27;\nheaders = {&amp;#x27;user-agent&amp;#x27;: &amp;#x27;elasticsearch-py/9.0.1 (Python/3.13.3; elastic-transport/8.17.1)&amp;#x27;, &amp;#x27;connection&amp;#x27;: &amp;#x27;keep-alive&amp;#x27;, &amp;#x27;accept...pplication/vnd.elasticsearch+json; compatible-with=9&amp;#x27;, &amp;#x27;x-elastic-client-meta&amp;#x27;: &amp;#x27;es=9.0.1,py=3.13.3,t=8.17.1,ur=2.4.0&amp;#x27;}\nretries = Retry(total=False, connect=None, read=None, redirect=0, status=None), redirect = True\nassert_same_host = True, timeout = &amp;lt;_TYPE_DEFAULT.token: -1&amp;gt;, pool_timeout = None\nrelease_conn = True, chunked = False, body_pos = None, preload_content = True\ndecode_content = True, response_kw = {}\nparsed_url = Url(scheme=None, auth=None, host=None, port=None, path=&amp;#x27;/autocura-testes-2025.05.21/_doc&amp;#x27;, query=None, fragment=None)\ndestination_scheme = None, conn = None, release_this_conn = True, http_tunnel_required = False\nerr = None, clean_exit = False\n\n    def urlopen(  # type: ignore[override]\n        self,\n        method: str,\n        url: str,\n        body: _TYPE_BODY | None = None,\n        headers: typing.Mapping[str, str] | None = None,\n        retries: Retry | bool | int | None = None,\n        redirect: bool = True,\n        assert_same_host: bool = True,\n        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n        pool_timeout: int | None = None,\n        release_conn: bool | None = None,\n        chunked: bool = False,\n        body_pos: _TYPE_BODY_POSITION | None = None,\n        preload_content: bool = True,\n        decode_content: bool = True,\n        **response_kw: typing.Any,\n    ) -&amp;gt; BaseHTTPResponse:\n        &amp;quot;&amp;quot;&amp;quot;\n        Get a connection from the pool and perform an HTTP request. This is the\n        lowest level call for making a request, so you&amp;#x27;ll need to specify all\n        the raw details.\n    \n        .. note::\n    \n           More commonly, it&amp;#x27;s appropriate to use a convenience method\n           such as :meth:`request`.\n    \n        .. note::\n    \n           `release_conn` will only behave as expected if\n           `preload_content=False` because we want to make\n           `preload_content=False` the default behaviour someday soon without\n           breaking backwards compatibility.\n    \n        :param method:\n            HTTP request method (such as GET, POST, PUT, etc.)\n    \n        :param url:\n            The URL to perform the request on.\n    \n        :param body:\n            Data to send in the request body, either :class:`str`, :class:`bytes`,\n            an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n    \n        :param headers:\n            Dictionary of custom headers to send, such as User-Agent,\n            If-None-Match, etc. If None, pool headers are used. If provided,\n            these headers completely replace any pool-specific headers.\n    \n        :param retries:\n            Configure the number of retries to allow before raising a\n            :class:`~urllib3.exceptions.MaxRetryError` exception.\n    \n            If ``None`` (default) will retry 3 times, see ``Retry.DEFAULT``. Pass a\n            :class:`~urllib3.util.retry.Retry` object for fine-grained control\n            over different types of retries.\n            Pass an integer number to retry connection errors that many times,\n            but no other types of errors. Pass zero to never retry.\n    \n            If ``False``, then retries are disabled and any exception is raised\n            immediately. Also, instead of raising a MaxRetryError on redirects,\n            the redirect response will be returned.\n    \n        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n    \n        :param redirect:\n            If True, automatically handle redirects (status codes 301, 302,\n            303, 307, 308). Each redirect counts as a retry. Disabling retries\n            will disable redirect, too.\n    \n        :param assert_same_host:\n            If ``True``, will make sure that the host of the pool requests is\n            consistent else will raise HostChangedError. When ``False``, you can\n            use the pool on an HTTP proxy and request foreign hosts.\n    \n        :param timeout:\n            If specified, overrides the default timeout for this one\n            request. It may be a float (in seconds) or an instance of\n            :class:`urllib3.util.Timeout`.\n    \n        :param pool_timeout:\n            If set and the pool is set to block=True, then this method will\n            block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n            connection is available within the time period.\n    \n        :param bool preload_content:\n            If True, the response&amp;#x27;s body will be preloaded into memory.\n    \n        :param bool decode_content:\n            If True, will attempt to decode the body based on the\n            &amp;#x27;content-encoding&amp;#x27; header.\n    \n        :param release_conn:\n            If False, then the urlopen call will not release the connection\n            back into the pool once a response is received (but will release if\n            you read the entire contents of the response such as when\n            `preload_content=True`). This is useful if you&amp;#x27;re not preloading\n            the response&amp;#x27;s content immediately. You will need to call\n            ``r.release_conn()`` on the response ``r`` to return the connection\n            back into the pool. If None, it takes the value of ``preload_content``\n            which defaults to ``True``.\n    \n        :param bool chunked:\n            If True, urllib3 will send the body using chunked transfer\n            encoding. Otherwise, urllib3 will send the body using the standard\n            content-length form. Defaults to False.\n    \n        :param int body_pos:\n            Position to seek to in file-like body in the event of a retry or\n            redirect. Typically this won&amp;#x27;t need to be set because urllib3 will\n            auto-populate the value when needed.\n        &amp;quot;&amp;quot;&amp;quot;\n        parsed_url = parse_url(url)\n        destination_scheme = parsed_url.scheme\n    \n        if headers is None:\n            headers = self.headers\n    \n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n    \n        if release_conn is None:\n            release_conn = preload_content\n    \n        # Check host\n        if assert_same_host and not self.is_same_host(url):\n            raise HostChangedError(self, url, retries)\n    \n        # Ensure that the URL we&amp;#x27;re connecting to is properly encoded\n        if url.startswith(&amp;quot;/&amp;quot;):\n            url = to_str(_encode_target(url))\n        else:\n            url = to_str(parsed_url.url)\n    \n        conn = None\n    \n        # Track whether `conn` needs to be released before\n        # returning/raising/recursing. Update this variable if necessary, and\n        # leave `release_conn` constant throughout the function. That way, if\n        # the function recurses, the original value of `release_conn` will be\n        # passed down into the recursive call, and its value will be respected.\n        #\n        # See issue #651 [1] for details.\n        #\n        # [1] &amp;lt;https://github.com/urllib3/urllib3/issues/651&amp;gt;\n        release_this_conn = release_conn\n    \n        http_tunnel_required = connection_requires_http_tunnel(\n            self.proxy, self.proxy_config, destination_scheme\n        )\n    \n        # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n        # have to copy the headers dict so we can safely change it without those\n        # changes being reflected in anyone else&amp;#x27;s copy.\n        if not http_tunnel_required:\n            headers = headers.copy()  # type: ignore[attr-defined]\n            headers.update(self.proxy_headers)  # type: ignore[union-attr]\n    \n        # Must keep the exception bound to a separate variable or else Python 3\n        # complains about UnboundLocalError.\n        err = None\n    \n        # Keep track of whether we cleanly exited the except block. This\n        # ensures we do proper cleanup in finally.\n        clean_exit = False\n    \n        # Rewind body position, if needed. Record current position\n        # for future rewinds in the event of a redirect/retry.\n        body_pos = set_file_position(body, body_pos)\n    \n        try:\n            # Request a connection from the queue.\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n    \n            conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]\n    \n            # Is this a closed/new connection that requires CONNECT tunnelling?\n            if self.proxy is not None and http_tunnel_required and conn.is_closed:\n                try:\n                    self._prepare_proxy(conn)\n                except (BaseSSLError, OSError, SocketTimeout) as e:\n                    self._raise_timeout(\n                        err=e, url=self.proxy.url, timeout_value=conn.timeout\n                    )\n                    raise\n    \n            # If we&amp;#x27;re going to release the connection in ``finally:``, then\n            # the response doesn&amp;#x27;t need to know about the connection. Otherwise\n            # it will also try to release it and we&amp;#x27;ll have a double-release\n            # mess.\n            response_conn = conn if not release_conn else None\n    \n            # Make the request on the HTTPConnection object\n            response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout_obj,\n                body=body,\n                headers=headers,\n                chunked=chunked,\n                retries=retries,\n                response_conn=response_conn,\n                preload_content=preload_content,\n                decode_content=decode_content,\n                **response_kw,\n            )\n    \n            # Everything went great!\n            clean_exit = True\n    \n        except EmptyPoolError:\n            # Didn&amp;#x27;t get a connection from the pool, no need to clean up\n            clean_exit = True\n            release_this_conn = False\n            raise\n    \n        except (\n            TimeoutError,\n            HTTPException,\n            OSError,\n            ProtocolError,\n            BaseSSLError,\n            SSLError,\n            CertificateError,\n            ProxyError,\n        ) as e:\n            # Discard the connection for these exceptions. It will be\n            # replaced during the next _get_conn() call.\n            clean_exit = False\n            new_e: Exception = e\n            if isinstance(e, (BaseSSLError, CertificateError)):\n                new_e = SSLError(e)\n            if isinstance(\n                new_e,\n                (\n                    OSError,\n                    NewConnectionError,\n                    TimeoutError,\n                    SSLError,\n                    HTTPException,\n                ),\n            ) and (conn and conn.proxy and not conn.has_connected_to_proxy):\n                new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n            elif isinstance(new_e, (OSError, HTTPException)):\n                new_e = ProtocolError(&amp;quot;Connection aborted.&amp;quot;, new_e)\n    \n&amp;gt;           retries = retries.increment(\n                method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]\n            )\n\nC:\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:841: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = Retry(total=False, connect=None, read=None, redirect=0, status=None), method = &amp;#x27;POST&amp;#x27;\nurl = &amp;#x27;/autocura-testes-2025.05.21/_doc&amp;#x27;, response = None\nerror = NewConnectionError(&amp;#x27;&amp;lt;urllib3.connection.HTTPConnection object at 0x000001E7F1B91F30&amp;gt;: Failed to establish a new connection: [WinError 10061] Nenhuma conex\u00e3o p\u00f4de ser feita porque a m\u00e1quina de destino as recusou ativamente&amp;#x27;)\n_pool = &amp;lt;urllib3.connectionpool.HTTPConnectionPool object at 0x000001E7F154DA90&amp;gt;\n_stacktrace = &amp;lt;traceback object at 0x000001E7F1C6FE80&amp;gt;\n\n    def increment(\n        self,\n        method: str | None = None,\n        url: str | None = None,\n        response: BaseHTTPResponse | None = None,\n        error: Exception | None = None,\n        _pool: ConnectionPool | None = None,\n        _stacktrace: TracebackType | None = None,\n    ) -&amp;gt; Self:\n        &amp;quot;&amp;quot;&amp;quot;Return a new Retry object with incremented retry counters.\n    \n        :param response: A response object, or None, if the server did not\n            return a response.\n        :type response: :class:`~urllib3.response.BaseHTTPResponse`\n        :param Exception error: An error encountered during the request, or\n            None if the response was received successfully.\n    \n        :return: A new ``Retry`` object.\n        &amp;quot;&amp;quot;&amp;quot;\n        if self.total is False and error:\n            # Disabled, indicate to re-raise the error.\n&amp;gt;           raise reraise(type(error), error, _stacktrace)\n\nC:\\Python313\\Lib\\site-packages\\urllib3\\util\\retry.py:449: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\ntp = &amp;lt;class &amp;#x27;urllib3.exceptions.NewConnectionError&amp;#x27;&amp;gt;, value = None, tb = None\n\n    def reraise(\n        tp: type[BaseException] | None,\n        value: BaseException,\n        tb: TracebackType | None = None,\n    ) -&amp;gt; typing.NoReturn:\n        try:\n            if value.__traceback__ is not tb:\n                raise value.with_traceback(tb)\n&amp;gt;           raise value\n\nC:\\Python313\\Lib\\site-packages\\urllib3\\util\\util.py:39: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;urllib3.connectionpool.HTTPConnectionPool object at 0x000001E7F154DA90&amp;gt;, method = &amp;#x27;POST&amp;#x27;\nurl = &amp;#x27;/autocura-testes-2025.05.21/_doc&amp;#x27;\nbody = b&amp;#x27;{&amp;quot;timestamp&amp;quot;:&amp;quot;2025-05-21T16:07:18.546552&amp;quot;,&amp;quot;nome&amp;quot;:&amp;quot;test_processamento_concorrente&amp;quot;,&amp;quot;sucesso&amp;quot;:true,&amp;quot;duracao&amp;quot;:1.8835067749023438e-05}&amp;#x27;\nheaders = {&amp;#x27;user-agent&amp;#x27;: &amp;#x27;elasticsearch-py/9.0.1 (Python/3.13.3; elastic-transport/8.17.1)&amp;#x27;, &amp;#x27;connection&amp;#x27;: &amp;#x27;keep-alive&amp;#x27;, &amp;#x27;accept...pplication/vnd.elasticsearch+json; compatible-with=9&amp;#x27;, &amp;#x27;x-elastic-client-meta&amp;#x27;: &amp;#x27;es=9.0.1,py=3.13.3,t=8.17.1,ur=2.4.0&amp;#x27;}\nretries = Retry(total=False, connect=None, read=None, redirect=0, status=None), redirect = True\nassert_same_host = True, timeout = &amp;lt;_TYPE_DEFAULT.token: -1&amp;gt;, pool_timeout = None\nrelease_conn = True, chunked = False, body_pos = None, preload_content = True\ndecode_content = True, response_kw = {}\nparsed_url = Url(scheme=None, auth=None, host=None, port=None, path=&amp;#x27;/autocura-testes-2025.05.21/_doc&amp;#x27;, query=None, fragment=None)\ndestination_scheme = None, conn = None, release_this_conn = True, http_tunnel_required = False\nerr = None, clean_exit = False\n\n    def urlopen(  # type: ignore[override]\n        self,\n        method: str,\n        url: str,\n        body: _TYPE_BODY | None = None,\n        headers: typing.Mapping[str, str] | None = None,\n        retries: Retry | bool | int | None = None,\n        redirect: bool = True,\n        assert_same_host: bool = True,\n        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n        pool_timeout: int | None = None,\n        release_conn: bool | None = None,\n        chunked: bool = False,\n        body_pos: _TYPE_BODY_POSITION | None = None,\n        preload_content: bool = True,\n        decode_content: bool = True,\n        **response_kw: typing.Any,\n    ) -&amp;gt; BaseHTTPResponse:\n        &amp;quot;&amp;quot;&amp;quot;\n        Get a connection from the pool and perform an HTTP request. This is the\n        lowest level call for making a request, so you&amp;#x27;ll need to specify all\n        the raw details.\n    \n        .. note::\n    \n           More commonly, it&amp;#x27;s appropriate to use a convenience method\n           such as :meth:`request`.\n    \n        .. note::\n    \n           `release_conn` will only behave as expected if\n           `preload_content=False` because we want to make\n           `preload_content=False` the default behaviour someday soon without\n           breaking backwards compatibility.\n    \n        :param method:\n            HTTP request method (such as GET, POST, PUT, etc.)\n    \n        :param url:\n            The URL to perform the request on.\n    \n        :param body:\n            Data to send in the request body, either :class:`str`, :class:`bytes`,\n            an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n    \n        :param headers:\n            Dictionary of custom headers to send, such as User-Agent,\n            If-None-Match, etc. If None, pool headers are used. If provided,\n            these headers completely replace any pool-specific headers.\n    \n        :param retries:\n            Configure the number of retries to allow before raising a\n            :class:`~urllib3.exceptions.MaxRetryError` exception.\n    \n            If ``None`` (default) will retry 3 times, see ``Retry.DEFAULT``. Pass a\n            :class:`~urllib3.util.retry.Retry` object for fine-grained control\n            over different types of retries.\n            Pass an integer number to retry connection errors that many times,\n            but no other types of errors. Pass zero to never retry.\n    \n            If ``False``, then retries are disabled and any exception is raised\n            immediately. Also, instead of raising a MaxRetryError on redirects,\n            the redirect response will be returned.\n    \n        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n    \n        :param redirect:\n            If True, automatically handle redirects (status codes 301, 302,\n            303, 307, 308). Each redirect counts as a retry. Disabling retries\n            will disable redirect, too.\n    \n        :param assert_same_host:\n            If ``True``, will make sure that the host of the pool requests is\n            consistent else will raise HostChangedError. When ``False``, you can\n            use the pool on an HTTP proxy and request foreign hosts.\n    \n        :param timeout:\n            If specified, overrides the default timeout for this one\n            request. It may be a float (in seconds) or an instance of\n            :class:`urllib3.util.Timeout`.\n    \n        :param pool_timeout:\n            If set and the pool is set to block=True, then this method will\n            block for ``pool_timeout`` seconds and raise EmptyPoolError if no\n            connection is available within the time period.\n    \n        :param bool preload_content:\n            If True, the response&amp;#x27;s body will be preloaded into memory.\n    \n        :param bool decode_content:\n            If True, will attempt to decode the body based on the\n            &amp;#x27;content-encoding&amp;#x27; header.\n    \n        :param release_conn:\n            If False, then the urlopen call will not release the connection\n            back into the pool once a response is received (but will release if\n            you read the entire contents of the response such as when\n            `preload_content=True`). This is useful if you&amp;#x27;re not preloading\n            the response&amp;#x27;s content immediately. You will need to call\n            ``r.release_conn()`` on the response ``r`` to return the connection\n            back into the pool. If None, it takes the value of ``preload_content``\n            which defaults to ``True``.\n    \n        :param bool chunked:\n            If True, urllib3 will send the body using chunked transfer\n            encoding. Otherwise, urllib3 will send the body using the standard\n            content-length form. Defaults to False.\n    \n        :param int body_pos:\n            Position to seek to in file-like body in the event of a retry or\n            redirect. Typically this won&amp;#x27;t need to be set because urllib3 will\n            auto-populate the value when needed.\n        &amp;quot;&amp;quot;&amp;quot;\n        parsed_url = parse_url(url)\n        destination_scheme = parsed_url.scheme\n    \n        if headers is None:\n            headers = self.headers\n    \n        if not isinstance(retries, Retry):\n            retries = Retry.from_int(retries, redirect=redirect, default=self.retries)\n    \n        if release_conn is None:\n            release_conn = preload_content\n    \n        # Check host\n        if assert_same_host and not self.is_same_host(url):\n            raise HostChangedError(self, url, retries)\n    \n        # Ensure that the URL we&amp;#x27;re connecting to is properly encoded\n        if url.startswith(&amp;quot;/&amp;quot;):\n            url = to_str(_encode_target(url))\n        else:\n            url = to_str(parsed_url.url)\n    \n        conn = None\n    \n        # Track whether `conn` needs to be released before\n        # returning/raising/recursing. Update this variable if necessary, and\n        # leave `release_conn` constant throughout the function. That way, if\n        # the function recurses, the original value of `release_conn` will be\n        # passed down into the recursive call, and its value will be respected.\n        #\n        # See issue #651 [1] for details.\n        #\n        # [1] &amp;lt;https://github.com/urllib3/urllib3/issues/651&amp;gt;\n        release_this_conn = release_conn\n    \n        http_tunnel_required = connection_requires_http_tunnel(\n            self.proxy, self.proxy_config, destination_scheme\n        )\n    \n        # Merge the proxy headers. Only done when not using HTTP CONNECT. We\n        # have to copy the headers dict so we can safely change it without those\n        # changes being reflected in anyone else&amp;#x27;s copy.\n        if not http_tunnel_required:\n            headers = headers.copy()  # type: ignore[attr-defined]\n            headers.update(self.proxy_headers)  # type: ignore[union-attr]\n    \n        # Must keep the exception bound to a separate variable or else Python 3\n        # complains about UnboundLocalError.\n        err = None\n    \n        # Keep track of whether we cleanly exited the except block. This\n        # ensures we do proper cleanup in finally.\n        clean_exit = False\n    \n        # Rewind body position, if needed. Record current position\n        # for future rewinds in the event of a redirect/retry.\n        body_pos = set_file_position(body, body_pos)\n    \n        try:\n            # Request a connection from the queue.\n            timeout_obj = self._get_timeout(timeout)\n            conn = self._get_conn(timeout=pool_timeout)\n    \n            conn.timeout = timeout_obj.connect_timeout  # type: ignore[assignment]\n    \n            # Is this a closed/new connection that requires CONNECT tunnelling?\n            if self.proxy is not None and http_tunnel_required and conn.is_closed:\n                try:\n                    self._prepare_proxy(conn)\n                except (BaseSSLError, OSError, SocketTimeout) as e:\n                    self._raise_timeout(\n                        err=e, url=self.proxy.url, timeout_value=conn.timeout\n                    )\n                    raise\n    \n            # If we&amp;#x27;re going to release the connection in ``finally:``, then\n            # the response doesn&amp;#x27;t need to know about the connection. Otherwise\n            # it will also try to release it and we&amp;#x27;ll have a double-release\n            # mess.\n            response_conn = conn if not release_conn else None\n    \n            # Make the request on the HTTPConnection object\n&amp;gt;           response = self._make_request(\n                conn,\n                method,\n                url,\n                timeout=timeout_obj,\n                body=body,\n                headers=headers,\n                chunked=chunked,\n                retries=retries,\n                response_conn=response_conn,\n                preload_content=preload_content,\n                decode_content=decode_content,\n                **response_kw,\n            )\n\nC:\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:787: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;urllib3.connectionpool.HTTPConnectionPool object at 0x000001E7F154DA90&amp;gt;\nconn = &amp;lt;urllib3.connection.HTTPConnection object at 0x000001E7F1B91F30&amp;gt;, method = &amp;#x27;POST&amp;#x27;\nurl = &amp;#x27;/autocura-testes-2025.05.21/_doc&amp;#x27;\nbody = b&amp;#x27;{&amp;quot;timestamp&amp;quot;:&amp;quot;2025-05-21T16:07:18.546552&amp;quot;,&amp;quot;nome&amp;quot;:&amp;quot;test_processamento_concorrente&amp;quot;,&amp;quot;sucesso&amp;quot;:true,&amp;quot;duracao&amp;quot;:1.8835067749023438e-05}&amp;#x27;\nheaders = {&amp;#x27;user-agent&amp;#x27;: &amp;#x27;elasticsearch-py/9.0.1 (Python/3.13.3; elastic-transport/8.17.1)&amp;#x27;, &amp;#x27;connection&amp;#x27;: &amp;#x27;keep-alive&amp;#x27;, &amp;#x27;accept...pplication/vnd.elasticsearch+json; compatible-with=9&amp;#x27;, &amp;#x27;x-elastic-client-meta&amp;#x27;: &amp;#x27;es=9.0.1,py=3.13.3,t=8.17.1,ur=2.4.0&amp;#x27;}\nretries = Retry(total=False, connect=None, read=None, redirect=0, status=None)\ntimeout = Timeout(connect=&amp;lt;_TYPE_DEFAULT.token: -1&amp;gt;, read=&amp;lt;_TYPE_DEFAULT.token: -1&amp;gt;, total=10.0)\nchunked = False, response_conn = None, preload_content = True, decode_content = True\nenforce_content_length = True\n\n    def _make_request(\n        self,\n        conn: BaseHTTPConnection,\n        method: str,\n        url: str,\n        body: _TYPE_BODY | None = None,\n        headers: typing.Mapping[str, str] | None = None,\n        retries: Retry | None = None,\n        timeout: _TYPE_TIMEOUT = _DEFAULT_TIMEOUT,\n        chunked: bool = False,\n        response_conn: BaseHTTPConnection | None = None,\n        preload_content: bool = True,\n        decode_content: bool = True,\n        enforce_content_length: bool = True,\n    ) -&amp;gt; BaseHTTPResponse:\n        &amp;quot;&amp;quot;&amp;quot;\n        Perform a request on a given urllib connection object taken from our\n        pool.\n    \n        :param conn:\n            a connection from one of our connection pools\n    \n        :param method:\n            HTTP request method (such as GET, POST, PUT, etc.)\n    \n        :param url:\n            The URL to perform the request on.\n    \n        :param body:\n            Data to send in the request body, either :class:`str`, :class:`bytes`,\n            an iterable of :class:`str`/:class:`bytes`, or a file-like object.\n    \n        :param headers:\n            Dictionary of custom headers to send, such as User-Agent,\n            If-None-Match, etc. If None, pool headers are used. If provided,\n            these headers completely replace any pool-specific headers.\n    \n        :param retries:\n            Configure the number of retries to allow before raising a\n            :class:`~urllib3.exceptions.MaxRetryError` exception.\n    \n            Pass ``None`` to retry until you receive a response. Pass a\n            :class:`~urllib3.util.retry.Retry` object for fine-grained control\n            over different types of retries.\n            Pass an integer number to retry connection errors that many times,\n            but no other types of errors. Pass zero to never retry.\n    \n            If ``False``, then retries are disabled and any exception is raised\n            immediately. Also, instead of raising a MaxRetryError on redirects,\n            the redirect response will be returned.\n    \n        :type retries: :class:`~urllib3.util.retry.Retry`, False, or an int.\n    \n        :param timeout:\n            If specified, overrides the default timeout for this one\n            request. It may be a float (in seconds) or an instance of\n            :class:`urllib3.util.Timeout`.\n    \n        :param chunked:\n            If True, urllib3 will send the body using chunked transfer\n            encoding. Otherwise, urllib3 will send the body using the standard\n            content-length form. Defaults to False.\n    \n        :param response_conn:\n            Set this to ``None`` if you will handle releasing the connection or\n            set the connection to have the response release it.\n    \n        :param preload_content:\n          If True, the response&amp;#x27;s body will be preloaded during construction.\n    \n        :param decode_content:\n            If True, will attempt to decode the body based on the\n            &amp;#x27;content-encoding&amp;#x27; header.\n    \n        :param enforce_content_length:\n            Enforce content length checking. Body returned by server must match\n            value of Content-Length header, if present. Otherwise, raise error.\n        &amp;quot;&amp;quot;&amp;quot;\n        self.num_requests += 1\n    \n        timeout_obj = self._get_timeout(timeout)\n        timeout_obj.start_connect()\n        conn.timeout = Timeout.resolve_default_timeout(timeout_obj.connect_timeout)\n    \n        try:\n            # Trigger any extra validation we need to do.\n            try:\n                self._validate_conn(conn)\n            except (SocketTimeout, BaseSSLError) as e:\n                self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n                raise\n    \n        # _validate_conn() starts the connection to an HTTPS proxy\n        # so we need to wrap errors with &amp;#x27;ProxyError&amp;#x27; here too.\n        except (\n            OSError,\n            NewConnectionError,\n            TimeoutError,\n            BaseSSLError,\n            CertificateError,\n            SSLError,\n        ) as e:\n            new_e: Exception = e\n            if isinstance(e, (BaseSSLError, CertificateError)):\n                new_e = SSLError(e)\n            # If the connection didn&amp;#x27;t successfully connect to it&amp;#x27;s proxy\n            # then there\n            if isinstance(\n                new_e, (OSError, NewConnectionError, TimeoutError, SSLError)\n            ) and (conn and conn.proxy and not conn.has_connected_to_proxy):\n                new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n            raise new_e\n    \n        # conn.request() calls http.client.*.request, not the method in\n        # urllib3.request. It also calls makefile (recv) on the socket.\n        try:\n&amp;gt;           conn.request(\n                method,\n                url,\n                body=body,\n                headers=headers,\n                chunked=chunked,\n                preload_content=preload_content,\n                decode_content=decode_content,\n                enforce_content_length=enforce_content_length,\n            )\n\nC:\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py:493: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;urllib3.connection.HTTPConnection object at 0x000001E7F1B91F30&amp;gt;, method = &amp;#x27;POST&amp;#x27;\nurl = &amp;#x27;/autocura-testes-2025.05.21/_doc&amp;#x27;\nbody = b&amp;#x27;{&amp;quot;timestamp&amp;quot;:&amp;quot;2025-05-21T16:07:18.546552&amp;quot;,&amp;quot;nome&amp;quot;:&amp;quot;test_processamento_concorrente&amp;quot;,&amp;quot;sucesso&amp;quot;:true,&amp;quot;duracao&amp;quot;:1.8835067749023438e-05}&amp;#x27;\nheaders = {&amp;#x27;user-agent&amp;#x27;: &amp;#x27;elasticsearch-py/9.0.1 (Python/3.13.3; elastic-transport/8.17.1)&amp;#x27;, &amp;#x27;connection&amp;#x27;: &amp;#x27;keep-alive&amp;#x27;, &amp;#x27;accept...pplication/vnd.elasticsearch+json; compatible-with=9&amp;#x27;, &amp;#x27;x-elastic-client-meta&amp;#x27;: &amp;#x27;es=9.0.1,py=3.13.3,t=8.17.1,ur=2.4.0&amp;#x27;}\n\n    def request(  # type: ignore[override]\n        self,\n        method: str,\n        url: str,\n        body: _TYPE_BODY | None = None,\n        headers: typing.Mapping[str, str] | None = None,\n        *,\n        chunked: bool = False,\n        preload_content: bool = True,\n        decode_content: bool = True,\n        enforce_content_length: bool = True,\n    ) -&amp;gt; None:\n        # Update the inner socket&amp;#x27;s timeout value to send the request.\n        # This only triggers if the connection is re-used.\n        if self.sock is not None:\n            self.sock.settimeout(self.timeout)\n    \n        # Store these values to be fed into the HTTPResponse\n        # object later. TODO: Remove this in favor of a real\n        # HTTP lifecycle mechanism.\n    \n        # We have to store these before we call .request()\n        # because sometimes we can still salvage a response\n        # off the wire even if we aren&amp;#x27;t able to completely\n        # send the request body.\n        self._response_options = _ResponseOptions(\n            request_method=method,\n            request_url=url,\n            preload_content=preload_content,\n            decode_content=decode_content,\n            enforce_content_length=enforce_content_length,\n        )\n    \n        if headers is None:\n            headers = {}\n        header_keys = frozenset(to_str(k.lower()) for k in headers)\n        skip_accept_encoding = &amp;quot;accept-encoding&amp;quot; in header_keys\n        skip_host = &amp;quot;host&amp;quot; in header_keys\n        self.putrequest(\n            method, url, skip_accept_encoding=skip_accept_encoding, skip_host=skip_host\n        )\n    \n        # Transform the body into an iterable of sendall()-able chunks\n        # and detect if an explicit Content-Length is doable.\n        chunks_and_cl = body_to_chunks(body, method=method, blocksize=self.blocksize)\n        chunks = chunks_and_cl.chunks\n        content_length = chunks_and_cl.content_length\n    \n        # When chunked is explicit set to &amp;#x27;True&amp;#x27; we respect that.\n        if chunked:\n            if &amp;quot;transfer-encoding&amp;quot; not in header_keys:\n                self.putheader(&amp;quot;Transfer-Encoding&amp;quot;, &amp;quot;chunked&amp;quot;)\n        else:\n            # Detect whether a framing mechanism is already in use. If so\n            # we respect that value, otherwise we pick chunked vs content-length\n            # depending on the type of &amp;#x27;body&amp;#x27;.\n            if &amp;quot;content-length&amp;quot; in header_keys:\n                chunked = False\n            elif &amp;quot;transfer-encoding&amp;quot; in header_keys:\n                chunked = True\n    \n            # Otherwise we go off the recommendation of &amp;#x27;body_to_chunks()&amp;#x27;.\n            else:\n                chunked = False\n                if content_length is None:\n                    if chunks is not None:\n                        chunked = True\n                        self.putheader(&amp;quot;Transfer-Encoding&amp;quot;, &amp;quot;chunked&amp;quot;)\n                else:\n                    self.putheader(&amp;quot;Content-Length&amp;quot;, str(content_length))\n    \n        # Now that framing headers are out of the way we send all the other headers.\n        if &amp;quot;user-agent&amp;quot; not in header_keys:\n            self.putheader(&amp;quot;User-Agent&amp;quot;, _get_default_user_agent())\n        for header, value in headers.items():\n            self.putheader(header, value)\n&amp;gt;       self.endheaders()\n\nC:\\Python313\\Lib\\site-packages\\urllib3\\connection.py:445: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;urllib3.connection.HTTPConnection object at 0x000001E7F1B91F30&amp;gt;, message_body = None\n\n    def endheaders(self, message_body=None, *, encode_chunked=False):\n        &amp;quot;&amp;quot;&amp;quot;Indicate that the last header line has been sent to the server.\n    \n        This method sends the request to the server.  The optional message_body\n        argument can be used to pass a message body associated with the\n        request.\n        &amp;quot;&amp;quot;&amp;quot;\n        if self.__state == _CS_REQ_STARTED:\n            self.__state = _CS_REQ_SENT\n        else:\n            raise CannotSendHeader()\n&amp;gt;       self._send_output(message_body, encode_chunked=encode_chunked)\n\nC:\\Python313\\Lib\\http\\client.py:1333: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;urllib3.connection.HTTPConnection object at 0x000001E7F1B91F30&amp;gt;, message_body = None\nencode_chunked = False\n\n    def _send_output(self, message_body=None, encode_chunked=False):\n        &amp;quot;&amp;quot;&amp;quot;Send the currently buffered request and clear the buffer.\n    \n        Appends an extra \\\\r\\\\n to the buffer.\n        A message_body may be specified, to be appended to the request.\n        &amp;quot;&amp;quot;&amp;quot;\n        self._buffer.extend((b&amp;quot;&amp;quot;, b&amp;quot;&amp;quot;))\n        msg = b&amp;quot;\\r\\n&amp;quot;.join(self._buffer)\n        del self._buffer[:]\n&amp;gt;       self.send(msg)\n\nC:\\Python313\\Lib\\http\\client.py:1093: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;urllib3.connection.HTTPConnection object at 0x000001E7F1B91F30&amp;gt;\ndata = b&amp;#x27;POST /autocura-testes-2025.05.21/_doc HTTP/1.1\\r\\nHost: localhost:9200\\r\\nAccept-Encoding: identity\\r\\nContent-Lengt...ation/vnd.elasticsearch+json; compatible-with=9\\r\\nx-elastic-client-meta: es=9.0.1,py=3.13.3,t=8.17.1,ur=2.4.0\\r\\n\\r\\n&amp;#x27;\n\n    def send(self, data):\n        &amp;quot;&amp;quot;&amp;quot;Send `data&amp;#x27; to the server.\n        ``data`` can be a string object, a bytes object, an array object, a\n        file-like object that supports a .read() method, or an iterable object.\n        &amp;quot;&amp;quot;&amp;quot;\n    \n        if self.sock is None:\n            if self.auto_open:\n&amp;gt;               self.connect()\n\nC:\\Python313\\Lib\\http\\client.py:1037: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;urllib3.connection.HTTPConnection object at 0x000001E7F1B91F30&amp;gt;\n\n    def connect(self) -&amp;gt; None:\n&amp;gt;       self.sock = self._new_conn()\n\nC:\\Python313\\Lib\\site-packages\\urllib3\\connection.py:276: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;urllib3.connection.HTTPConnection object at 0x000001E7F1B91F30&amp;gt;\n\n    def _new_conn(self) -&amp;gt; socket.socket:\n        &amp;quot;&amp;quot;&amp;quot;Establish a socket connection and set nodelay settings on it.\n    \n        :return: New socket connection.\n        &amp;quot;&amp;quot;&amp;quot;\n        try:\n            sock = connection.create_connection(\n                (self._dns_host, self.port),\n                self.timeout,\n                source_address=self.source_address,\n                socket_options=self.socket_options,\n            )\n        except socket.gaierror as e:\n            raise NameResolutionError(self.host, self, e) from e\n        except SocketTimeout as e:\n            raise ConnectTimeoutError(\n                self,\n                f&amp;quot;Connection to {self.host} timed out. (connect timeout={self.timeout})&amp;quot;,\n            ) from e\n    \n        except OSError as e:\n&amp;gt;           raise NewConnectionError(\n                self, f&amp;quot;Failed to establish a new connection: {e}&amp;quot;\n            ) from e\nE           urllib3.exceptions.NewConnectionError: &amp;lt;urllib3.connection.HTTPConnection object at 0x000001E7F1B91F30&amp;gt;: Failed to establish a new connection: [WinError 10061] Nenhuma conex\u00e3o p\u00f4de ser feita porque a m\u00e1quina de destino as recusou ativamente\n\nC:\\Python313\\Lib\\site-packages\\urllib3\\connection.py:213: NewConnectionError\n\nThe above exception was the direct cause of the following exception:\n\nself = &amp;lt;tests.integration.test_sistema_completo.TestSistemaCompleto object at 0x000001E7F138B360&amp;gt;\nconfig_teste = {&amp;#x27;ambiente&amp;#x27;: &amp;#x27;teste&amp;#x27;, &amp;#x27;api_url&amp;#x27;: &amp;#x27;http://localhost:8000&amp;#x27;, &amp;#x27;db_url&amp;#x27;: &amp;#x27;postgresql://test:test@localhost:5432/test_db&amp;#x27;, &amp;#x27;redis_url&amp;#x27;: &amp;#x27;redis://localhost:6379/0&amp;#x27;, ...}\nmock_api = &amp;lt;MagicMock name=&amp;#x27;Session&amp;#x27; id=&amp;#x27;2095697780016&amp;#x27;&amp;gt;\nmock_db = &amp;lt;MagicMock name=&amp;#x27;create_engine&amp;#x27; id=&amp;#x27;2095701933568&amp;#x27;&amp;gt;\nmock_redis = &amp;lt;MagicMock name=&amp;#x27;Redis&amp;#x27; id=&amp;#x27;2095704948816&amp;#x27;&amp;gt;\nmonitoramento = &amp;lt;src.orquestrador.monitoramento.MonitoramentoTestes object at 0x000001E7F1451810&amp;gt;\n\n    def test_processamento_concorrente(\n        self,\n        config_teste: Dict[str, Any],\n        mock_api: Any,\n        mock_db: Any,\n        mock_redis: Any,\n        monitoramento: Any\n    ) -&amp;gt; None:\n        &amp;quot;&amp;quot;&amp;quot;\n        Testa o processamento concorrente de m\u00faltiplos dados.\n    \n        Este teste verifica:\n        1. Processamento paralelo\n        2. Consist\u00eancia dos dados\n        3. Performance\n    \n        Args:\n            config_teste: Configura\u00e7\u00f5es de teste\n            mock_api: Mock da API\n            mock_db: Mock do banco de dados\n            mock_redis: Mock do Redis\n            monitoramento: Inst\u00e2ncia do monitoramento\n        &amp;quot;&amp;quot;&amp;quot;\n        # Arrange\n        dados_entrada = [\n            {&amp;quot;id&amp;quot;: f&amp;quot;test_{i}&amp;quot;, &amp;quot;dados&amp;quot;: [i], &amp;quot;timestamp&amp;quot;: datetime.now().isoformat()}\n            for i in range(10)\n        ]\n    \n        # Act\n        inicio = time.time()\n        resultados = self._processar_dados_concorrente(dados_entrada, config_teste)\n        duracao = time.time() - inicio\n    \n        # Assert\n        assert len(resultados) == len(dados_entrada)\n        assert all(r[&amp;quot;status&amp;quot;] == &amp;quot;success&amp;quot; for r in resultados)\n    \n        # Verifica m\u00e9tricas\n&amp;gt;       monitoramento.registrar_execucao_teste(\n            &amp;quot;test_processamento_concorrente&amp;quot;,\n            True,\n            duracao\n        )\n\ntests\\integration\\test_sistema_completo.py:142: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;src.orquestrador.monitoramento.MonitoramentoTestes object at 0x000001E7F1451810&amp;gt;\nnome = &amp;#x27;test_processamento_concorrente&amp;#x27;, sucesso = True, duracao = 1.8835067749023438e-05\n\n    def registrar_execucao_teste(self, nome: str, sucesso: bool, duracao: float) -&amp;gt; None:\n        &amp;quot;&amp;quot;&amp;quot;\n        Registra a execu\u00e7\u00e3o de um teste.\n    \n        Args:\n            nome: Nome do teste\n            sucesso: Se o teste passou\n            duracao: Dura\u00e7\u00e3o em segundos\n        &amp;quot;&amp;quot;&amp;quot;\n        # Prometheus\n        if hasattr(self, &amp;quot;metricas&amp;quot;):\n            self.metricas[&amp;quot;testes_executados&amp;quot;].inc()\n            self.metricas[&amp;quot;duracao_testes&amp;quot;].observe(duracao)\n    \n            if not sucesso:\n                self.metricas[&amp;quot;testes_falhas&amp;quot;].inc()\n    \n        # Elasticsearch\n        if hasattr(self, &amp;quot;es&amp;quot;):\n            doc = {\n                &amp;quot;timestamp&amp;quot;: datetime.now().isoformat(),\n                &amp;quot;nome&amp;quot;: nome,\n                &amp;quot;sucesso&amp;quot;: sucesso,\n                &amp;quot;duracao&amp;quot;: duracao\n            }\n    \n&amp;gt;           self.es.index(\n                index=f&amp;quot;{self.config[&amp;#x27;elk&amp;#x27;][&amp;#x27;elasticsearch&amp;#x27;][&amp;#x27;indice_prefixo&amp;#x27;]}{datetime.now().strftime(&amp;#x27;%Y.%m.%d&amp;#x27;)}&amp;quot;,\n                document=doc\n            )\n\nsrc\\orquestrador\\monitoramento.py:151: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nargs = (&amp;lt;Elasticsearch([&amp;#x27;http://localhost:9200&amp;#x27;])&amp;gt;,)\nkwargs = {&amp;#x27;document&amp;#x27;: {&amp;#x27;duracao&amp;#x27;: 1.8835067749023438e-05, &amp;#x27;nome&amp;#x27;: &amp;#x27;test_processamento_concorrente&amp;#x27;, &amp;#x27;sucesso&amp;#x27;: True, &amp;#x27;timestamp&amp;#x27;: &amp;#x27;2025-05-21T16:07:18.546552&amp;#x27;}, &amp;#x27;index&amp;#x27;: &amp;#x27;autocura-testes-2025.05.21&amp;#x27;}\nmaybe_transport_options = set()\n\n    @wraps(api)\n    def wrapped(*args: Any, **kwargs: Any) -&amp;gt; Any:\n        # Let&amp;#x27;s give a nicer error message when users pass positional arguments.\n        if len(args) &amp;gt;= 2:\n            raise TypeError(\n                &amp;quot;Positional arguments can&amp;#x27;t be used with Elasticsearch API methods. &amp;quot;\n                &amp;quot;Instead only use keyword arguments.&amp;quot;\n            )\n    \n        # We merge &amp;#x27;params&amp;#x27; first as transport options can be specified using params.\n        if &amp;quot;params&amp;quot; in kwargs and (\n            not ignore_deprecated_options\n            or &amp;quot;params&amp;quot; not in ignore_deprecated_options\n        ):\n            params = kwargs.pop(&amp;quot;params&amp;quot;)\n            if params:\n                if not hasattr(params, &amp;quot;items&amp;quot;):\n                    raise ValueError(\n                        &amp;quot;Couldn&amp;#x27;t merge &amp;#x27;params&amp;#x27; with other parameters as it wasn&amp;#x27;t a mapping. &amp;quot;\n                        &amp;quot;Instead of using &amp;#x27;params&amp;#x27; use individual API parameters&amp;quot;\n                    )\n                warnings.warn(\n                    &amp;quot;The &amp;#x27;params&amp;#x27; parameter is deprecated and will be removed &amp;quot;\n                    &amp;quot;in a future version. Instead use individual parameters.&amp;quot;,\n                    category=DeprecationWarning,\n                    stacklevel=warn_stacklevel(),\n                )\n                _merge_kwargs_no_duplicates(kwargs, params)\n    \n        maybe_transport_options = _TRANSPORT_OPTIONS.intersection(kwargs)\n        if maybe_transport_options:\n            transport_options = {}\n            for option in maybe_transport_options:\n                if (\n                    ignore_deprecated_options\n                    and option in ignore_deprecated_options\n                ):\n                    continue\n                try:\n                    option_rename = option\n                    if option == &amp;quot;ignore&amp;quot;:\n                        option_rename = &amp;quot;ignore_status&amp;quot;\n                    transport_options[option_rename] = kwargs.pop(option)\n                except KeyError:\n                    pass\n            if transport_options:\n                warnings.warn(\n                    &amp;quot;Passing transport options in the API method is deprecated. Use &amp;#x27;Elasticsearch.options()&amp;#x27; instead.&amp;quot;,\n                    category=DeprecationWarning,\n                    stacklevel=warn_stacklevel(),\n                )\n                client = args[0]\n    \n                # Namespaced clients need to unwrapped.\n                namespaced_client: Optional[Type[&amp;quot;NamespacedClient&amp;quot;]] = None\n                if hasattr(client, &amp;quot;_client&amp;quot;):\n                    namespaced_client = type(client)\n                    client = client._client\n    \n                client = client.options(**transport_options)\n    \n                # Re-wrap the client if we unwrapped due to being namespaced.\n                if namespaced_client is not None:\n                    client = namespaced_client(client)\n                args = (client,) + args[1:]\n    \n        if &amp;quot;body&amp;quot; in kwargs and (\n            not ignore_deprecated_options or &amp;quot;body&amp;quot; not in ignore_deprecated_options\n        ):\n            body: Optional[_TYPE_BODY] = kwargs.pop(&amp;quot;body&amp;quot;)\n            mixed_body_and_params = False\n            if body is not None:\n                if body_name:\n                    if body_name in kwargs:\n                        raise TypeError(\n                            f&amp;quot;Can&amp;#x27;t use &amp;#x27;{body_name}&amp;#x27; and &amp;#x27;body&amp;#x27; parameters together because &amp;#x27;{body_name}&amp;#x27; &amp;quot;\n                            &amp;quot;is an alias for &amp;#x27;body&amp;#x27;. Instead you should only use the &amp;quot;\n                            f&amp;quot;&amp;#x27;{body_name}&amp;#x27; parameter. See https://github.com/elastic/elasticsearch-py/&amp;quot;\n                            &amp;quot;issues/1698 for more information&amp;quot;\n                        )\n                    kwargs[body_name] = body\n                elif body_fields is not None:\n                    mixed_body_and_params = _merge_body_fields_no_duplicates(\n                        body, kwargs, body_fields\n                    )\n                    kwargs[&amp;quot;body&amp;quot;] = body\n    \n                if parameter_aliases and not isinstance(body, (str, bytes)):\n                    for alias, rename_to in parameter_aliases.items():\n                        if rename_to in body:\n                            body[alias] = body.pop(rename_to)\n                            # If body and params are mixed, the alias may come from a param,\n                            # in which case the warning below will not make sense.\n                            if not mixed_body_and_params:\n                                warnings.warn(\n                                    f&amp;quot;Using &amp;#x27;{rename_to}&amp;#x27; alias in &amp;#x27;body&amp;#x27; is deprecated and will be removed &amp;quot;\n                                    f&amp;quot;in a future version of elasticsearch-py. Use &amp;#x27;{alias}&amp;#x27; directly instead. &amp;quot;\n                                    &amp;quot;See https://github.com/elastic/elasticsearch-py/issues/1698 for more information&amp;quot;,\n                                    category=DeprecationWarning,\n                                    stacklevel=2,\n                                )\n    \n        if parameter_aliases:\n            for alias, rename_to in parameter_aliases.items():\n                try:\n                    kwargs[rename_to] = kwargs.pop(alias)\n                except KeyError:\n                    pass\n    \n&amp;gt;       return api(*args, **kwargs)\n\nC:\\Python313\\Lib\\site-packages\\elasticsearch\\_sync\\client\\utils.py:415: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;Elasticsearch([&amp;#x27;http://localhost:9200&amp;#x27;])&amp;gt;\n\n    @_rewrite_parameters(\n        body_name=&amp;quot;document&amp;quot;,\n    )\n    def index(\n        self,\n        *,\n        index: str,\n        document: t.Optional[t.Mapping[str, t.Any]] = None,\n        body: t.Optional[t.Mapping[str, t.Any]] = None,\n        id: t.Optional[str] = None,\n        error_trace: t.Optional[bool] = None,\n        filter_path: t.Optional[t.Union[str, t.Sequence[str]]] = None,\n        human: t.Optional[bool] = None,\n        if_primary_term: t.Optional[int] = None,\n        if_seq_no: t.Optional[int] = None,\n        include_source_on_error: t.Optional[bool] = None,\n        op_type: t.Optional[t.Union[str, t.Literal[&amp;quot;create&amp;quot;, &amp;quot;index&amp;quot;]]] = None,\n        pipeline: t.Optional[str] = None,\n        pretty: t.Optional[bool] = None,\n        refresh: t.Optional[\n            t.Union[bool, str, t.Literal[&amp;quot;false&amp;quot;, &amp;quot;true&amp;quot;, &amp;quot;wait_for&amp;quot;]]\n        ] = None,\n        require_alias: t.Optional[bool] = None,\n        routing: t.Optional[str] = None,\n        timeout: t.Optional[t.Union[str, t.Literal[-1], t.Literal[0]]] = None,\n        version: t.Optional[int] = None,\n        version_type: t.Optional[\n            t.Union[str, t.Literal[&amp;quot;external&amp;quot;, &amp;quot;external_gte&amp;quot;, &amp;quot;force&amp;quot;, &amp;quot;internal&amp;quot;]]\n        ] = None,\n        wait_for_active_shards: t.Optional[\n            t.Union[int, t.Union[str, t.Literal[&amp;quot;all&amp;quot;, &amp;quot;index-setting&amp;quot;]]]\n        ] = None,\n    ) -&amp;gt; ObjectApiResponse[t.Any]:\n        &amp;quot;&amp;quot;&amp;quot;\n        .. raw:: html\n    \n          &amp;lt;p&amp;gt;Create or update a document in an index.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;Add a JSON document to the specified data stream or index and make it searchable.\n          If the target is an index and the document already exists, the request updates the document and increments its version.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;NOTE: You cannot use this API to send update requests for existing documents in a data stream.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;If the Elasticsearch security features are enabled, you must have the following index privileges for the target data stream, index, or index alias:&amp;lt;/p&amp;gt;\n          &amp;lt;ul&amp;gt;\n          &amp;lt;li&amp;gt;To add or overwrite a document using the &amp;lt;code&amp;gt;PUT /&amp;amp;lt;target&amp;amp;gt;/_doc/&amp;amp;lt;_id&amp;amp;gt;&amp;lt;/code&amp;gt; request format, you must have the &amp;lt;code&amp;gt;create&amp;lt;/code&amp;gt;, &amp;lt;code&amp;gt;index&amp;lt;/code&amp;gt;, or &amp;lt;code&amp;gt;write&amp;lt;/code&amp;gt; index privilege.&amp;lt;/li&amp;gt;\n          &amp;lt;li&amp;gt;To add a document using the &amp;lt;code&amp;gt;POST /&amp;amp;lt;target&amp;amp;gt;/_doc/&amp;lt;/code&amp;gt; request format, you must have the &amp;lt;code&amp;gt;create_doc&amp;lt;/code&amp;gt;, &amp;lt;code&amp;gt;create&amp;lt;/code&amp;gt;, &amp;lt;code&amp;gt;index&amp;lt;/code&amp;gt;, or &amp;lt;code&amp;gt;write&amp;lt;/code&amp;gt; index privilege.&amp;lt;/li&amp;gt;\n          &amp;lt;li&amp;gt;To automatically create a data stream or index with this API request, you must have the &amp;lt;code&amp;gt;auto_configure&amp;lt;/code&amp;gt;, &amp;lt;code&amp;gt;create_index&amp;lt;/code&amp;gt;, or &amp;lt;code&amp;gt;manage&amp;lt;/code&amp;gt; index privilege.&amp;lt;/li&amp;gt;\n          &amp;lt;/ul&amp;gt;\n          &amp;lt;p&amp;gt;Automatic data stream creation requires a matching index template with data stream enabled.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;NOTE: Replica shards might not all be started when an indexing operation returns successfully.\n          By default, only the primary is required. Set &amp;lt;code&amp;gt;wait_for_active_shards&amp;lt;/code&amp;gt; to change this default behavior.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;&amp;lt;strong&amp;gt;Automatically create data streams and indices&amp;lt;/strong&amp;gt;&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;If the request&amp;#x27;s target doesn&amp;#x27;t exist and matches an index template with a &amp;lt;code&amp;gt;data_stream&amp;lt;/code&amp;gt; definition, the index operation automatically creates the data stream.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;If the target doesn&amp;#x27;t exist and doesn&amp;#x27;t match a data stream template, the operation automatically creates the index and applies any matching index templates.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;NOTE: Elasticsearch includes several built-in index templates. To avoid naming collisions with these templates, refer to index pattern documentation.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;If no mapping exists, the index operation creates a dynamic mapping.\n          By default, new fields and objects are automatically added to the mapping if needed.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;Automatic index creation is controlled by the &amp;lt;code&amp;gt;action.auto_create_index&amp;lt;/code&amp;gt; setting.\n          If it is &amp;lt;code&amp;gt;true&amp;lt;/code&amp;gt;, any index can be created automatically.\n          You can modify this setting to explicitly allow or block automatic creation of indices that match specified patterns or set it to &amp;lt;code&amp;gt;false&amp;lt;/code&amp;gt; to turn off automatic index creation entirely.\n          Specify a comma-separated list of patterns you want to allow or prefix each pattern with &amp;lt;code&amp;gt;+&amp;lt;/code&amp;gt; or &amp;lt;code&amp;gt;-&amp;lt;/code&amp;gt; to indicate whether it should be allowed or blocked.\n          When a list is specified, the default behaviour is to disallow.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;NOTE: The &amp;lt;code&amp;gt;action.auto_create_index&amp;lt;/code&amp;gt; setting affects the automatic creation of indices only.\n          It does not affect the creation of data streams.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;&amp;lt;strong&amp;gt;Optimistic concurrency control&amp;lt;/strong&amp;gt;&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;Index operations can be made conditional and only be performed if the last modification to the document was assigned the sequence number and primary term specified by the &amp;lt;code&amp;gt;if_seq_no&amp;lt;/code&amp;gt; and &amp;lt;code&amp;gt;if_primary_term&amp;lt;/code&amp;gt; parameters.\n          If a mismatch is detected, the operation will result in a &amp;lt;code&amp;gt;VersionConflictException&amp;lt;/code&amp;gt; and a status code of &amp;lt;code&amp;gt;409&amp;lt;/code&amp;gt;.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;&amp;lt;strong&amp;gt;Routing&amp;lt;/strong&amp;gt;&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;By default, shard placement\u2009\u2014\u2009or routing\u2009\u2014\u2009is controlled by using a hash of the document&amp;#x27;s ID value.\n          For more explicit control, the value fed into the hash function used by the router can be directly specified on a per-operation basis using the &amp;lt;code&amp;gt;routing&amp;lt;/code&amp;gt; parameter.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;When setting up explicit mapping, you can also use the &amp;lt;code&amp;gt;_routing&amp;lt;/code&amp;gt; field to direct the index operation to extract the routing value from the document itself.\n          This does come at the (very minimal) cost of an additional document parsing pass.\n          If the &amp;lt;code&amp;gt;_routing&amp;lt;/code&amp;gt; mapping is defined and set to be required, the index operation will fail if no routing value is provided or extracted.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;NOTE: Data streams do not support custom routing unless they were created with the &amp;lt;code&amp;gt;allow_custom_routing&amp;lt;/code&amp;gt; setting enabled in the template.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;&amp;lt;strong&amp;gt;Distributed&amp;lt;/strong&amp;gt;&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;The index operation is directed to the primary shard based on its route and performed on the actual node containing this shard.\n          After the primary shard completes the operation, if needed, the update is distributed to applicable replicas.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;&amp;lt;strong&amp;gt;Active shards&amp;lt;/strong&amp;gt;&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;To improve the resiliency of writes to the system, indexing operations can be configured to wait for a certain number of active shard copies before proceeding with the operation.\n          If the requisite number of active shard copies are not available, then the write operation must wait and retry, until either the requisite shard copies have started or a timeout occurs.\n          By default, write operations only wait for the primary shards to be active before proceeding (that is to say &amp;lt;code&amp;gt;wait_for_active_shards&amp;lt;/code&amp;gt; is &amp;lt;code&amp;gt;1&amp;lt;/code&amp;gt;).\n          This default can be overridden in the index settings dynamically by setting &amp;lt;code&amp;gt;index.write.wait_for_active_shards&amp;lt;/code&amp;gt;.\n          To alter this behavior per operation, use the &amp;lt;code&amp;gt;wait_for_active_shards request&amp;lt;/code&amp;gt; parameter.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;Valid values are all or any positive integer up to the total number of configured copies per shard in the index (which is &amp;lt;code&amp;gt;number_of_replicas&amp;lt;/code&amp;gt;+1).\n          Specifying a negative value or a number greater than the number of shard copies will throw an error.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;For example, suppose you have a cluster of three nodes, A, B, and C and you create an index index with the number of replicas set to 3 (resulting in 4 shard copies, one more copy than there are nodes).\n          If you attempt an indexing operation, by default the operation will only ensure the primary copy of each shard is available before proceeding.\n          This means that even if B and C went down and A hosted the primary shard copies, the indexing operation would still proceed with only one copy of the data.\n          If &amp;lt;code&amp;gt;wait_for_active_shards&amp;lt;/code&amp;gt; is set on the request to &amp;lt;code&amp;gt;3&amp;lt;/code&amp;gt; (and all three nodes are up), the indexing operation will require 3 active shard copies before proceeding.\n          This requirement should be met because there are 3 active nodes in the cluster, each one holding a copy of the shard.\n          However, if you set &amp;lt;code&amp;gt;wait_for_active_shards&amp;lt;/code&amp;gt; to &amp;lt;code&amp;gt;all&amp;lt;/code&amp;gt; (or to &amp;lt;code&amp;gt;4&amp;lt;/code&amp;gt;, which is the same in this situation), the indexing operation will not proceed as you do not have all 4 copies of each shard active in the index.\n          The operation will timeout unless a new node is brought up in the cluster to host the fourth copy of the shard.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;It is important to note that this setting greatly reduces the chances of the write operation not writing to the requisite number of shard copies, but it does not completely eliminate the possibility, because this check occurs before the write operation starts.\n          After the write operation is underway, it is still possible for replication to fail on any number of shard copies but still succeed on the primary.\n          The &amp;lt;code&amp;gt;_shards&amp;lt;/code&amp;gt; section of the API response reveals the number of shard copies on which replication succeeded and failed.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;&amp;lt;strong&amp;gt;No operation (noop) updates&amp;lt;/strong&amp;gt;&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;When updating a document by using this API, a new version of the document is always created even if the document hasn&amp;#x27;t changed.\n          If this isn&amp;#x27;t acceptable use the &amp;lt;code&amp;gt;_update&amp;lt;/code&amp;gt; API with &amp;lt;code&amp;gt;detect_noop&amp;lt;/code&amp;gt; set to &amp;lt;code&amp;gt;true&amp;lt;/code&amp;gt;.\n          The &amp;lt;code&amp;gt;detect_noop&amp;lt;/code&amp;gt; option isn&amp;#x27;t available on this API because it doesn\u2019t fetch the old source and isn&amp;#x27;t able to compare it against the new source.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;There isn&amp;#x27;t a definitive rule for when noop updates aren&amp;#x27;t acceptable.\n          It&amp;#x27;s a combination of lots of factors like how frequently your data source sends updates that are actually noops and how many queries per second Elasticsearch runs on the shard receiving the updates.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;&amp;lt;strong&amp;gt;Versioning&amp;lt;/strong&amp;gt;&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;Each indexed document is given a version number.\n          By default, internal versioning is used that starts at 1 and increments with each update, deletes included.\n          Optionally, the version number can be set to an external value (for example, if maintained in a database).\n          To enable this functionality, &amp;lt;code&amp;gt;version_type&amp;lt;/code&amp;gt; should be set to &amp;lt;code&amp;gt;external&amp;lt;/code&amp;gt;.\n          The value provided must be a numeric, long value greater than or equal to 0, and less than around &amp;lt;code&amp;gt;9.2e+18&amp;lt;/code&amp;gt;.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;NOTE: Versioning is completely real time, and is not affected by the near real time aspects of search operations.\n          If no version is provided, the operation runs without any version checks.&amp;lt;/p&amp;gt;\n          &amp;lt;p&amp;gt;When using the external version type, the system checks to see if the version number passed to the index request is greater than the version of the currently stored document.\n          If true, the document will be indexed and the new version number used.\n          If the value provided is less than or equal to the stored document&amp;#x27;s version number, a version conflict will occur and the index operation will fail. For example:&amp;lt;/p&amp;gt;\n          &amp;lt;pre&amp;gt;&amp;lt;code&amp;gt;PUT my-index-000001/_doc/1?version=2&amp;amp;amp;version_type=external\n          {\n            &amp;amp;quot;user&amp;amp;quot;: {\n              &amp;amp;quot;id&amp;amp;quot;: &amp;amp;quot;elkbee&amp;amp;quot;\n            }\n          }\n    \n          In this example, the operation will succeed since the supplied version of 2 is higher than the current document version of 1.\n          If the document was already updated and its version was set to 2 or higher, the indexing command will fail and result in a conflict (409 HTTP status code).\n    \n          A nice side effect is that there is no need to maintain strict ordering of async indexing operations run as a result of changes to a source database, as long as version numbers from the source database are used.\n          Even the simple case of updating the Elasticsearch index using data from a database is simplified if external versioning is used, as only the latest version will be used if the index operations arrive out of order.\n          &amp;lt;/code&amp;gt;&amp;lt;/pre&amp;gt;\n    \n    \n        `&amp;lt;https://www.elastic.co/docs/api/doc/elasticsearch/v9/operation/operation-create&amp;gt;`_\n    \n        :param index: The name of the data stream or index to target. If the target doesn&amp;#x27;t\n            exist and matches the name or wildcard (`*`) pattern of an index template\n            with a `data_stream` definition, this request creates the data stream. If\n            the target doesn&amp;#x27;t exist and doesn&amp;#x27;t match a data stream template, this request\n            creates the index. You can check for existing targets with the resolve index\n            API.\n        :param document:\n        :param id: A unique identifier for the document. To automatically generate a\n            document ID, use the `POST /&amp;lt;target&amp;gt;/_doc/` request format and omit this\n            parameter.\n        :param if_primary_term: Only perform the operation if the document has this primary\n            term.\n        :param if_seq_no: Only perform the operation if the document has this sequence\n            number.\n        :param include_source_on_error: True or false if to include the document source\n            in the error message in case of parsing errors.\n        :param op_type: Set to `create` to only index the document if it does not already\n            exist (put if absent). If a document with the specified `_id` already exists,\n            the indexing operation will fail. The behavior is the same as using the `&amp;lt;index&amp;gt;/_create`\n            endpoint. If a document ID is specified, this paramater defaults to `index`.\n            Otherwise, it defaults to `create`. If the request targets a data stream,\n            an `op_type` of `create` is required.\n        :param pipeline: The ID of the pipeline to use to preprocess incoming documents.\n            If the index has a default ingest pipeline specified, then setting the value\n            to `_none` disables the default ingest pipeline for this request. If a final\n            pipeline is configured it will always run, regardless of the value of this\n            parameter.\n        :param refresh: If `true`, Elasticsearch refreshes the affected shards to make\n            this operation visible to search. If `wait_for`, it waits for a refresh to\n            make this operation visible to search. If `false`, it does nothing with refreshes.\n        :param require_alias: If `true`, the destination must be an index alias.\n        :param routing: A custom value that is used to route operations to a specific\n            shard.\n        :param timeout: The period the request waits for the following operations: automatic\n            index creation, dynamic mapping updates, waiting for active shards. This\n            parameter is useful for situations where the primary shard assigned to perform\n            the operation might not be available when the operation runs. Some reasons\n            for this might be that the primary shard is currently recovering from a gateway\n            or undergoing relocation. By default, the operation will wait on the primary\n            shard to become available for at least 1 minute before failing and responding\n            with an error. The actual wait time could be longer, particularly when multiple\n            waits occur.\n        :param version: An explicit version number for concurrency control. It must be\n            a non-negative long number.\n        :param version_type: The version type.\n        :param wait_for_active_shards: The number of shard copies that must be active\n            before proceeding with the operation. You can set it to `all` or any positive\n            integer up to the total number of shards in the index (`number_of_replicas+1`).\n            The default value of `1` means it waits for each primary shard to be active.\n        &amp;quot;&amp;quot;&amp;quot;\n        if index in SKIP_IN_PATH:\n            raise ValueError(&amp;quot;Empty value passed for parameter &amp;#x27;index&amp;#x27;&amp;quot;)\n        if document is None and body is None:\n            raise ValueError(\n                &amp;quot;Empty value passed for parameters &amp;#x27;document&amp;#x27; and &amp;#x27;body&amp;#x27;, one of them should be set.&amp;quot;\n            )\n        elif document is not None and body is not None:\n            raise ValueError(&amp;quot;Cannot set both &amp;#x27;document&amp;#x27; and &amp;#x27;body&amp;#x27;&amp;quot;)\n        __path_parts: t.Dict[str, str]\n        if index not in SKIP_IN_PATH and id not in SKIP_IN_PATH:\n            __path_parts = {&amp;quot;index&amp;quot;: _quote(index), &amp;quot;id&amp;quot;: _quote(id)}\n            __path = f&amp;#x27;/{__path_parts[&amp;quot;index&amp;quot;]}/_doc/{__path_parts[&amp;quot;id&amp;quot;]}&amp;#x27;\n            __method = &amp;quot;PUT&amp;quot;\n        elif index not in SKIP_IN_PATH:\n            __path_parts = {&amp;quot;index&amp;quot;: _quote(index)}\n            __path = f&amp;#x27;/{__path_parts[&amp;quot;index&amp;quot;]}/_doc&amp;#x27;\n            __method = &amp;quot;POST&amp;quot;\n        else:\n            raise ValueError(&amp;quot;Couldn&amp;#x27;t find a path for the given parameters&amp;quot;)\n        __query: t.Dict[str, t.Any] = {}\n        if error_trace is not None:\n            __query[&amp;quot;error_trace&amp;quot;] = error_trace\n        if filter_path is not None:\n            __query[&amp;quot;filter_path&amp;quot;] = filter_path\n        if human is not None:\n            __query[&amp;quot;human&amp;quot;] = human\n        if if_primary_term is not None:\n            __query[&amp;quot;if_primary_term&amp;quot;] = if_primary_term\n        if if_seq_no is not None:\n            __query[&amp;quot;if_seq_no&amp;quot;] = if_seq_no\n        if include_source_on_error is not None:\n            __query[&amp;quot;include_source_on_error&amp;quot;] = include_source_on_error\n        if op_type is not None:\n            __query[&amp;quot;op_type&amp;quot;] = op_type\n        if pipeline is not None:\n            __query[&amp;quot;pipeline&amp;quot;] = pipeline\n        if pretty is not None:\n            __query[&amp;quot;pretty&amp;quot;] = pretty\n        if refresh is not None:\n            __query[&amp;quot;refresh&amp;quot;] = refresh\n        if require_alias is not None:\n            __query[&amp;quot;require_alias&amp;quot;] = require_alias\n        if routing is not None:\n            __query[&amp;quot;routing&amp;quot;] = routing\n        if timeout is not None:\n            __query[&amp;quot;timeout&amp;quot;] = timeout\n        if version is not None:\n            __query[&amp;quot;version&amp;quot;] = version\n        if version_type is not None:\n            __query[&amp;quot;version_type&amp;quot;] = version_type\n        if wait_for_active_shards is not None:\n            __query[&amp;quot;wait_for_active_shards&amp;quot;] = wait_for_active_shards\n        __body = document if document is not None else body\n        __headers = {&amp;quot;accept&amp;quot;: &amp;quot;application/json&amp;quot;, &amp;quot;content-type&amp;quot;: &amp;quot;application/json&amp;quot;}\n&amp;gt;       return self.perform_request(  # type: ignore[return-value]\n            __method,\n            __path,\n            params=__query,\n            headers=__headers,\n            body=__body,\n            endpoint_id=&amp;quot;index&amp;quot;,\n            path_parts=__path_parts,\n        )\n\nC:\\Python313\\Lib\\site-packages\\elasticsearch\\_sync\\client\\__init__.py:2951: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;Elasticsearch([&amp;#x27;http://localhost:9200&amp;#x27;])&amp;gt;, method = &amp;#x27;POST&amp;#x27;\npath = &amp;#x27;/autocura-testes-2025.05.21/_doc&amp;#x27;\n\n    def perform_request(\n        self,\n        method: str,\n        path: str,\n        *,\n        params: Optional[Mapping[str, Any]] = None,\n        headers: Optional[Mapping[str, str]] = None,\n        body: Optional[Any] = None,\n        endpoint_id: Optional[str] = None,\n        path_parts: Optional[Mapping[str, Any]] = None,\n    ) -&amp;gt; ApiResponse[Any]:\n        with self._otel.span(\n            method,\n            endpoint_id=endpoint_id,\n            path_parts=path_parts or {},\n        ) as otel_span:\n&amp;gt;           response = self._perform_request(\n                method,\n                path,\n                params=params,\n                headers=headers,\n                body=body,\n                otel_span=otel_span,\n            )\n\nC:\\Python313\\Lib\\site-packages\\elasticsearch\\_sync\\client\\_base.py:271: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;Elasticsearch([&amp;#x27;http://localhost:9200&amp;#x27;])&amp;gt;, method = &amp;#x27;POST&amp;#x27;\npath = &amp;#x27;/autocura-testes-2025.05.21/_doc&amp;#x27;\n\n    def _perform_request(\n        self,\n        method: str,\n        path: str,\n        *,\n        params: Optional[Mapping[str, Any]] = None,\n        headers: Optional[Mapping[str, str]] = None,\n        body: Optional[Any] = None,\n        otel_span: OpenTelemetrySpan,\n    ) -&amp;gt; ApiResponse[Any]:\n        if headers:\n            request_headers = self._headers.copy()\n            request_headers.update(headers)\n        else:\n            request_headers = self._headers\n    \n        def mimetype_header_to_compat(header: str) -&amp;gt; None:\n            # Converts all parts of a Accept/Content-Type headers\n            # from application/X -&amp;gt; application/vnd.elasticsearch+X\n            mimetype = request_headers.get(header, None)\n            if mimetype:\n                request_headers[header] = _COMPAT_MIMETYPE_RE.sub(\n                    _COMPAT_MIMETYPE_SUB, mimetype\n                )\n    \n        mimetype_header_to_compat(&amp;quot;Accept&amp;quot;)\n        mimetype_header_to_compat(&amp;quot;Content-Type&amp;quot;)\n    \n        if params:\n            target = f&amp;quot;{path}?{_quote_query(params)}&amp;quot;\n        else:\n            target = path\n    \n&amp;gt;       meta, resp_body = self.transport.perform_request(\n            method,\n            target,\n            headers=request_headers,\n            body=body,\n            request_timeout=self._request_timeout,\n            max_retries=self._max_retries,\n            retry_on_status=self._retry_on_status,\n            retry_on_timeout=self._retry_on_timeout,\n            client_meta=self._client_meta,\n            otel_span=otel_span,\n        )\n\nC:\\Python313\\Lib\\site-packages\\elasticsearch\\_sync\\client\\_base.py:315: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;elastic_transport.Transport object at 0x000001E7F154D310&amp;gt;, method = &amp;#x27;POST&amp;#x27;\ntarget = &amp;#x27;/autocura-testes-2025.05.21/_doc&amp;#x27;\n\n    def perform_request(  # type: ignore[return]\n        self,\n        method: str,\n        target: str,\n        *,\n        body: Optional[Any] = None,\n        headers: Union[Mapping[str, Any], DefaultType] = DEFAULT,\n        max_retries: Union[int, DefaultType] = DEFAULT,\n        retry_on_status: Union[Collection[int], DefaultType] = DEFAULT,\n        retry_on_timeout: Union[bool, DefaultType] = DEFAULT,\n        request_timeout: Union[Optional[float], DefaultType] = DEFAULT,\n        client_meta: Union[Tuple[Tuple[str, str], ...], DefaultType] = DEFAULT,\n        otel_span: Union[OpenTelemetrySpan, DefaultType] = DEFAULT,\n    ) -&amp;gt; TransportApiResponse:\n        &amp;quot;&amp;quot;&amp;quot;\n        Perform the actual request. Retrieve a node from the node\n        pool, pass all the information to it&amp;#x27;s perform_request method and\n        return the data.\n    \n        If an exception was raised, mark the node as failed and retry (up\n        to ``max_retries`` times).\n    \n        If the operation was successful and the node used was previously\n        marked as dead, mark it as live, resetting it&amp;#x27;s failure count.\n    \n        :arg method: HTTP method to use\n        :arg target: HTTP request target\n        :arg body: body of the request, will be serialized using serializer and\n            passed to the node\n        :arg headers: Additional headers to send with the request.\n        :arg max_retries: Maximum number of retries before giving up on a request.\n            Set to ``0`` to disable retries.\n        :arg retry_on_status: Collection of HTTP status codes to retry.\n        :arg retry_on_timeout: Set to true to retry after timeout errors.\n        :arg request_timeout: Amount of time to wait for a response to fail with a timeout error.\n        :arg client_meta: Extra client metadata key-value pairs to send in the client meta header.\n        :arg otel_span: OpenTelemetry span used to add metadata to the span.\n    \n        :returns: Tuple of the :class:`elastic_transport.ApiResponseMeta` with the deserialized response.\n        &amp;quot;&amp;quot;&amp;quot;\n        if headers is DEFAULT:\n            request_headers = HttpHeaders()\n        else:\n            request_headers = HttpHeaders(headers)\n        max_retries = resolve_default(max_retries, self.max_retries)\n        retry_on_timeout = resolve_default(retry_on_timeout, self.retry_on_timeout)\n        retry_on_status = resolve_default(retry_on_status, self.retry_on_status)\n        otel_span = resolve_default(otel_span, OpenTelemetrySpan(None))\n    \n        if self.meta_header:\n            request_headers[&amp;quot;x-elastic-client-meta&amp;quot;] = &amp;quot;,&amp;quot;.join(\n                f&amp;quot;{k}={v}&amp;quot;\n                for k, v in self._transport_client_meta\n                + resolve_default(client_meta, ())\n            )\n    \n        # Serialize the request body to bytes based on the given mimetype.\n        request_body: Optional[bytes]\n        if body is not None:\n            if &amp;quot;content-type&amp;quot; not in request_headers:\n                raise ValueError(\n                    &amp;quot;Must provide a &amp;#x27;Content-Type&amp;#x27; header to requests with bodies&amp;quot;\n                )\n            request_body = self.serializers.dumps(\n                body, mimetype=request_headers[&amp;quot;content-type&amp;quot;]\n            )\n            otel_span.set_db_statement(request_body)\n        else:\n            request_body = None\n    \n        # Errors are stored from (oldest-&amp;gt;newest)\n        errors: List[Exception] = []\n    \n        for attempt in range(max_retries + 1):\n            # If we sniff before requests are made we want to do so before\n            # &amp;#x27;node_pool.get()&amp;#x27; is called so our sniffed nodes show up in the pool.\n            if self._sniff_before_requests:\n                self.sniff(False)\n    \n            retry = False\n            node_failure = False\n            last_response: Optional[TransportApiResponse] = None\n            node = self.node_pool.get()\n            start_time = time.time()\n            try:\n                otel_span.set_node_metadata(node.host, node.port, node.base_url, target)\n&amp;gt;               resp = node.perform_request(\n                    method,\n                    target,\n                    body=request_body,\n                    headers=request_headers,\n                    request_timeout=request_timeout,\n                )\n\nC:\\Python313\\Lib\\site-packages\\elastic_transport\\_transport.py:342: \n_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n\nself = &amp;lt;Urllib3HttpNode(http://localhost:9200)&amp;gt;, method = &amp;#x27;POST&amp;#x27;\ntarget = &amp;#x27;/autocura-testes-2025.05.21/_doc&amp;#x27;\nbody = b&amp;#x27;{&amp;quot;timestamp&amp;quot;:&amp;quot;2025-05-21T16:07:18.546552&amp;quot;,&amp;quot;nome&amp;quot;:&amp;quot;test_processamento_concorrente&amp;quot;,&amp;quot;sucesso&amp;quot;:true,&amp;quot;duracao&amp;quot;:1.8835067749023438e-05}&amp;#x27;\nheaders = {&amp;#x27;accept&amp;#x27;: &amp;#x27;application/vnd.elasticsearch+json; compatible-with=9&amp;#x27;, &amp;#x27;content-type&amp;#x27;: &amp;#x27;application/vnd.elasticsearch+json; compatible-with=9&amp;#x27;, &amp;#x27;x-elastic-client-meta&amp;#x27;: &amp;#x27;es=9.0.1,py=3.13.3,t=8.17.1,ur=2.4.0&amp;#x27;}\nrequest_timeout = &amp;lt;DEFAULT&amp;gt;\n\n    def perform_request(\n        self,\n        method: str,\n        target: str,\n        body: Optional[bytes] = None,\n        headers: Optional[HttpHeaders] = None,\n        request_timeout: Union[DefaultType, Optional[float]] = DEFAULT,\n    ) -&amp;gt; NodeApiResponse:\n        if self.path_prefix:\n            target = f&amp;quot;{self.path_prefix}{target}&amp;quot;\n    \n        start = time.time()\n        try:\n            kw = {}\n            if request_timeout is not DEFAULT:\n                kw[&amp;quot;timeout&amp;quot;] = request_timeout\n    \n            request_headers = self._headers.copy()\n            if headers:\n                request_headers.update(headers)\n    \n            body_to_send: Optional[bytes]\n            if body:\n                if self._http_compress:\n                    body_to_send = gzip.compress(body)\n                    request_headers[&amp;quot;content-encoding&amp;quot;] = &amp;quot;gzip&amp;quot;\n                else:\n                    body_to_send = body\n            else:\n                body_to_send = None\n    \n            response = self.pool.urlopen(\n                method,\n                target,\n                body=body_to_send,\n                retries=Retry(False),\n                headers=request_headers,\n                **kw,  # type: ignore[arg-type]\n            )\n            response_headers = HttpHeaders(response.headers)\n            data = response.data\n            duration = time.time() - start\n    \n        except RERAISE_EXCEPTIONS:\n            raise\n        except Exception as e:\n            err: Exception\n            if isinstance(e, NewConnectionError):\n                err = ConnectionError(str(e), errors=(e,))\n            elif isinstance(e, (ConnectTimeoutError, ReadTimeoutError)):\n                err = ConnectionTimeout(\n                    &amp;quot;Connection timed out during request&amp;quot;, errors=(e,)\n                )\n            elif isinstance(e, (ssl.SSLError, urllib3.exceptions.SSLError)):\n                err = TlsError(str(e), errors=(e,))\n            elif isinstance(e, BUILTIN_EXCEPTIONS):\n                raise\n            else:\n                err = ConnectionError(str(e), errors=(e,))\n            self._log_request(\n                method=method,\n                target=target,\n                headers=request_headers,\n                body=body,\n                exception=err,\n            )\n&amp;gt;           raise err from e\nE           elastic_transport.ConnectionError: Connection error caused by: ConnectionError(Connection error caused by: NewConnectionError(&amp;lt;urllib3.connection.HTTPConnection object at 0x000001E7F1BFC2F0&amp;gt;: Failed to establish a new connection: [WinError 10061] Nenhuma conex\u00e3o p\u00f4de ser feita porque a m\u00e1quina de destino as recusou ativamente))\n\nC:\\Python313\\Lib\\site-packages\\elastic_transport\\_node\\_http_urllib3.py:202: ConnectionError\n\n----------------------------- Captured stderr call -----------------------------\n2025-05-21 16:07:22,649 - elastic_transport.transport - INFO - POST http://localhost:9200/autocura-testes-2025.05.21/_doc [status:N/A duration:4.103s]\n2025-05-21 16:07:22,650 - elastic_transport.node_pool - WARNING - Node &amp;lt;Urllib3HttpNode(http://localhost:9200)&amp;gt; has failed for 1 times in a row, putting on 1 second timeout\n2025-05-21 16:07:22,650 - elastic_transport.transport - WARNING - Retrying request after failure (attempt 0 of 3)\nTraceback (most recent call last):\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 198, in _new_conn\n    sock = connection.create_connection(\n        (self._dns_host, self.port),\n    ...&amp;lt;2 lines&amp;gt;...\n        socket_options=self.socket_options,\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\connection.py&amp;quot;, line 85, in create_connection\n    raise err\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\connection.py&amp;quot;, line 73, in create_connection\n    sock.connect(sa)\n    ~~~~~~~~~~~~^^^^\nConnectionRefusedError: [WinError 10061] Nenhuma conex\u00e3o p\u00f4de ser feita porque a m\u00e1quina de destino as recusou ativamente\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\elastic_transport\\_node\\_http_urllib3.py&amp;quot;, line 167, in perform_request\n    response = self.pool.urlopen(\n        method,\n    ...&amp;lt;4 lines&amp;gt;...\n        **kw,  # type: ignore[arg-type]\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py&amp;quot;, line 841, in urlopen\n    retries = retries.increment(\n        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\retry.py&amp;quot;, line 449, in increment\n    raise reraise(type(error), error, _stacktrace)\n          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\util.py&amp;quot;, line 39, in reraise\n    raise value\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py&amp;quot;, line 787, in urlopen\n    response = self._make_request(\n        conn,\n    ...&amp;lt;10 lines&amp;gt;...\n        **response_kw,\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py&amp;quot;, line 493, in _make_request\n    conn.request(\n    ~~~~~~~~~~~~^\n        method,\n        ^^^^^^^\n    ...&amp;lt;6 lines&amp;gt;...\n        enforce_content_length=enforce_content_length,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 445, in request\n    self.endheaders()\n    ~~~~~~~~~~~~~~~^^\n  File &amp;quot;C:\\Python313\\Lib\\http\\client.py&amp;quot;, line 1333, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;C:\\Python313\\Lib\\http\\client.py&amp;quot;, line 1093, in _send_output\n    self.send(msg)\n    ~~~~~~~~~^^^^^\n  File &amp;quot;C:\\Python313\\Lib\\http\\client.py&amp;quot;, line 1037, in send\n    self.connect()\n    ~~~~~~~~~~~~^^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 276, in connect\n    self.sock = self._new_conn()\n                ~~~~~~~~~~~~~~^^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 213, in _new_conn\n    raise NewConnectionError(\n        self, f&amp;quot;Failed to establish a new connection: {e}&amp;quot;\n    ) from e\nurllib3.exceptions.NewConnectionError: &amp;lt;urllib3.connection.HTTPConnection object at 0x000001E7F1BFC2F0&amp;gt;: Failed to establish a new connection: [WinError 10061] Nenhuma conex\u00e3o p\u00f4de ser feita porque a m\u00e1quina de destino as recusou ativamente\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\elastic_transport\\_transport.py&amp;quot;, line 342, in perform_request\n    resp = node.perform_request(\n        method,\n    ...&amp;lt;3 lines&amp;gt;...\n        request_timeout=request_timeout,\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\elastic_transport\\_node\\_http_urllib3.py&amp;quot;, line 202, in perform_request\n    raise err from e\nelastic_transport.ConnectionError: Connection error caused by: NewConnectionError(&amp;lt;urllib3.connection.HTTPConnection object at 0x000001E7F1BFC2F0&amp;gt;: Failed to establish a new connection: [WinError 10061] Nenhuma conex\u00e3o p\u00f4de ser feita porque a m\u00e1quina de destino as recusou ativamente)\n2025-05-21 16:07:26,750 - elastic_transport.transport - INFO - POST http://localhost:9200/autocura-testes-2025.05.21/_doc [status:N/A duration:4.094s]\n2025-05-21 16:07:26,750 - elastic_transport.node_pool - WARNING - Node &amp;lt;Urllib3HttpNode(http://localhost:9200)&amp;gt; has failed for 2 times in a row, putting on 2 second timeout\n2025-05-21 16:07:26,751 - elastic_transport.transport - WARNING - Retrying request after failure (attempt 1 of 3)\nTraceback (most recent call last):\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 198, in _new_conn\n    sock = connection.create_connection(\n        (self._dns_host, self.port),\n    ...&amp;lt;2 lines&amp;gt;...\n        socket_options=self.socket_options,\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\connection.py&amp;quot;, line 85, in create_connection\n    raise err\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\connection.py&amp;quot;, line 73, in create_connection\n    sock.connect(sa)\n    ~~~~~~~~~~~~^^^^\nConnectionRefusedError: [WinError 10061] Nenhuma conex\u00e3o p\u00f4de ser feita porque a m\u00e1quina de destino as recusou ativamente\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\elastic_transport\\_node\\_http_urllib3.py&amp;quot;, line 167, in perform_request\n    response = self.pool.urlopen(\n        method,\n    ...&amp;lt;4 lines&amp;gt;...\n        **kw,  # type: ignore[arg-type]\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py&amp;quot;, line 841, in urlopen\n    retries = retries.increment(\n        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\retry.py&amp;quot;, line 449, in increment\n    raise reraise(type(error), error, _stacktrace)\n          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\util.py&amp;quot;, line 39, in reraise\n    raise value\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py&amp;quot;, line 787, in urlopen\n    response = self._make_request(\n        conn,\n    ...&amp;lt;10 lines&amp;gt;...\n        **response_kw,\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py&amp;quot;, line 493, in _make_request\n    conn.request(\n    ~~~~~~~~~~~~^\n        method,\n        ^^^^^^^\n    ...&amp;lt;6 lines&amp;gt;...\n        enforce_content_length=enforce_content_length,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 445, in request\n    self.endheaders()\n    ~~~~~~~~~~~~~~~^^\n  File &amp;quot;C:\\Python313\\Lib\\http\\client.py&amp;quot;, line 1333, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;C:\\Python313\\Lib\\http\\client.py&amp;quot;, line 1093, in _send_output\n    self.send(msg)\n    ~~~~~~~~~^^^^^\n  File &amp;quot;C:\\Python313\\Lib\\http\\client.py&amp;quot;, line 1037, in send\n    self.connect()\n    ~~~~~~~~~~~~^^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 276, in connect\n    self.sock = self._new_conn()\n                ~~~~~~~~~~~~~~^^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 213, in _new_conn\n    raise NewConnectionError(\n        self, f&amp;quot;Failed to establish a new connection: {e}&amp;quot;\n    ) from e\nurllib3.exceptions.NewConnectionError: &amp;lt;urllib3.connection.HTTPConnection object at 0x000001E7F1B1FC50&amp;gt;: Failed to establish a new connection: [WinError 10061] Nenhuma conex\u00e3o p\u00f4de ser feita porque a m\u00e1quina de destino as recusou ativamente\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\elastic_transport\\_transport.py&amp;quot;, line 342, in perform_request\n    resp = node.perform_request(\n        method,\n    ...&amp;lt;3 lines&amp;gt;...\n        request_timeout=request_timeout,\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\elastic_transport\\_node\\_http_urllib3.py&amp;quot;, line 202, in perform_request\n    raise err from e\nelastic_transport.ConnectionError: Connection error caused by: NewConnectionError(&amp;lt;urllib3.connection.HTTPConnection object at 0x000001E7F1B1FC50&amp;gt;: Failed to establish a new connection: [WinError 10061] Nenhuma conex\u00e3o p\u00f4de ser feita porque a m\u00e1quina de destino as recusou ativamente)\n2025-05-21 16:07:26,753 - elastic_transport.node_pool - INFO - Resurrected node &amp;lt;Urllib3HttpNode(http://localhost:9200)&amp;gt; (force=False)\n2025-05-21 16:07:30,827 - elastic_transport.transport - INFO - POST http://localhost:9200/autocura-testes-2025.05.21/_doc [status:N/A duration:4.074s]\n2025-05-21 16:07:30,828 - elastic_transport.node_pool - WARNING - Node &amp;lt;Urllib3HttpNode(http://localhost:9200)&amp;gt; has failed for 3 times in a row, putting on 4 second timeout\n2025-05-21 16:07:30,828 - elastic_transport.transport - WARNING - Retrying request after failure (attempt 2 of 3)\nTraceback (most recent call last):\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 198, in _new_conn\n    sock = connection.create_connection(\n        (self._dns_host, self.port),\n    ...&amp;lt;2 lines&amp;gt;...\n        socket_options=self.socket_options,\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\connection.py&amp;quot;, line 85, in create_connection\n    raise err\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\connection.py&amp;quot;, line 73, in create_connection\n    sock.connect(sa)\n    ~~~~~~~~~~~~^^^^\nConnectionRefusedError: [WinError 10061] Nenhuma conex\u00e3o p\u00f4de ser feita porque a m\u00e1quina de destino as recusou ativamente\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\elastic_transport\\_node\\_http_urllib3.py&amp;quot;, line 167, in perform_request\n    response = self.pool.urlopen(\n        method,\n    ...&amp;lt;4 lines&amp;gt;...\n        **kw,  # type: ignore[arg-type]\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py&amp;quot;, line 841, in urlopen\n    retries = retries.increment(\n        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\retry.py&amp;quot;, line 449, in increment\n    raise reraise(type(error), error, _stacktrace)\n          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\util.py&amp;quot;, line 39, in reraise\n    raise value\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py&amp;quot;, line 787, in urlopen\n    response = self._make_request(\n        conn,\n    ...&amp;lt;10 lines&amp;gt;...\n        **response_kw,\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py&amp;quot;, line 493, in _make_request\n    conn.request(\n    ~~~~~~~~~~~~^\n        method,\n        ^^^^^^^\n    ...&amp;lt;6 lines&amp;gt;...\n        enforce_content_length=enforce_content_length,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 445, in request\n    self.endheaders()\n    ~~~~~~~~~~~~~~~^^\n  File &amp;quot;C:\\Python313\\Lib\\http\\client.py&amp;quot;, line 1333, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;C:\\Python313\\Lib\\http\\client.py&amp;quot;, line 1093, in _send_output\n    self.send(msg)\n    ~~~~~~~~~^^^^^\n  File &amp;quot;C:\\Python313\\Lib\\http\\client.py&amp;quot;, line 1037, in send\n    self.connect()\n    ~~~~~~~~~~~~^^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 276, in connect\n    self.sock = self._new_conn()\n                ~~~~~~~~~~~~~~^^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 213, in _new_conn\n    raise NewConnectionError(\n        self, f&amp;quot;Failed to establish a new connection: {e}&amp;quot;\n    ) from e\nurllib3.exceptions.NewConnectionError: &amp;lt;urllib3.connection.HTTPConnection object at 0x000001E7F1B1FD90&amp;gt;: Failed to establish a new connection: [WinError 10061] Nenhuma conex\u00e3o p\u00f4de ser feita porque a m\u00e1quina de destino as recusou ativamente\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\elastic_transport\\_transport.py&amp;quot;, line 342, in perform_request\n    resp = node.perform_request(\n        method,\n    ...&amp;lt;3 lines&amp;gt;...\n        request_timeout=request_timeout,\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\elastic_transport\\_node\\_http_urllib3.py&amp;quot;, line 202, in perform_request\n    raise err from e\nelastic_transport.ConnectionError: Connection error caused by: NewConnectionError(&amp;lt;urllib3.connection.HTTPConnection object at 0x000001E7F1B1FD90&amp;gt;: Failed to establish a new connection: [WinError 10061] Nenhuma conex\u00e3o p\u00f4de ser feita porque a m\u00e1quina de destino as recusou ativamente)\n2025-05-21 16:07:30,832 - elastic_transport.node_pool - INFO - Resurrected node &amp;lt;Urllib3HttpNode(http://localhost:9200)&amp;gt; (force=False)\n2025-05-21 16:07:34,911 - elastic_transport.transport - INFO - POST http://localhost:9200/autocura-testes-2025.05.21/_doc [status:N/A duration:4.079s]\n2025-05-21 16:07:34,911 - elastic_transport.node_pool - WARNING - Node &amp;lt;Urllib3HttpNode(http://localhost:9200)&amp;gt; has failed for 4 times in a row, putting on 8 second timeout\n\n------------------------------ Captured log call -------------------------------\nINFO     elastic_transport.transport:_transport.py:372 POST http://localhost:9200/autocura-testes-2025.05.21/_doc [status:N/A duration:4.103s]\nWARNING  elastic_transport.node_pool:_node_pool.py:249 Node &amp;lt;Urllib3HttpNode(http://localhost:9200)&amp;gt; has failed for 1 times in a row, putting on 1 second timeout\nWARNING  elastic_transport.transport:_transport.py:415 Retrying request after failure (attempt 0 of 3)\nTraceback (most recent call last):\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 198, in _new_conn\n    sock = connection.create_connection(\n        (self._dns_host, self.port),\n    ...&amp;lt;2 lines&amp;gt;...\n        socket_options=self.socket_options,\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\connection.py&amp;quot;, line 85, in create_connection\n    raise err\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\connection.py&amp;quot;, line 73, in create_connection\n    sock.connect(sa)\n    ~~~~~~~~~~~~^^^^\nConnectionRefusedError: [WinError 10061] Nenhuma conex\u00e3o p\u00f4de ser feita porque a m\u00e1quina de destino as recusou ativamente\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\elastic_transport\\_node\\_http_urllib3.py&amp;quot;, line 167, in perform_request\n    response = self.pool.urlopen(\n        method,\n    ...&amp;lt;4 lines&amp;gt;...\n        **kw,  # type: ignore[arg-type]\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py&amp;quot;, line 841, in urlopen\n    retries = retries.increment(\n        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\retry.py&amp;quot;, line 449, in increment\n    raise reraise(type(error), error, _stacktrace)\n          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\util.py&amp;quot;, line 39, in reraise\n    raise value\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py&amp;quot;, line 787, in urlopen\n    response = self._make_request(\n        conn,\n    ...&amp;lt;10 lines&amp;gt;...\n        **response_kw,\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py&amp;quot;, line 493, in _make_request\n    conn.request(\n    ~~~~~~~~~~~~^\n        method,\n        ^^^^^^^\n    ...&amp;lt;6 lines&amp;gt;...\n        enforce_content_length=enforce_content_length,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 445, in request\n    self.endheaders()\n    ~~~~~~~~~~~~~~~^^\n  File &amp;quot;C:\\Python313\\Lib\\http\\client.py&amp;quot;, line 1333, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;C:\\Python313\\Lib\\http\\client.py&amp;quot;, line 1093, in _send_output\n    self.send(msg)\n    ~~~~~~~~~^^^^^\n  File &amp;quot;C:\\Python313\\Lib\\http\\client.py&amp;quot;, line 1037, in send\n    self.connect()\n    ~~~~~~~~~~~~^^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 276, in connect\n    self.sock = self._new_conn()\n                ~~~~~~~~~~~~~~^^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 213, in _new_conn\n    raise NewConnectionError(\n        self, f&amp;quot;Failed to establish a new connection: {e}&amp;quot;\n    ) from e\nurllib3.exceptions.NewConnectionError: &amp;lt;urllib3.connection.HTTPConnection object at 0x000001E7F1BFC2F0&amp;gt;: Failed to establish a new connection: [WinError 10061] Nenhuma conex\u00e3o p\u00f4de ser feita porque a m\u00e1quina de destino as recusou ativamente\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\elastic_transport\\_transport.py&amp;quot;, line 342, in perform_request\n    resp = node.perform_request(\n        method,\n    ...&amp;lt;3 lines&amp;gt;...\n        request_timeout=request_timeout,\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\elastic_transport\\_node\\_http_urllib3.py&amp;quot;, line 202, in perform_request\n    raise err from e\nelastic_transport.ConnectionError: Connection error caused by: NewConnectionError(&amp;lt;urllib3.connection.HTTPConnection object at 0x000001E7F1BFC2F0&amp;gt;: Failed to establish a new connection: [WinError 10061] Nenhuma conex\u00e3o p\u00f4de ser feita porque a m\u00e1quina de destino as recusou ativamente)\nINFO     elastic_transport.transport:_transport.py:372 POST http://localhost:9200/autocura-testes-2025.05.21/_doc [status:N/A duration:4.094s]\nWARNING  elastic_transport.node_pool:_node_pool.py:249 Node &amp;lt;Urllib3HttpNode(http://localhost:9200)&amp;gt; has failed for 2 times in a row, putting on 2 second timeout\nWARNING  elastic_transport.transport:_transport.py:415 Retrying request after failure (attempt 1 of 3)\nTraceback (most recent call last):\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 198, in _new_conn\n    sock = connection.create_connection(\n        (self._dns_host, self.port),\n    ...&amp;lt;2 lines&amp;gt;...\n        socket_options=self.socket_options,\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\connection.py&amp;quot;, line 85, in create_connection\n    raise err\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\connection.py&amp;quot;, line 73, in create_connection\n    sock.connect(sa)\n    ~~~~~~~~~~~~^^^^\nConnectionRefusedError: [WinError 10061] Nenhuma conex\u00e3o p\u00f4de ser feita porque a m\u00e1quina de destino as recusou ativamente\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\elastic_transport\\_node\\_http_urllib3.py&amp;quot;, line 167, in perform_request\n    response = self.pool.urlopen(\n        method,\n    ...&amp;lt;4 lines&amp;gt;...\n        **kw,  # type: ignore[arg-type]\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py&amp;quot;, line 841, in urlopen\n    retries = retries.increment(\n        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\retry.py&amp;quot;, line 449, in increment\n    raise reraise(type(error), error, _stacktrace)\n          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\util.py&amp;quot;, line 39, in reraise\n    raise value\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py&amp;quot;, line 787, in urlopen\n    response = self._make_request(\n        conn,\n    ...&amp;lt;10 lines&amp;gt;...\n        **response_kw,\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py&amp;quot;, line 493, in _make_request\n    conn.request(\n    ~~~~~~~~~~~~^\n        method,\n        ^^^^^^^\n    ...&amp;lt;6 lines&amp;gt;...\n        enforce_content_length=enforce_content_length,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 445, in request\n    self.endheaders()\n    ~~~~~~~~~~~~~~~^^\n  File &amp;quot;C:\\Python313\\Lib\\http\\client.py&amp;quot;, line 1333, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;C:\\Python313\\Lib\\http\\client.py&amp;quot;, line 1093, in _send_output\n    self.send(msg)\n    ~~~~~~~~~^^^^^\n  File &amp;quot;C:\\Python313\\Lib\\http\\client.py&amp;quot;, line 1037, in send\n    self.connect()\n    ~~~~~~~~~~~~^^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 276, in connect\n    self.sock = self._new_conn()\n                ~~~~~~~~~~~~~~^^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 213, in _new_conn\n    raise NewConnectionError(\n        self, f&amp;quot;Failed to establish a new connection: {e}&amp;quot;\n    ) from e\nurllib3.exceptions.NewConnectionError: &amp;lt;urllib3.connection.HTTPConnection object at 0x000001E7F1B1FC50&amp;gt;: Failed to establish a new connection: [WinError 10061] Nenhuma conex\u00e3o p\u00f4de ser feita porque a m\u00e1quina de destino as recusou ativamente\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\elastic_transport\\_transport.py&amp;quot;, line 342, in perform_request\n    resp = node.perform_request(\n        method,\n    ...&amp;lt;3 lines&amp;gt;...\n        request_timeout=request_timeout,\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\elastic_transport\\_node\\_http_urllib3.py&amp;quot;, line 202, in perform_request\n    raise err from e\nelastic_transport.ConnectionError: Connection error caused by: NewConnectionError(&amp;lt;urllib3.connection.HTTPConnection object at 0x000001E7F1B1FC50&amp;gt;: Failed to establish a new connection: [WinError 10061] Nenhuma conex\u00e3o p\u00f4de ser feita porque a m\u00e1quina de destino as recusou ativamente)\nINFO     elastic_transport.node_pool:_node_pool.py:310 Resurrected node &amp;lt;Urllib3HttpNode(http://localhost:9200)&amp;gt; (force=False)\nINFO     elastic_transport.transport:_transport.py:372 POST http://localhost:9200/autocura-testes-2025.05.21/_doc [status:N/A duration:4.074s]\nWARNING  elastic_transport.node_pool:_node_pool.py:249 Node &amp;lt;Urllib3HttpNode(http://localhost:9200)&amp;gt; has failed for 3 times in a row, putting on 4 second timeout\nWARNING  elastic_transport.transport:_transport.py:415 Retrying request after failure (attempt 2 of 3)\nTraceback (most recent call last):\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 198, in _new_conn\n    sock = connection.create_connection(\n        (self._dns_host, self.port),\n    ...&amp;lt;2 lines&amp;gt;...\n        socket_options=self.socket_options,\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\connection.py&amp;quot;, line 85, in create_connection\n    raise err\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\connection.py&amp;quot;, line 73, in create_connection\n    sock.connect(sa)\n    ~~~~~~~~~~~~^^^^\nConnectionRefusedError: [WinError 10061] Nenhuma conex\u00e3o p\u00f4de ser feita porque a m\u00e1quina de destino as recusou ativamente\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\elastic_transport\\_node\\_http_urllib3.py&amp;quot;, line 167, in perform_request\n    response = self.pool.urlopen(\n        method,\n    ...&amp;lt;4 lines&amp;gt;...\n        **kw,  # type: ignore[arg-type]\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py&amp;quot;, line 841, in urlopen\n    retries = retries.increment(\n        method, url, error=new_e, _pool=self, _stacktrace=sys.exc_info()[2]\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\retry.py&amp;quot;, line 449, in increment\n    raise reraise(type(error), error, _stacktrace)\n          ~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\util\\util.py&amp;quot;, line 39, in reraise\n    raise value\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py&amp;quot;, line 787, in urlopen\n    response = self._make_request(\n        conn,\n    ...&amp;lt;10 lines&amp;gt;...\n        **response_kw,\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connectionpool.py&amp;quot;, line 493, in _make_request\n    conn.request(\n    ~~~~~~~~~~~~^\n        method,\n        ^^^^^^^\n    ...&amp;lt;6 lines&amp;gt;...\n        enforce_content_length=enforce_content_length,\n        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n    )\n    ^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 445, in request\n    self.endheaders()\n    ~~~~~~~~~~~~~~~^^\n  File &amp;quot;C:\\Python313\\Lib\\http\\client.py&amp;quot;, line 1333, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n    ~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File &amp;quot;C:\\Python313\\Lib\\http\\client.py&amp;quot;, line 1093, in _send_output\n    self.send(msg)\n    ~~~~~~~~~^^^^^\n  File &amp;quot;C:\\Python313\\Lib\\http\\client.py&amp;quot;, line 1037, in send\n    self.connect()\n    ~~~~~~~~~~~~^^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 276, in connect\n    self.sock = self._new_conn()\n                ~~~~~~~~~~~~~~^^\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\urllib3\\connection.py&amp;quot;, line 213, in _new_conn\n    raise NewConnectionError(\n        self, f&amp;quot;Failed to establish a new connection: {e}&amp;quot;\n    ) from e\nurllib3.exceptions.NewConnectionError: &amp;lt;urllib3.connection.HTTPConnection object at 0x000001E7F1B1FD90&amp;gt;: Failed to establish a new connection: [WinError 10061] Nenhuma conex\u00e3o p\u00f4de ser feita porque a m\u00e1quina de destino as recusou ativamente\n\nThe above exception was the direct cause of the following exception:\n\nTraceback (most recent call last):\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\elastic_transport\\_transport.py&amp;quot;, line 342, in perform_request\n    resp = node.perform_request(\n        method,\n    ...&amp;lt;3 lines&amp;gt;...\n        request_timeout=request_timeout,\n    )\n  File &amp;quot;C:\\Python313\\Lib\\site-packages\\elastic_transport\\_node\\_http_urllib3.py&amp;quot;, line 202, in perform_request\n    raise err from e\nelastic_transport.ConnectionError: Connection error caused by: NewConnectionError(&amp;lt;urllib3.connection.HTTPConnection object at 0x000001E7F1B1FD90&amp;gt;: Failed to establish a new connection: [WinError 10061] Nenhuma conex\u00e3o p\u00f4de ser feita porque a m\u00e1quina de destino as recusou ativamente)\nINFO     elastic_transport.node_pool:_node_pool.py:310 Resurrected node &amp;lt;Urllib3HttpNode(http://localhost:9200)&amp;gt; (force=False)\nINFO     elastic_transport.transport:_transport.py:372 POST http://localhost:9200/autocura-testes-2025.05.21/_doc [status:N/A duration:4.079s]\nWARNING  elastic_transport.node_pool:_node_pool.py:249 Node &amp;lt;Urllib3HttpNode(http://localhost:9200)&amp;gt; has failed for 4 times in a row, putting on 8 second timeout\n\n&#34;}]}, &#34;renderCollapsed&#34;: [&#34;passed&#34;], &#34;initialSort&#34;: &#34;result&#34;, &#34;title&#34;: &#34;report.html&#34;}"></div>
    <script>
      (function(){function r(e,n,t){function o(i,f){if(!n[i]){if(!e[i]){var c="function"==typeof require&&require;if(!f&&c)return c(i,!0);if(u)return u(i,!0);var a=new Error("Cannot find module '"+i+"'");throw a.code="MODULE_NOT_FOUND",a}var p=n[i]={exports:{}};e[i][0].call(p.exports,function(r){var n=e[i][1][r];return o(n||r)},p,p.exports,r,e,n,t)}return n[i].exports}for(var u="function"==typeof require&&require,i=0;i<t.length;i++)o(t[i]);return o}return r})()({1:[function(require,module,exports){
const { getCollapsedCategory, setCollapsedIds } = require('./storage.js')

class DataManager {
    setManager(data) {
        const collapsedCategories = [...getCollapsedCategory(data.renderCollapsed)]
        const collapsedIds = []
        const tests = Object.values(data.tests).flat().map((test, index) => {
            const collapsed = collapsedCategories.includes(test.result.toLowerCase())
            const id = `test_${index}`
            if (collapsed) {
                collapsedIds.push(id)
            }
            return {
                ...test,
                id,
                collapsed,
            }
        })
        const dataBlob = { ...data, tests }
        this.data = { ...dataBlob }
        this.renderData = { ...dataBlob }
        setCollapsedIds(collapsedIds)
    }

    get allData() {
        return { ...this.data }
    }

    resetRender() {
        this.renderData = { ...this.data }
    }

    setRender(data) {
        this.renderData.tests = [...data]
    }

    toggleCollapsedItem(id) {
        this.renderData.tests = this.renderData.tests.map((test) =>
            test.id === id ? { ...test, collapsed: !test.collapsed } : test,
        )
    }

    set allCollapsed(collapsed) {
        this.renderData = { ...this.renderData, tests: [...this.renderData.tests.map((test) => (
            { ...test, collapsed }
        ))] }
    }

    get testSubset() {
        return [...this.renderData.tests]
    }

    get environment() {
        return this.renderData.environment
    }

    get initialSort() {
        return this.data.initialSort
    }
}

module.exports = {
    manager: new DataManager(),
}

},{"./storage.js":8}],2:[function(require,module,exports){
const mediaViewer = require('./mediaviewer.js')
const templateEnvRow = document.getElementById('template_environment_row')
const templateResult = document.getElementById('template_results-table__tbody')

function htmlToElements(html) {
    const temp = document.createElement('template')
    temp.innerHTML = html
    return temp.content.childNodes
}

const find = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return elem.querySelector(selector)
}

const findAll = (selector, elem) => {
    if (!elem) {
        elem = document
    }
    return [...elem.querySelectorAll(selector)]
}

const dom = {
    getStaticRow: (key, value) => {
        const envRow = templateEnvRow.content.cloneNode(true)
        const isObj = typeof value === 'object' && value !== null
        const values = isObj ? Object.keys(value).map((k) => `${k}: ${value[k]}`) : null

        const valuesElement = htmlToElements(
            values ? `<ul>${values.map((val) => `<li>${val}</li>`).join('')}<ul>` : `<div>${value}</div>`)[0]
        const td = findAll('td', envRow)
        td[0].textContent = key
        td[1].appendChild(valuesElement)

        return envRow
    },
    getResultTBody: ({ testId, id, log, extras, resultsTableRow, tableHtml, result, collapsed }) => {
        const resultBody = templateResult.content.cloneNode(true)
        resultBody.querySelector('tbody').classList.add(result.toLowerCase())
        resultBody.querySelector('tbody').id = testId
        resultBody.querySelector('.collapsible').dataset.id = id

        resultsTableRow.forEach((html) => {
            const t = document.createElement('template')
            t.innerHTML = html
            resultBody.querySelector('.collapsible').appendChild(t.content)
        })

        if (log) {
            // Wrap lines starting with "E" with span.error to color those lines red
            const wrappedLog = log.replace(/^E.*$/gm, (match) => `<span class="error">${match}</span>`)
            resultBody.querySelector('.log').innerHTML = wrappedLog
        } else {
            resultBody.querySelector('.log').remove()
        }

        if (collapsed) {
            resultBody.querySelector('.collapsible > td')?.classList.add('collapsed')
            resultBody.querySelector('.extras-row').classList.add('hidden')
        } else {
            resultBody.querySelector('.collapsible > td')?.classList.remove('collapsed')
        }

        const media = []
        extras?.forEach(({ name, format_type, content }) => {
            if (['image', 'video'].includes(format_type)) {
                media.push({ path: content, name, format_type })
            }

            if (format_type === 'html') {
                resultBody.querySelector('.extraHTML').insertAdjacentHTML('beforeend', `<div>${content}</div>`)
            }
        })
        mediaViewer.setup(resultBody, media)

        // Add custom html from the pytest_html_results_table_html hook
        tableHtml?.forEach((item) => {
            resultBody.querySelector('td[class="extra"]').insertAdjacentHTML('beforeend', item)
        })

        return resultBody
    },
}

module.exports = {
    dom,
    htmlToElements,
    find,
    findAll,
}

},{"./mediaviewer.js":6}],3:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const storageModule = require('./storage.js')

const getFilteredSubSet = (filter) =>
    manager.allData.tests.filter(({ result }) => filter.includes(result.toLowerCase()))

const doInitFilter = () => {
    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)
}

const doFilter = (type, show) => {
    if (show) {
        storageModule.showCategory(type)
    } else {
        storageModule.hideCategory(type)
    }

    const currentFilter = storageModule.getVisible()
    const filteredSubset = getFilteredSubSet(currentFilter)
    manager.setRender(filteredSubset)

    const sortColumn = storageModule.getSort()
    doSort(sortColumn, true)
}

module.exports = {
    doFilter,
    doInitFilter,
}

},{"./datamanager.js":1,"./sort.js":7,"./storage.js":8}],4:[function(require,module,exports){
const { redraw, bindEvents, renderStatic } = require('./main.js')
const { doInitFilter } = require('./filter.js')
const { doInitSort } = require('./sort.js')
const { manager } = require('./datamanager.js')
const data = JSON.parse(document.getElementById('data-container').dataset.jsonblob)

function init() {
    manager.setManager(data)
    doInitFilter()
    doInitSort()
    renderStatic()
    redraw()
    bindEvents()
}

init()

},{"./datamanager.js":1,"./filter.js":3,"./main.js":5,"./sort.js":7}],5:[function(require,module,exports){
const { dom, find, findAll } = require('./dom.js')
const { manager } = require('./datamanager.js')
const { doSort } = require('./sort.js')
const { doFilter } = require('./filter.js')
const {
    getVisible,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    getSortDirection,
    possibleFilters,
} = require('./storage.js')

const removeChildren = (node) => {
    while (node.firstChild) {
        node.removeChild(node.firstChild)
    }
}

const renderStatic = () => {
    const renderEnvironmentTable = () => {
        const environment = manager.environment
        const rows = Object.keys(environment).map((key) => dom.getStaticRow(key, environment[key]))
        const table = document.getElementById('environment')
        removeChildren(table)
        rows.forEach((row) => table.appendChild(row))
    }
    renderEnvironmentTable()
}

const addItemToggleListener = (elem) => {
    elem.addEventListener('click', ({ target }) => {
        const id = target.parentElement.dataset.id
        manager.toggleCollapsedItem(id)

        const collapsedIds = getCollapsedIds()
        if (collapsedIds.includes(id)) {
            const updated = collapsedIds.filter((item) => item !== id)
            setCollapsedIds(updated)
        } else {
            collapsedIds.push(id)
            setCollapsedIds(collapsedIds)
        }
        redraw()
    })
}

const renderContent = (tests) => {
    const sortAttr = getSort(manager.initialSort)
    const sortAsc = JSON.parse(getSortDirection())
    const rows = tests.map(dom.getResultTBody)
    const table = document.getElementById('results-table')
    const tableHeader = document.getElementById('results-table-head')

    const newTable = document.createElement('table')
    newTable.id = 'results-table'

    // remove all sorting classes and set the relevant
    findAll('.sortable', tableHeader).forEach((elem) => elem.classList.remove('asc', 'desc'))
    tableHeader.querySelector(`.sortable[data-column-type="${sortAttr}"]`)?.classList.add(sortAsc ? 'desc' : 'asc')
    newTable.appendChild(tableHeader)

    if (!rows.length) {
        const emptyTable = document.getElementById('template_results-table__body--empty').content.cloneNode(true)
        newTable.appendChild(emptyTable)
    } else {
        rows.forEach((row) => {
            if (!!row) {
                findAll('.collapsible td:not(.col-links', row).forEach(addItemToggleListener)
                find('.logexpander', row).addEventListener('click',
                    (evt) => evt.target.parentNode.classList.toggle('expanded'),
                )
                newTable.appendChild(row)
            }
        })
    }

    table.replaceWith(newTable)
}

const renderDerived = () => {
    const currentFilter = getVisible()
    possibleFilters.forEach((result) => {
        const input = document.querySelector(`input[data-test-result="${result}"]`)
        input.checked = currentFilter.includes(result)
    })
}

const bindEvents = () => {
    const filterColumn = (evt) => {
        const { target: element } = evt
        const { testResult } = element.dataset

        doFilter(testResult, element.checked)
        const collapsedIds = getCollapsedIds()
        const updated = manager.renderData.tests.map((test) => {
            return {
                ...test,
                collapsed: collapsedIds.includes(test.id),
            }
        })
        manager.setRender(updated)
        redraw()
    }

    const header = document.getElementById('environment-header')
    header.addEventListener('click', () => {
        const table = document.getElementById('environment')
        table.classList.toggle('hidden')
        header.classList.toggle('collapsed')
    })

    findAll('input[name="filter_checkbox"]').forEach((elem) => {
        elem.addEventListener('click', filterColumn)
    })

    findAll('.sortable').forEach((elem) => {
        elem.addEventListener('click', (evt) => {
            const { target: element } = evt
            const { columnType } = element.dataset
            doSort(columnType)
            redraw()
        })
    })

    document.getElementById('show_all_details').addEventListener('click', () => {
        manager.allCollapsed = false
        setCollapsedIds([])
        redraw()
    })
    document.getElementById('hide_all_details').addEventListener('click', () => {
        manager.allCollapsed = true
        const allIds = manager.renderData.tests.map((test) => test.id)
        setCollapsedIds(allIds)
        redraw()
    })
}

const redraw = () => {
    const { testSubset } = manager

    renderContent(testSubset)
    renderDerived()
}

module.exports = {
    redraw,
    bindEvents,
    renderStatic,
}

},{"./datamanager.js":1,"./dom.js":2,"./filter.js":3,"./sort.js":7,"./storage.js":8}],6:[function(require,module,exports){
class MediaViewer {
    constructor(assets) {
        this.assets = assets
        this.index = 0
    }

    nextActive() {
        this.index = this.index === this.assets.length - 1 ? 0 : this.index + 1
        return [this.activeFile, this.index]
    }

    prevActive() {
        this.index = this.index === 0 ? this.assets.length - 1 : this.index -1
        return [this.activeFile, this.index]
    }

    get currentIndex() {
        return this.index
    }

    get activeFile() {
        return this.assets[this.index]
    }
}


const setup = (resultBody, assets) => {
    if (!assets.length) {
        resultBody.querySelector('.media').classList.add('hidden')
        return
    }

    const mediaViewer = new MediaViewer(assets)
    const container = resultBody.querySelector('.media-container')
    const leftArrow = resultBody.querySelector('.media-container__nav--left')
    const rightArrow = resultBody.querySelector('.media-container__nav--right')
    const mediaName = resultBody.querySelector('.media__name')
    const counter = resultBody.querySelector('.media__counter')
    const imageEl = resultBody.querySelector('img')
    const sourceEl = resultBody.querySelector('source')
    const videoEl = resultBody.querySelector('video')

    const setImg = (media, index) => {
        if (media?.format_type === 'image') {
            imageEl.src = media.path

            imageEl.classList.remove('hidden')
            videoEl.classList.add('hidden')
        } else if (media?.format_type === 'video') {
            sourceEl.src = media.path

            videoEl.classList.remove('hidden')
            imageEl.classList.add('hidden')
        }

        mediaName.innerText = media?.name
        counter.innerText = `${index + 1} / ${assets.length}`
    }
    setImg(mediaViewer.activeFile, mediaViewer.currentIndex)

    const moveLeft = () => {
        const [media, index] = mediaViewer.prevActive()
        setImg(media, index)
    }
    const doRight = () => {
        const [media, index] = mediaViewer.nextActive()
        setImg(media, index)
    }
    const openImg = () => {
        window.open(mediaViewer.activeFile.path, '_blank')
    }
    if (assets.length === 1) {
        container.classList.add('media-container--fullscreen')
    } else {
        leftArrow.addEventListener('click', moveLeft)
        rightArrow.addEventListener('click', doRight)
    }
    imageEl.addEventListener('click', openImg)
}

module.exports = {
    setup,
}

},{}],7:[function(require,module,exports){
const { manager } = require('./datamanager.js')
const storageModule = require('./storage.js')

const genericSort = (list, key, ascending, customOrder) => {
    let sorted
    if (customOrder) {
        sorted = list.sort((a, b) => {
            const aValue = a.result.toLowerCase()
            const bValue = b.result.toLowerCase()

            const aIndex = customOrder.findIndex((item) => item.toLowerCase() === aValue)
            const bIndex = customOrder.findIndex((item) => item.toLowerCase() === bValue)

            // Compare the indices to determine the sort order
            return aIndex - bIndex
        })
    } else {
        sorted = list.sort((a, b) => a[key] === b[key] ? 0 : a[key] > b[key] ? 1 : -1)
    }

    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const durationSort = (list, ascending) => {
    const parseDuration = (duration) => {
        if (duration.includes(':')) {
            // If it's in the format "HH:mm:ss"
            const [hours, minutes, seconds] = duration.split(':').map(Number)
            return (hours * 3600 + minutes * 60 + seconds) * 1000
        } else {
            // If it's in the format "nnn ms"
            return parseInt(duration)
        }
    }
    const sorted = list.sort((a, b) => parseDuration(a['duration']) - parseDuration(b['duration']))
    if (ascending) {
        sorted.reverse()
    }
    return sorted
}

const doInitSort = () => {
    const type = storageModule.getSort(manager.initialSort)
    const ascending = storageModule.getSortDirection()
    const list = manager.testSubset
    const initialOrder = ['Error', 'Failed', 'Rerun', 'XFailed', 'XPassed', 'Skipped', 'Passed']

    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    if (type?.toLowerCase() === 'original') {
        manager.setRender(list)
    } else {
        let sortedList
        switch (type) {
        case 'duration':
            sortedList = durationSort(list, ascending)
            break
        case 'result':
            sortedList = genericSort(list, type, ascending, initialOrder)
            break
        default:
            sortedList = genericSort(list, type, ascending)
            break
        }
        manager.setRender(sortedList)
    }
}

const doSort = (type, skipDirection) => {
    const newSortType = storageModule.getSort(manager.initialSort) !== type
    const currentAsc = storageModule.getSortDirection()
    let ascending
    if (skipDirection) {
        ascending = currentAsc
    } else {
        ascending = newSortType ? false : !currentAsc
    }
    storageModule.setSort(type)
    storageModule.setSortDirection(ascending)

    const list = manager.testSubset
    const sortedList = type === 'duration' ? durationSort(list, ascending) : genericSort(list, type, ascending)
    manager.setRender(sortedList)
}

module.exports = {
    doInitSort,
    doSort,
}

},{"./datamanager.js":1,"./storage.js":8}],8:[function(require,module,exports){
const possibleFilters = [
    'passed',
    'skipped',
    'failed',
    'error',
    'xfailed',
    'xpassed',
    'rerun',
]

const getVisible = () => {
    const url = new URL(window.location.href)
    const settings = new URLSearchParams(url.search).get('visible')
    const lower = (item) => {
        const lowerItem = item.toLowerCase()
        if (possibleFilters.includes(lowerItem)) {
            return lowerItem
        }
        return null
    }
    return settings === null ?
        possibleFilters :
        [...new Set(settings?.split(',').map(lower).filter((item) => item))]
}

const hideCategory = (categoryToHide) => {
    const url = new URL(window.location.href)
    const visibleParams = new URLSearchParams(url.search).get('visible')
    const currentVisible = visibleParams ? visibleParams.split(',') : [...possibleFilters]
    const settings = [...new Set(currentVisible)].filter((f) => f !== categoryToHide).join(',')

    url.searchParams.set('visible', settings)
    window.history.pushState({}, null, unescape(url.href))
}

const showCategory = (categoryToShow) => {
    if (typeof window === 'undefined') {
        return
    }
    const url = new URL(window.location.href)
    const currentVisible = new URLSearchParams(url.search).get('visible')?.split(',').filter(Boolean) ||
        [...possibleFilters]
    const settings = [...new Set([categoryToShow, ...currentVisible])]
    const noFilter = possibleFilters.length === settings.length || !settings.length

    noFilter ? url.searchParams.delete('visible') : url.searchParams.set('visible', settings.join(','))
    window.history.pushState({}, null, unescape(url.href))
}

const getSort = (initialSort) => {
    const url = new URL(window.location.href)
    let sort = new URLSearchParams(url.search).get('sort')
    if (!sort) {
        sort = initialSort || 'result'
    }
    return sort
}

const setSort = (type) => {
    const url = new URL(window.location.href)
    url.searchParams.set('sort', type)
    window.history.pushState({}, null, unescape(url.href))
}

const getCollapsedCategory = (renderCollapsed) => {
    let categories
    if (typeof window !== 'undefined') {
        const url = new URL(window.location.href)
        const collapsedItems = new URLSearchParams(url.search).get('collapsed')
        switch (true) {
        case !renderCollapsed && collapsedItems === null:
            categories = ['passed']
            break
        case collapsedItems?.length === 0 || /^["']{2}$/.test(collapsedItems):
            categories = []
            break
        case /^all$/.test(collapsedItems) || collapsedItems === null && /^all$/.test(renderCollapsed):
            categories = [...possibleFilters]
            break
        default:
            categories = collapsedItems?.split(',').map((item) => item.toLowerCase()) || renderCollapsed
            break
        }
    } else {
        categories = []
    }
    return categories
}

const getSortDirection = () => JSON.parse(sessionStorage.getItem('sortAsc')) || false
const setSortDirection = (ascending) => sessionStorage.setItem('sortAsc', ascending)

const getCollapsedIds = () => JSON.parse(sessionStorage.getItem('collapsedIds')) || []
const setCollapsedIds = (list) => sessionStorage.setItem('collapsedIds', JSON.stringify(list))

module.exports = {
    getVisible,
    hideCategory,
    showCategory,
    getCollapsedIds,
    setCollapsedIds,
    getSort,
    setSort,
    getSortDirection,
    setSortDirection,
    getCollapsedCategory,
    possibleFilters,
}

},{}]},{},[4]);
    </script>
  </footer>
</html>